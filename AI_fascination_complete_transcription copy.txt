[00:00:00.038] Speaker 1: সো, ধরো তোমাকে চিনে না।
[00:00:01.818] Speaker 1: এরকম কোনো একজন মানুষ তোমার এই এপিসোড আসলে ঠিক কী কারণে দেখবে? তুমি নিজে যেহেতু একজন কেজো মানুষ...
[00:00:05.518] Speaker 2: হ্যাঁ হ্যাঁ হ্যাঁ।
[00:00:06.018] Speaker 1: সো এটার উপযোগিতা কী এই এপিসোডটা? মানে এই এপিসোডটা
[00:00:10.518] Speaker 1: ধরলাম তুমি কেন করছো সেটা তুমিই জানো।
[00:00:13.198] Speaker 1: হুম।
[00:00:13.908] Speaker 1: তোমার উদ্দেশ্য না হয় আংশিক হোক বা কিছু না কিছু হোক ফুলফিল হইছে।
[00:00:17.658] Speaker 1: হুম।
[00:00:17.978] Speaker 1: কিন্তু তুমি যখন চাচ্ছো যে একজন ভিউয়ার বা অডিয়েন্স তোমার এটা দেখবে
[00:00:22.188] Speaker 1: হুম।
[00:00:22.958] Speaker 1: কী আছে এখানে?
[00:00:25.108] Speaker 2: এইখানে
[00:00:26.968] Speaker 2: কী আছে বলতে,
[00:00:28.298] Speaker 2: এআই রিলেটেড একটা এক্সাইটমেন্ট তার মধ্যে সঞ্চারিত হইতে পারে।
[00:00:36.910] Speaker 1: একেকটা দশক বা একেকটা যুগ যখন শুরু হয়, তখন দেখা যাচ্ছে যে সেটার পৃথিবীতে কোনো না কোনো একটা ট্রেন্ড থাকে।
[00:00:42.270] Speaker 1: যেমন
[00:00:43.610] Speaker 1: আজ থেকে কয়েক বছর আগে যখন ট্রেন্ড ছিল ফেসবুকের ট্রেন্ড।
[00:00:47.700] Speaker 1: তো ফেসবুক, টুইটার এরা মোটামুটি এখন সেটেলড হয়ে গেছে।
[00:00:50.310] Speaker 1: তারপর লাস্ট কয়েক বছরে
[00:00:52.270] Speaker 1: সবসময় শুনতেছি যে এআই এর কথা, এআই এর কথা।
[00:00:55.200] Speaker 1: তো এআই জিনিসটা নিয়ে এত কথা শুনতে শুনতে মাঝে মাঝে খুব বিরক্ত লাগে
[00:00:58.750] Speaker 1: এবং এটা নিয়ে যে
[01:00.780] Speaker 1: আমার এই বাবুল রেজার সাথেও বা অন্যান্য বিভিন্ন সময় বিভিন্ন জনের সাথে কথা বলছি, বাট সেটা প্রসঙ্গক্রমে।
[01:04.970] Speaker 1: কিন্তু সরাসরি এআই নিয়ে কোনো কথা হয় নাই।
[01:07.720] Speaker 1: তো যেহেতু এআই নিয়ে আমার এক ধরনের একটা মানে বিরক্তি আছে, বাট আমি যদিও চ্যাট জিপিটি সাবস্ক্রাইব করি আড়াই হাজার টাকা দিয়ে।
[01:15.360] Speaker 1: বাট স্টিল আমার মনে হয়েছে এআই যতটা গুরুত্ব পাওয়া উচিত তার চেয়ে অনেক বেশি গুরুত্ব পেয়ে যাচ্ছে এবং জিনিসটা শেষ পর্যন্ত হয়তো একটা শেয়ার মার্কেট টাইপ কিছু একটা হয়ে যাইতে পারে।
[01:23.950] Speaker 1: কিন্তু
[01:24.960] Speaker 1: আমার একজন খুব
[01:26.240] Speaker 1: মানে পছন্দের জুনিয়র আছে, আবিদ আদনান।
[01:29.800] Speaker 1: আমি তাকে ওর সাথে যখন প্রথম পাইছিলাম ২০১৪ তে, ওকে ডাকতাম হতাশ আদনান।
[01:33.400] Speaker 1: পরবর্তীতে সে বিয়ে করে
[01:35.730] Speaker 1: গেরস্ত আদনান হইছে এবং
[01:37.670] Speaker 1: আমি ওই সময় তাকে যেভাবে বা যে বেশভূষায় যে চেহারায় দেখছি, সেখান থেকে আজকে যখন তাকে দেখতেছি
[01:43.680] Speaker 1: মানে আমি বুঝতে পারছি যে মানুষ আসলে বেঁচে থাকলে বদলায়। মুনীর চৌধুরী কথাটা ঠিক বলে নাই।
[01:48.810] Speaker 1: মানে ঠিকই বলছে।
[01:51.270] Speaker 1: তো যাইহোক, ও
[01:52.790] Speaker 1: ইদানিং নিজেকে এআই আদনান দাবি করার চেষ্টা করতেছে।
[01:55.350] Speaker 1: তো আমি ওকে বললাম যে, "আমি তোমাকে এআই আদনান কখনোই বলব না।"
[01:57.370] Speaker 1: কারণ এআইকে আমি সবসময় একটা অ্যাসিস্ট্যান্টের জায়গা থেকে দেখি।
[02:00.670] Speaker 1: ফলে তোমাকে যদি আমি এআই বলা শুরু করি,
[02:03.450] Speaker 1: তখন
[02:04.220] Speaker 1: আমার কাছে তোমার যে পজিশনটা আছে, তুমি কিন্তু পজিশন লুজ করবা।
[02:07.130] Speaker 1: তো সেজন্য সে গেরস্ত আদনান হিসেবেই
[02:10.510] Speaker 1: সেটেলড হইছে।
[02:11.750] Speaker 1: তো ও এআই নিয়ে যেহেতু লাস্ট তিন চার পাঁচ বছর ধরে অনেক পড়াশোনা করতেছে, এটা নিয়ে এংগেজড।
[02:15.860] Speaker 1: ও এআই নিয়ে একটা আলাদা
[02:17.890] Speaker 1: ল্যান্ডের মধ্যে ঢুকে গেছে।
[02:19.160] Speaker 1: ল্যান্ড অফ এআই।
[02:21.030] Speaker 1: সো
[02:22.510] Speaker 1: তো ওর সাথে মনে হলো যে বাবুল রেজার সাথে কথা বলার জন্য
[02:25.560] Speaker 1: ওই একজন ভালো রিসোর্স।
[02:27.240] Speaker 1: তো বেসিক্যালি আদনান অন্যরকম গ্রুপে জব করে।
[02:31.900] Speaker 1: আমার জীবনের প্রথম ক্যারিয়ার অন্যরকম গ্রুপে শুরু হয়েছিল।
[02:34.690] Speaker 1: সেখানে আমি ক্রিয়েটিভ কনসালটেন্ট ছিলাম আট বছর।
[02:37.580] Speaker 1: বাট বয়স বাড়ার সাথে সাথে অন্যরকম গ্রুপও বড় হয়ে গেছে, আমিও আলাদা হয়ে গেছি।
[02:41.360] Speaker 1: বাট স্টিল মানে যেটা হয় যে মানুষের জীবনের
[02:44.520] Speaker 1: প্রথম জিনিসপত্র কখনো হয় না, ভুলে না।
[02:46.900] Speaker 1: মানুষ তার বাপের নাম চেঞ্জ করতে পারে না, মায়ের নাম চেঞ্জ করতে পারে না।
[02:49.880] Speaker 1: সেরকম আমি যখন আমার ৪০ বছর, ৫০ বছর, ৬০ বছর যখনই হোক,
[02:54.490] Speaker 1: আমার
[02:55.670] Speaker 1: ক্যারিয়ার কোথা থেকে শুরু হয়েছিল, সেটা তো আসলে চেঞ্জ হবে না।
[02:57.910] Speaker 1: তো এইজন্য ওর সাথে আমার ওই অন্যরকম গ্রুপের ওই ব্যাপারটাও একটা ইমোশনের ব্যাপার আছে।
[03:03.110] Speaker 1: কিন্তু এআই কি আসলে ইমোশন বুঝে?
[03:05.470] Speaker 1: হয় এবার!
[03:06.690] Speaker 1: তো ওর সাথে এআই এর যে গল্পটা, দেখা যাক ই করা শুরু করি।
[03:09.770] Speaker 1: তো আদনান...
[03:10.520] Speaker 2: জ্বী, ভাইয়া।
[03:10.870] Speaker 1: তুমি তো হতাশ আদনান থেকে এখন গেরস্ত আদনান।
[03:13.560] Speaker 2: জ্বী।
[03:13.800] Speaker 1: তো
[03:15.150] Speaker 1: গেরস্ত আদনানের জীবনে এআই কিভাবে ঢুকে পড়লো?
[03:17.510] Speaker 2: আচ্ছা, গেরস্ত আদনানের জীবনে এআই ঢুকছে হচ্ছে,
[03:20.300] Speaker 2: আমি তো বেসিক্যালি মার্কেটিং নিয়েই ছিলাম অনেকদিন।
[03:23.230] Speaker 2: আপনি যখন আমাকে জয়েন করাইছিলেন, তখন হচ্ছে আমি কন্টেন্ট নিয়ে জয়েন করছিলাম।
[03:27.420] Speaker 2: পরে আস্তে আস্তে কাজ করতে করতে মার্কেটিং।
[03:29.410] Speaker 2: পরে হচ্ছে মার্কেটিং নিয়েই কাজ করতাম।
[03:31.730] Speaker 2: তো করতে করতে যেটা হইছে যে কোম্পানিতে একটা শিফট আসছে আর কি।
[03:34.540] Speaker 2: মানে নতুন কনসার্ন আসছে।
[03:36.420] Speaker 2: তারপরে নতুন লিডারশিপ আসছে।
[03:37.940] Speaker 2: তো ওইরকম যখন হইছে যে তখন আমার আসলে
[03:41.130] Speaker 2: ওই মার্কেটিং এর কাজের পরিমাণ একটু কমছে।
[03:43.790] Speaker 2: তো যখন কমে গেছে এবং ওইরকম একটা টাইমেই হচ্ছে চ্যাট জিপিটি
[03:47.380] Speaker 2: আপনার আসলো।
[03:48.330] Speaker 2: ২০২২ এ আসছিল চ্যাট জিপিটি।
[03:49.950] Speaker 2: কিন্তু ২৩ নাগাদ হচ্ছে আপনার ওদের জিপিটি ফোর ভার্সন যেটা,
[03:53.370] Speaker 2: মানে যেইটার সাথে একটু ইন্টার‍্যাক্ট করলে আসলে সারপ্রাইজিং যেই
[03:57.650] Speaker 2: এলিমেন্টগুলা, ওইটা টের পাওয়া যায়।
[04:00.320] Speaker 2: ২০২৩ এর ওই মাঝামাঝির দিকে মেবি, মানে আমি হচ্ছে ওইটা একদিন টের পাইছি।
[04:05.400] Speaker 2: আর আমার হচ্ছে ছোটবেলা থেকেই আমার হচ্ছে ইন্টারনেট ঘাটার অভ্যাস, কম্পিউটার ঘাটার অভ্যাস, ইন্ট্রোভার্ট মানুষ।
[04:10.960] Speaker 2: ডিভাইসের সাথেই বেশি যায়।
[04:12.630] Speaker 2: তো যেকোনো প্রবলেমে পড়লে আমার যেটা হইতো যে আমি ধরেন নিজেই গুগল করে
[04:16.590] Speaker 2: ২০ টার মত ওয়েবসাইট, ৩০ টার মত ওয়েবসাইট ঘেঁটে
[04:19.860] Speaker 2: পুরাটা পড়ে, ইউজুয়ালি মানুষজন যেটা করে না আর কি।
[04:22.050] Speaker 2: মানে যে এক দুইটা ওয়েবসাইট ঘাটে।
[04:23.370] Speaker 2: বাট আমার যদি কোনো একটা জিনিস করা লাগবে,
[04:25.800] Speaker 2: সেটা আমি নেটে ঘাটতে ঘাটতে ঘাটতে ঘাটতে ধরেন অনেক র‍্যাবিট হোলের অনেক ভিতরে গিয়ে হয়তো একটা অ্যানসার পাইতাম
[04:30.650] Speaker 2: বা একটা ফিক্স পাইতাম।
[04:31.810] Speaker 2: বা ধরেন, ওইখানে একটা অ্যানসার পাইছি, ওইটা ট্রাই করছি, করে দেখছি যে কাজ করতেছে না।
[04:35.890] Speaker 2: টেকনিক্যাল ইস্যু হয়তো।
[04:37.520] Speaker 2: কাজ করতেছে না।
[04:38.560] Speaker 2: পরে গিয়ে আবার ওই ইস্যুটা নিয়ে আবার সার্চ করা শুরু করলাম।
[04:40.970] Speaker 2: তো বিশাল একটা র‍্যাবিট হোলের মধ্য দিয়ে গিয়ে অ্যানসার পাওয়া যাইতো।
[04:44.270] Speaker 2: আমি দেখছি যে অলওয়েজই অ্যানসার কোথাও না কোথাও আছে।
[04:46.680] Speaker 2: টেকনিক্যাল জিনিসপত্রের বিশেষ করে।
[04:48.910] Speaker 2: ফিলোসফিক্যাল জিনিসপত্রও পাওয়া যায়, একটা লেভেলের ইনসাইট পাওয়া যায়।
[04:51.810] Speaker 2: তো চ্যাট জিপিটির সারপ্রাইজিং মোমেন্ট ছিল আমার এরকম একটা ইস্যু আমি হচ্ছে ওকে দিয়ে
[04:56.400] Speaker 2: মানে আমি জাস্ট মানে অবাক হয়ে গেছি।
[04:58.290] Speaker 2: মানে যে, প্রথম কথা অবাক হইছি যে ও আমাকে যে রেসপন্স দিছে, ওইটা তো অনেক হিউম্যান ছিল।
[05:02.730] Speaker 2: আর স্টেপগুলাও লজিক্যাল ছিল।
[05:04.380] Speaker 2: পরে ওই স্টেপ কাজ করতে গিয়ে কাজ করে নাই।
[05:06.940] Speaker 2: বাট আমি ওকে যখন কনটেক্সটা আবার দিছি,
[05:09.130] Speaker 2: তখন হচ্ছে আমি দেখতেছি যে আরে, এ তো কনটেক্স বুঝে আমাকে আবার
[05:12.780] Speaker 2: মানে ধরেন, আগে আমার যেটা এক ঘন্টার একটা নিজের ঘাটাঘাটি করা লাগতো,
[05:17.380] Speaker 2: আবার আমার কনটেক্সটের সাথে মিলায়ে আবার সলিউশনটাকে বুঝে সলভ করতে হতো।
[05:22.650] Speaker 2: ওইটা আমার ধরেন ওই যে
[05:24.160] Speaker 2: ১০-১৫ মিনিটে হয়ে গেছে।
[05:25.290] Speaker 2: আমি যদি আপনাকে একটু স্পেসিফিক করে বলি যে বিজ্ঞানবাক্সেরই একটা কাজ,
[05:28.480] Speaker 2: আমাদের ওয়ার্ডপ্রেসের ব্যাকএন্ডে অর্ডার আসতো, অনেকগুলা অর্ডার।
[05:31.630] Speaker 2: তো এই অর্ডার হচ্ছে অটোমেটেড ওয়েতে গুগল শিটে নিয়ে যাইতে হবে।
[05:36.190] Speaker 2: তো আগে হইলে আমি যেটা করতাম যে আমি ঘেটে ঘেটে একটা একটা করে করতাম।
[05:38.740] Speaker 2: তো এখন আমি ওকে যেটা করছি যে কনটেক্সট বুঝায়ে ওকে যখন বলছি, ও আমাকে যেই কোড দিছে,
[05:43.140] Speaker 2: এই অ্যাপস্ক্রিপ্টের কোড বলে আর কি গুগলের।
[05:45.310] Speaker 2: মানে সোজা বাংলায় হচ্ছে ওই কোডটা দিয়ে হচ্ছে গুগলের শিট অটোমেট করা যায়।
[05:48.930] Speaker 2: ওইটা সেকেন্ড ট্রাইতেই কাজ করে ফেলছিল আমার।
[05:51.810] Speaker 2: ওইটা একটা আহা মোমেন্ট ছিল আর কি।
[05:52.920] Speaker 2: সবার যেমন একটা চ্যাট জিপিটি মোমেন্ট আছে,
[05:55.770] Speaker 2: মানে যারাই চ্যাট জিপিটি ইউজ করে, তাদের একটা চ্যাট জিপিটি মোমেন্ট থাকে কিন্তু যে কিরে বাবা, কী হচ্ছে!
[06:00.620] Speaker 2: হয়তো আজকে থেকে পাঁচ বছর পরে আমাদের বাচ্চারা বা ইয়েরা, ওদের কাছে মনে হবে যে এটা তো নরমাল, ইন্টারনেট ব্রাউজ করার মতই।
[06:06.180] Speaker 2: বাট আমাদের তো আসলে একটা মোমেন্ট আছে যে, মানে আমরা ট্রানজিশনটা খুব ক্লিয়ারলি ধরতে পারতেছি।
[06:11.410] Speaker 2: তো ওইখান থেকে আপনার ২০২৩ এর
[06:14.300] Speaker 2: মানে আমার যে ওই যে মার্কেটিং থেকেও একটু আমার ইয়ে কমতেছে,
[06:17.060] Speaker 2: ইনভলভমেন্ট কমতেছে,
[06:18.350] Speaker 2: প্লাস নতুন একটা জিনিস,
[06:19.920] Speaker 2: আর ভাইয়ার কোম্পানিতে তো অলওয়েজ এক্সপ্লোরিং এর একটা
[06:22.250] Speaker 2: মানে হিউজ অপারচুনিটি থাকে।
[06:24.080] Speaker 2: মানে ভাইয়া হচ্ছে লার্নিংকে কিন্তু মানে আপনিও তো জানেন যে কেউ লার্ন করতে চাইলে ভাইয়া ওইটা কখনো ইয়ে করে না।
[06:29.400] Speaker 2: ইভেন ভাইয়ার সাথে যারা কাজ করে, তারাও মোটামুটি এইরকমই।
[06:31.950] Speaker 2: যে কেউ যদি কোনো একটা কিছু এক্সপ্লোর করতে চায়, সেটা কিন্তু উনারা খুবই একোমোডেট করে।
[06:36.930] Speaker 2: তো আমি ওইখানে অনেক এক্সপ্লোর করারও টাইম পাইছি।
[06:38.830] Speaker 2: কারণ আমার
[06:40.540] Speaker 2: দুইটা মেয়ে আছে,
[06:41.740] Speaker 2: বাসায় ইয়ে আছে,
[06:42.920] Speaker 2: মানে ওয়াইফ, আম্মা, ব্যস্ততা আছে।
[06:45.190] Speaker 2: মতিঝিল থেকে মিরপুরে যাই।
[06:46.850] Speaker 2: তো তারপরেও আমি কিন্তু মানে অফিসে যেহেতু আমি এক্সপ্লোর করার অনেক টাইম পাইছি,
[06:51.980] Speaker 2: ওইখান থেকে হচ্ছে আমি জিনিসগুলার আসলে
[06:53.940] Speaker 2: মানে অনেক বেশি আমাকে কানেক্ট করছে, এক নাম্বার।
[06:56.660] Speaker 2: আর দুই নাম্বার হচ্ছে ভাইয়া যে আমি ওই যে, আপনি তো আমার প্রোফাইল জানেন MBTI প্রোফাইল, INFP.
[07:01.370] Speaker 2: তো আমি তো পসিবিলিটির মধ্যে নরমালি বেশি থাকি যে
[07:04.470] Speaker 2: হোয়াট মাইট হ্যাপেন
[07:06.010] Speaker 2: বা হোয়াট মানে ক্যান হ্যাপেন।
[07:08.120] Speaker 2: সো যখন এই টেকনোলজিটা পাইলাম, মানে
[07:11.660] Speaker 2: তো এরপর থেকে আমার হচ্ছে পসিবিলিটিজ অনেক বেশি আমাকে, মানে এটা দিয়ে কী কী হইতে পারে,
[07:15.540] Speaker 2: হুম।
[07:16.140] Speaker 2: রিয়েলিটিতে তো হয়তো আমি তেমন কিছুই অত করি নাই।
[07:18.660] Speaker 2: বাট মাথার মধ্যে ধরেন
[07:20.300] Speaker 2: হাজার পদের পসিবিলিটিজ হচ্ছে চলে আসছে।
[07:22.610] Speaker 2: তো যখন চলে আসছে, আমি আসলে ফোর্সড হইছি জিনিসটায়।
[07:24.960] Speaker 2: মানে
[07:25.680] Speaker 2: ইভেন এমনও হইছে আমার অফিসের লোকজন তিতা হয়ে গেছে, ইভেন তিতা।
[07:28.530] Speaker 2: কেন তিতা হয়ে গেছে?
[07:29.480] Speaker 2: কারণ আমার মুখে, মানে আমি খালি তাদেরকে এইটাই বলতেছি যে ভাই, মানে এভরিথিং উইল বি চেঞ্জড, এভরিথিং উইল বি চেঞ্জড।
[07:36.190] Speaker 2: তো ওই জায়গা থেকে আর কি ভাইয়া, মানে
[07:38.300] Speaker 2: চ্যাট জিপিটি মানে সোজা বাংলায় পুরা পৃথিবীর মানুষকে যেমন এআই প্রথম এআই এর প্রথম
[07:42.820] Speaker 2: মানে ট্রিগারটা করে চ্যাট জিপিটি,
[07:44.750] Speaker 2: আমাকে হচ্ছে চ্যাট জিপিটি হচ্ছে
[07:47.160] Speaker 2: এআইতে ট্রিগার করছে।
[07:48.580] Speaker 2: করার পরে আমি হচ্ছে
[07:50.910] Speaker 2: এটার যে পসিবিলিটিজটা আমার মাথায় আসা শুরু করছে,
[07:53.400] Speaker 2: আর আমার একটা অ্যাডভান্টেজ ছিল যে আমি মানে কোডার না, প্রোগ্রামারও না।
[07:56.960] Speaker 2: বাট আমার তো আপনি জানেনই যে মানে টেকনিক্যাল, মানে আমার একটা ছোট স্টার্টআপও ছিল।
[08:00.680] Speaker 2: আর টেকনিক্যাল জিনিসপত্রও আমি ভালো বুঝি।
[08:02.820] Speaker 2: সো আমার আবার আরেকটা ব্যাপারও আছে যে কোনো একটা জিনিসের ধরেন মানে ভিতরের যে যে ব্যাপারগুলা,
[08:07.130] Speaker 2: যে এই জিনিসটা আসলে কাজ করতেছে কীভাবে?
[08:08.820] Speaker 2: আমি যখন এইটা নিয়েও ঘাটা শুরু করছি,
[08:11.160] Speaker 2: তখনও ওইখানে কিন্তু
[08:12.920] Speaker 2: মানে ব্যাকএন্ডের অনেকগুলা ব্যাপার আছে, যেমন লার্জ ল্যাঙ্গুয়েজ মডেল বলে।
[08:15.650] Speaker 2: মানে চ্যাট জিপিটির যে টেকনোলজি, বিহাইন্ড দা সিন টেকনোলজি, LLM.
[08:19.460] Speaker 2: তো এই LLM এর মেকানিজম, এটা কীভাবে কাজ করে?
[08:21.650] Speaker 2: গুগল থাকতে কেন চ্যাট জিপিটি LLM এ ডমিনেট করলো?
[08:26.150] Speaker 2: যেমন আপনি জানেন কিনা যে এই জিপিটির যে 'টি',
[08:28.460] Speaker 2: হুম।
[08:28.520] Speaker 2: এই 'টি'টা, এই 'টি'টা হচ্ছে Transformer.
[08:31.020] Speaker 2: Generative, Pre-trained Transformer.
[08:32.840] Speaker 2: এই Transformer টেকনোলজি গুগলের রিসার্চ ল্যাবে বসে বানানো।
[08:36.870] Speaker 1: ওকে।
[08:37.490] Speaker 2: বাট সেইটাই গিয়ে স্যাম অল্টম্যানের OpenAI হচ্ছে
[08:41.970] Speaker 2: মানে ওইখানের ফার্স্ট মুভার, ফুল অ্যাডভান্টেজটা পেয়ে গেল।
[08:45.330] Speaker 2: এই যে কোয়েশ্চেনগুলা,
[08:46.990] Speaker 2: আর আমার তো আজাইরা ঘাটতেও ভালো লাগে।
[08:48.470] Speaker 2: কারণ মানুষের হচ্ছে "আরে, এইটা দিয়ে আমি জানি কী করব!"
[08:50.510] Speaker 2: কিন্তু আমার হচ্ছে যে কিরে ভাই, এটা কীভাবে... ওকে।
[08:52.470] Speaker 1: তো তোমার এই গল্পটা, এই গল্পটা তো মোস্টলি
[08:55.770] Speaker 1: একজন, বলা যাইতে পারে, একজন বিগিনার,
[08:57.650] Speaker 1: হুম।
[08:57.920] Speaker 1: যে
[08:59.500] Speaker 1: যদি আমি এভাবে বলি যে, জীবনে কোনোদিন কোকাকোলা খায় নাই,
[09:03.110] Speaker 1: হুম।
[09:03.740] Speaker 1: সে হঠাৎ করে একদিন একটা কোকের বোতল দেখলো।
[09:05.710] Speaker 1: মানে গড মাস্ট বি ক্রেজি ফিল্মটা যদি তুমি দেখে থাকো।
[09:07.720] Speaker 2: হুম হুম।
[09:08.100] Speaker 2: দেখছি, মানে অনেকটাই দেখছি।
[09:09.680] Speaker 1: হ্যাঁ, ওই যে একটা জঙ্গলে গিয়ে একটা কোকের বোতল পড়ে।
[09:11.890] Speaker 1: তারা মনে করে এটা তাদের জন্য অভিশাপ।
[09:13.620] Speaker 1: হুম।
[09:13.800] Speaker 1: এরপরে এটা হচ্ছে পৃথিবীর শেষ প্রান্তে গিয়ে ফেলে দিয়ে আসতে হবে।
[09:16.400] Speaker 1: তো এরপর সে এটা নিয়ে
[09:17.910] Speaker 2: হ্যাঁ হ্যাঁ।
[09:18.150] Speaker 1: রওনা দেয়।
[09:19.460] Speaker 1: তো তোমার ব্যাপারটা হয়তো শুরু হয়েছিল ওইভাবে।
[09:22.030] Speaker 1: তারপর ওইটা করতে করতে করতে তোমার যে জার্নিটা হইলো।
[09:25.770] Speaker 1: সো এইখানে
[09:27.180] Speaker 1: যদি এআই এর ব্যাপারটা ধরি, একটা হইলো যে যারা
[09:29.830] Speaker 1: টেকনোলজি নিয়ে কাজ করে, লাইক যারা ডেভেলপার,
[09:32.400] Speaker 1: তাদের যে ভিউ,
[09:34.050] Speaker 1: তোমারটা তো মোস্টলি ইউজার পার্সপেক্টিভ থেকে।
[09:36.430] Speaker 1: নাকি তুমি এইখানে যদিও তুমি
[09:38.930] Speaker 1: তোমার একটা আইটি ধরনের ই ছিল, মানে স্টার্টআপ ছিল,
[09:41.690] Speaker 1: বাট তুমি নিজে তো ডেভেলপার বা ওই ধরনের স্কিলড মানে ওই ট্রেনিংটা তোমার নাই।
[09:46.390] Speaker 1: নাই।
[09:47.160] Speaker 1: সো তুমি এআই নিয়ে তোমার যে ফ্যাসিনেশন বা পসিবিলিটিস এর কথা বলতেছো, এইগুলার বেস কি ইউজার এক্সপেরিয়েন্স থেকে?
[09:53.790] Speaker 1: নাকি তোমার ডেভেলপারদের সাথে বা যারা কাজ-টাজ করে, ওই সমস্ত জায়গা থেকেও তোমার ফিডব্যাক নিয়ে তারপরে এই পারসেপশনটা তৈরি হইছে?
[10:01.373] Speaker 2: আচ্ছা, হ্যাঁ, মানে এটা খুবই ভালো একটা পয়েন্ট বলছেন যে ইউজারের পার্সপেক্টিভ থেকেও আছে,
[10:05.903] Speaker 2: আবার যেহেতু আমি আগে আমার যে স্টার্টআপ ছিল, ওইটা অ্যাপ স্টোরেরই স্টার্টআপ ছিল।
[10:09.993] Speaker 2: মানে আমি কোড নিয়েও নাড়াচাড়া করছি।
[10:12.333] Speaker 2: তো সেই জায়গা থেকে SaaS লেভেলে
[10:14.933] Speaker 2: মানে সফটওয়্যার কীভাবে কাজ করে বা টেকনোলজির যে বুম হচ্ছে, ইন্টারনেট থেকে কীভাবে আমরা স্মার্টফোনে আসলাম, তার আগে কী ছিল,
[10:22.753] Speaker 2: তারপরে হচ্ছে এখন স্মার্টফোন থেকে যে এই যে এআই বেসড একটা রেভোলিউশন হচ্ছে,
[10:26.963] Speaker 2: এই জিনিসগুলো আমার মানে আন্ডারস্ট্যান্ডিং এ ছিল, এক নাম্বার।
[10:30.293] Speaker 2: আর দুই নাম্বার হচ্ছে যে টেকনিক্যাল হওয়ার কারণে, এই যে কেন এটাকে ভালো পয়েন্ট বলতেছি,
[10:33.783] Speaker 2: এই টেকনোলজিটা এমন একটা টেকনোলজি ভাইয়া,
[10:37.363] Speaker 2: চ্যাট জিপিটি এআই মোমেন্টটাকে ট্রিগার করছে।
[10:40.493] Speaker 2: চ্যাট জিপিটি এআই রেভোলিউশনের শুরুতেও আছে।
[10:42.853] Speaker 2: বাট
[10:44.293] Speaker 2: এই যে মোমেন্টটা, এটা হচ্ছে কাইন্ড অফ ইঞ্জিন আবিষ্কারের মত।
[10:48.913] Speaker 2: যে কথা আমি জানি না কে ইঞ্জিন আবিষ্কার করছিল, মেবি ফোর্ড বা কেউ একজন।
[10:52.743] Speaker 2: তো যেটা হয়েছিল যে ইঞ্জিন আবিষ্কার করে ফোর্ডের একটা গাড়ি বের হইছে।
[10:56.193] Speaker 2: বাট তারপরে কী হইছে?
[10:57.103] Speaker 2: তারপরে যেটা হইছে যে পৃথিবীর সমস্ত কিছুতে
[11:01.123] Speaker 2: ব্যাকএন্ড টেকনোলজিতে কিন্তু
[11:03.203] Speaker 2: ইঞ্জিন চলে গেছে।
[11:05.413] Speaker 2: চ্যাট জিপিটি হচ্ছে ওই গাড়িটা ফোর্ডের।
[11:07.973] Speaker 2: আর এআই এর যে ব্যাকএন্ড, জেনারেটিভ এআই আর কি, এইটা হচ্ছে এই ইঞ্জিনটা।
[11:12.923] Speaker 2: আর আমার ইন জেনারেল মানে সিস্টেম ডিজাইন নিয়েও আমার আগ্রহ আছে।
[11:15.933] Speaker 2: ধরেন বিজ্ঞানবাক্সের জন্য আমি অটোমেটেড বট বানাইছি আরও মানে ধরেন দুই তিন বছর আগে।
[11:20.193] Speaker 2: এবং ওই বট থেকে ধরেন প্রায় মানে এরাউন্ড ওয়ান ক্রোরের মতো অটোমেটেড সেল আসছে।
[11:24.773] Speaker 2: আমার ইয়ে অনুযায়ী, এক্সাক্ট ডাটাটা আমার মনে নাই।
[11:26.703] Speaker 2: ওই বটটা হচ্ছে
[11:28.053] Speaker 2: এআই আসার আগেই
[11:29.623] Speaker 2: এই চ্যাটফুয়েল, মেনুচ্যাট নামে কোম্পানি আছে, ওরা হচ্ছে একটার পর একটা টেক্সট পাঠায়ে আপনি হচ্ছে নরমাল অর্ডার করছেন না আপনি ইন্টারনেটে?
[11:36.193] Speaker 2: নাম-টাম দিতে হয়।
[11:37.843] Speaker 2: ওইরকম একই জিনিস আপনাকে কনভার্সেশনাল স্টাইলে নিবে আর কি।
[11:40.863] Speaker 2: এটাকে বট বলে আর কি।
[11:42.023] Speaker 2: মেসেঞ্জার বট আছে।
[11:43.203] Speaker 1: হুম হুম।
[11:43.603] Speaker 2: তো ওই ব্যাকএন্ডের টেকনোলজিটাও আমার ইয়েতে আছে।
[11:46.013] Speaker 2: আবার হচ্ছে আপনার যেহেতু অ্যাপের কাজ করছি, ওইটা আছে।
[11:48.653] Speaker 2: আবার হিউম্যান সেন্ট্রিক ডিজাইন নিয়েও আমার মানে,
[11:51.103] Speaker 2: মানে কোনো যে আপনার
[11:53.693] Speaker 2: পার্সোনাল ইন্টারেস্ট বা ওইরকম ইয়ে থেকে না।
[11:55.723] Speaker 2: বাট এটা আমার মানে ওই যে INFP এর যে F ভাইয়া,
[11:58.213] Speaker 1: হুম।
[11:58.743] Speaker 2: ওই F থেকে হচ্ছে এম্প্যাথেটিক যে ডিজাইন,
[12:02.503] Speaker 2: ওইটাও কিন্তু আমার মানে আমি টের পাইছি।
[12:04.283] Speaker 2: এগুলা শোনাইতে পারে যে আমি একটু, আমি জানি না, মানে কেমন মানে সেলফ ইয়ে করতেছি ওরকম মনে হইতে পারে।
[12:08.763] Speaker 1: আরে তোমার মনে হয় নাকি আসে, তুমি বলতে থাকো না।
[12:10.033] Speaker 2: ওকে।
[12:11.293] Speaker 1: আমি তো আর তোমারে জাজ করতেছি না।
[12:11.963] Speaker 2: ওকে ওকে, রাইট রাইট।
[12:12.873] Speaker 2: ওই যে, এটাও কিন্তু আমার ওই যে জাজমেন্টাল একটা ইয়ে চলে আসতেছে, ওকে।
[12:16.143] Speaker 2: তো ওই জায়গা থেকে যে মানে হিউম্যান সেন্ট্রিক যে ডিজাইন,
[12:18.573] Speaker 2: তো হিউম্যান সেন্ট্রিক ডিজাইন, আবার এই জায়গায় হচ্ছে এই যে ব্যাকএন্ডের ওই টেকনোলজিক্যাল জিনিসটা,
[12:22.763] Speaker 2: এইগুলা মেলার কারণেই যেমন আমি নিজেই কিন্তু আপনাকে এপ্রোচ করছি যে ভাইয়া আমি এআই নিয়ে পডকাস্ট করতে চাই, কেন?
[12:27.423] Speaker 1: হুম।
[12:27.973] Speaker 2: বিকজ
[12:29.243] Speaker 1: আসলে আমি খুব অবাক হইছিলাম।
[12:30.083] Speaker 1: তুমি পডকাস্ট করতে পারো, এটা আমার মাথায় আসে নাই।
[12:32.493] Speaker 2: হ্যাঁ, মাথায় আসে নাই।
[12:33.243] Speaker 2: আবার আমি কিন্তু মানুষকে...
[12:34.503] Speaker 1: কারণ তোমার সাথে তো আসলে আমার এতদিন যোগাযোগ নাই।
[12:37.053] Speaker 1: তোমার যে এই ট্রান্সফরমেশন হইছে, এটা তো আমি জানি না।
[12:39.113] Speaker 2: হ্যাঁ।
[12:40.913] Speaker 2: আমি পডকাস্ট করতে পারি ব্যাপারটার চেয়েও, ব্যাপারটা ইয়ে হচ্ছে আমি এআই নিয়ে এতটাই ইন্ট্রিগড,
[12:46.043] Speaker 2: আমি এতটাই ইন্ট্রিগড, আমি কিন্তু বইও লিখতেছি।
[12:48.373] Speaker 2: মানে জাস্ট এটা বইয়ের মার্কেটিং করার জন্য বলতেছি তা না।
[12:51.493] Speaker 1: তোমার এত ক্ল্যারিফিকেশন দিতে হবে কেন?
[12:52.793] Speaker 1: তুমি কথার ফ্লো নষ্ট করতেছো তো!
[12:54.383] Speaker 2: হ্যাঁ।
[12:54.773] Speaker 1: বলতে থাকো না।
[12:55.233] Speaker 2: তো আমি এটা নিয়ে এতটাই ইন্ট্রিগড যে
[12:57.943] Speaker 2: আমি আমার ওয়াইফকে পাগল বানায় ফেলছি।
[13:00.913] Speaker 2: তারপরে ধরেন আমার অফিসে, আমার আমি যেই ফ্লোরে বসি,
[13:03.953] Speaker 2: ওইখানের অন্য মানে যারা আমাকে চিনে, এরা জানে যে আদনানের কাছে গেলেই এখন দুই মিনিট একটু এআই নিয়ে কিছু একটা শোনা লাগবে।
[13:09.433] Speaker 1: তাহলে তোমার মাঝে মাঝে আমার প্রিন্স কিচেনে আসা দরকার ছিল তো।
[13:11.833] Speaker 2: প্রিন্স কিচেনে?
[13:12.443] Speaker 2: ওহ হ্যাঁ।
[13:12.753] Speaker 2: আমি ভাই ওই যে, ভাইয়া যেটা হইছে আমাকে সংসার অনেক, সংসার আর অফিস...
[13:16.293] Speaker 1: মানে তুমি তো আমার সাথে কথা বললে তো বোর হইতা না।
[13:18.153] Speaker 1: আমি তোমারে একেবারে প্রশ্ন করতেই থাকতাম, তুমি বলতেই থাকতা।
[13:20.593] Speaker 2: হ্যাঁ হ্যাঁ হ্যাঁ।
[13:20.893] Speaker 1: তুমি ভুল মানুষরে...
[13:21.843] Speaker 2: হ্যাঁ, আর আমার এমনি অনেক উত্তরও, আপনার কাছ থেকেও অনেক উত্তর আমার জানার ছিল।
[13:24.713] Speaker 2: তো মানে ভালোই হতো।
[13:26.063] Speaker 2: ইনশাআল্লাহ আসতে হবে ভাইয়া।
[13:27.133] Speaker 1: হ্যাঁ।
[13:27.523] Speaker 1: তো যাই হোক, বলতে থাকো।
[13:28.843] Speaker 2: হ্যাঁ।
[13:29.133] Speaker 2: তো কোথা থেকে বলতেছিলাম যেন?
[13:31.253] Speaker 2: তো
[13:31.953] Speaker 2: এই যে হিউম্যান সেন্ট্রিক ডিজাইন আর হচ্ছে টেকনোলজিক্যাল যে আমার একটা, মানে আমি ওই যে কোডার না, বাট আই নো দা মানে জিস্ট আর কি।
[13:39.993] Speaker 2: মানে পিছনের যে ব্যাপারগুলা, ওইগুলা আমি মোটামুটি সবই জানি।
[13:42.223] Speaker 2: এইখান থেকে আমি আপনাকে আরেকটা জিনিস বলি,
[13:44.913] Speaker 2: চারদিন আগে
[13:46.043] Speaker 2: চ্যাট জিপিটি
[13:47.383] Speaker 2: একটা টুল লঞ্চ করছে,
[13:49.673] Speaker 2: টিম যেটা প্ল্যান ওদের, ওইটা নাম হচ্ছে কোডেক্স।
[13:52.883] Speaker 2: কোডেক্স ওয়ান মডেল এটা।
[13:54.673] Speaker 2: সো এটা যারা চ্যাট জিপিটির টিম প্ল্যান চালায়, আমি আপনি তো প্রো প্ল্যান চালাই।
[13:58.333] Speaker 2: মানে ওই যে ২৫ ডলারের যেটা।
[14:00.223] Speaker 2: আরেকটা আছে ২০ ডলারের।
[14:01.813] Speaker 2: ২০ ডলার বাংলায় কনভার্ট করলে ২৭০০ বা এরকম আসে।
[14:03.953] Speaker 1: আড়াই হাজার।
[14:04.573] Speaker 2: আড়াই হাজার।
[14:05.153] Speaker 2: এর পরের ভার্সন যেটা হচ্ছে টিম প্ল্যান।
[14:07.133] Speaker 2: টিম প্ল্যান হচ্ছে আপনার কত, এই ৩০ ডলার করে দুইটা একাউন্ট নেয়া লাগে এটলিস্ট।
[14:12.013] Speaker 2: মানে এটা হচ্ছে কোম্পানিগুলার জন্য করছে আর কি।
[14:13.913] Speaker 2: এখানে কিছু বাড়তি সুবিধা আছে।
[14:14.993] Speaker 2: তার মধ্যে যে একটা জিনিস ওরা লঞ্চ করছে, কোডেক্স।
[14:17.843] Speaker 2: এই কোডেক্সের কাজ কী?
[14:19.333] Speaker 2: আমি নিজে এটা ট্রাই করে বলতেছি,
[14:21.843] Speaker 2: কোডেক্স হচ্ছে
[14:23.013] Speaker 2: আপনি একটা কোড বেজ ওকে কানেক্ট করে দিবেন।
[14:25.293] Speaker 2: অনলাইনে যে কোড বেজ রাখে, ওইটাকে বলে হচ্ছে গিটহাব।
[14:27.763] Speaker 2: গিটহাবে সফটওয়্যারের মেইন কোডগুলা থাকে, প্রাইভেটলিও থাকে, পাবলিকলিও থাকে।
[14:32.483] Speaker 2: মানে সফটওয়্যার যে মেইনটেইন, ম্যানেজমেন্ট, এইটার কোর যে টেকনোলজি, ওইটা হচ্ছে গিটহাব।
[14:38.933] Speaker 2: কোডেক্স গিটহাবের সাথে কানেক্ট করা।
[14:40.853] Speaker 2: আর এইখানে একটা এজেন্ট আছে, কোডিং এজেন্ট।
[14:44.253] Speaker 2: এই এজেন্টটা
[14:45.983] Speaker 2: OpenAI এর সার্ভারে অটোনোমাস একটা এজেন্ট।
[14:49.343] Speaker 2: মানে আপনার কম্পিউটার লাগবে না।
[14:50.843] Speaker 2: আপনি মোবাইল দিয়ে ওকে কমান্ড দিলে ও হচ্ছে বিশাল বড় একটা কম্পিউটারের পাওয়ার নিয়ে কাজ করতে পারবে।
[14:56.263] Speaker 2: এখন কোডেক্সকে আমি হচ্ছে একটা সফটওয়্যারের এক্সেস দিছি গিটহাবের।
[15:00.953] Speaker 2: দিয়ে বলছি, এইখানে তুমি এই দুইটা নতুন ফিচার এড করো।
[15:03.963] Speaker 2: তো আমি তো এগুলা গত এক বছর ধরেই ঘাটতেছি।
[15:05.653] Speaker 2: আমি মডেলগুলা জানি যে কোন মডেলে কী হয়।
[15:09.133] Speaker 2: যেমন ক্লড নামে একটা আছে, ক্লডের নাম শুনছেন?
[15:10.993] Speaker 1: হ্যাঁ হ্যাঁ হ্যাঁ।
[15:11.373] Speaker 2: ক্লড থ্রি পয়েন্ট সেভেন যেটা, ওইটা হচ্ছে সবচেয়ে পাওয়ারফুল কোডিং মডেল।
[15:16.483] Speaker 2: ওকে?
[15:16.893] Speaker 2: বাট ওইটার পরে এই যে কোডেক্স আসলো।
[15:19.463] Speaker 2: আমি দেখলাম যে ও থ্রি পয়েন্ট সেভেন এর চেয়েও ভালো করে
[15:22.423] Speaker 2: ওই ফিচারগুলা যে করে ফেলছে,
[15:24.403] Speaker 2: দুইটা ফিচার দিছিলাম, একটা ফিচার ভালোমতো করে ফেলছে, কোনো ভুল নাই।
[15:27.603] Speaker 2: সেকেন্ড ফিচারে কিছু জিনিস ভুল হইছে, ওইটা আমি আগে বলার পরে ও আবার ঠিক করে দিছে, ওকে।
[15:32.093] Speaker 2: এটা তো গেল একটা।
[15:33.723] Speaker 2: পাশাপাশি আপনি ওকে পাঁচটা টাস্ক দিতে পারবেন, দশটা দিতে পারবেন।
[15:37.793] Speaker 2: মানে আপনার এই যে সাবস্ক্রিপশনের উপরে বেস করে।
[15:39.633] Speaker 2: এই দশটা আপনি যদি ঘুমায়েও থাকেন,
[15:41.873] Speaker 2: আপনি মোবাইলেও ওকে বলে দিলেন,
[15:43.793] Speaker 2: ও কিন্তু ক্লাউডে এই ফিচারগুলা বানাইতে থাকবে।
[15:47.383] Speaker 2: বানায়া থেকে আপনাকে জানাবে যে "বানাইছি, তুমি টেস্ট করো।
[15:49.623] Speaker 2: টেস্ট করে যদি ওকে হয় তাহলে রিসিভ করে ফেলো।"
[15:52.923] Speaker 2: জাকারবার্গ এই কথা বলছে যে ২০২৫ এর শেষ নাগাদ হইতে হইতে ৫০% কোড
[15:59.203] Speaker 2: ফেসবুকের ৫০% কোড
[16:01.813] Speaker 2: এআই লিখবে।
[16:03.023] Speaker 2: আর কোডেক্স দেখে আমি ওইটার আরও একটা স্নিক পিক পাইছি যে আপনার কী হইতে যাইতেছে।
[16:07.763] Speaker 2: তাহলে এই এজেন্টটাই যখন আরও এডভান্স হয়ে যাবে,
[16:10.903] Speaker 2: অলরেডি যেই এডভান্স, এটা দিয়ে আসলে কমন মানে স্মল বিজনেস লেভেলের যেকোনো
[16:15.543] Speaker 2: মানে সফটওয়্যারের এমভিপি আপনি খুব ভালোমতো রান করতে পারবেন।
[16:18.063] Speaker 2: ওয়ান পার্সন কোম্পানি হিসেবে।
[16:19.893] Speaker 2: এটা আমি নিজে এক্সপেরিয়েন্স করে বলতেছি।
[16:23.013] Speaker 2: এবার আবার একই সাথে হচ্ছে এই যে ক্লড।
[16:25.803] Speaker 2: ক্লড তারপরে আবার এগুলা একটা রেসের মতো চলতেছে ভাইয়া, এআইটা।
[16:28.583] Speaker 2: একটা মানে বড় কোম্পানিগুলার মধ্যে একটা রেসের মতো চলতেছে।
[16:30.983] Speaker 2: কেউ একটা কিছু আজকে করলে কালকে আরেকজন আরেকটা
[16:34.193] Speaker 2: মানে লঞ্চ করে।
[16:35.913] Speaker 2: তো ক্লড হচ্ছে আবার সেখানে অপাস ফোর ওদের একটা মডেল,
[16:39.563] Speaker 2: এইটা আবার কোডেক্সের চেয়েও একটু ভালো।
[16:41.693] Speaker 2: বাট কোডেক্সের মতো ক্লাউডে নাই আর কি।
[16:43.343] Speaker 2: মানে ওইটা হচ্ছে আপনার এনভায়রনমেন্টে, পিসিতে আপনি কাজ করবেন আর কি।
[16:48.064] Speaker 1: ওকে, সো তুমি
[16:48.874] Speaker 1: যে কথাটা তোমার সবচেয়ে পছন্দ, যেটা নিয়ে তুমি আসলে শো করতে চাইছিলা যে, "এই কি মানুষকে রিপ্লেস করবে কিনা?"
[16:55.334] Speaker 1: এবং আমি বলছিলাম যে এটা আমার প্রশ্নটা কেমন পছন্দ না।
[16:58.824] Speaker 1: হুম।
[16:59.084] Speaker 1: কারণ এই প্রশ্নটা ইটসেলফ একটা প্রবলেমেটিক প্রশ্ন।
[17:02.394] Speaker 1: এইজন্য কিন্তু তোমার এই টাইটেলটা আমি গ্রহণ করি নাই।
[17:04.424] Speaker 2: হুম হুম হুম হুম।
[17:05.104] Speaker 1: তারপর তুমি অনেকগুলা টাইটেল দিছো যেগুলো আসলে ওই চ্যাট জিপিটি থেকেই জেনারেট করা।
[17:10.934] Speaker 1: তো আমাকে তুমি বলো যে
[17:12.634] Speaker 1: এইটা তো আরও চার পাঁচ বছর আগে থেকেই ওই মুনির ভাই যখন এই যে তৃতীয়...
[17:18.244] Speaker 1: কী বলে?
[17:18.964] Speaker 1: চতুর্থ শিল্প বিপ্লব এই ধরনের জিনিসপত্র নিয়ে কাজ করতো, ব্লকচেইন-টকচেইন এগুলা নিয়ে লিখতো,
[17:22.954] Speaker 1: তখন থেকেই শুনতেছি যে মানুষ রিপ্লেস হবে, মানুষ রিপ্লেস হবে।
[17:27.244] Speaker 1: তো এটা তো একটা পপুলার কথাই।
[17:29.134] Speaker 1: মানে তোমার এই পপুলার কথা এতদিন পরে মনে হওয়ার কারণটা কী?
[17:31.794] Speaker 1: তুমি লেট বুমার নাকি তুমি এমন কোনো বোধিজ্ঞান লাভ করছো যেটা আসলে ওই মুনির হাসান ভাইরা যখন বলতো তখন লোকজন বুঝে নাই?
[17:39.464] Speaker 2: আমার, আমি উনার আসলে উনার কনটেক্সটা জানি না, উনি কোন কনটেক্সটে এটা বলতো।
[17:42.594] Speaker 2: তো ওইটা আমি পড়লে আমি উনার কনটেক্সটা বলতে পারবো।
[17:45.384] Speaker 2: বাট আমি আপনাকে এতটুকু এশিওর করতে পারি...
[17:46.854] Speaker 1: না, মানে কনটেক্সট বলি নাই, আমি...
[17:47.964] Speaker 2: বুঝছি, আমি আমি বলতেছি ভাইয়া...
[17:49.624] Speaker 1: আউটকামটা বলছি যে...
[17:50.554] Speaker 2: আমি বুঝছি।
[17:51.104] Speaker 2: চতুর্থ শিল্প বিপ্লব বা হিউম্যান রিপ্লেস বা এআই রেভোলিউশন...
[17:54.194] Speaker 1: হ্যাঁ, মানুষ রিপ্লেসড হয়ে যাবে।
[17:55.454] Speaker 1: এই গল্প তো পপুলার হয়ে গেছে অলরেডি।
[17:56.914] Speaker 1: মানে সবাই বলতেছে।
[17:58.214] Speaker 2: রাইট।
[17:58.744] Speaker 2: এইটা মানে হ্যাঁ মানে আমি ওইটাই বলতেছি উনারা কেন বলছো ওইটা আসলে আমি জানি না এবং কেন কীভাবে আগে বলছিল,
[18:03.624] Speaker 2: ওইটাও আমি কনটেক্সটা যদি বুঝি তাহলে হয়তো বলতে পারবো যে আরে উনারা তো অনেক ট্যালেন্টেড
[18:08.774] Speaker 2: যে এই জিনিস এইভাবে বুঝছে।
[18:10.274] Speaker 2: কারণ উনাদের আর্গুমেন্টটা যদি আমি বুঝতে পারি, তাহলে আমার কাছে ওইটাই মনে হবে অবসলি।
[18:13.844] Speaker 1: চতুর্থ শিল্প বিপ্লব, ওইটা তাহলে যোগাড় করে ফেলো।
[18:15.584] Speaker 1: ওটা সম্ভবত তয়েব ভাই না কার লেখা ভুলে গেছি।
[18:17.984] Speaker 1: ফরিদুজ্জামান স্যারের...
[18:18.734] Speaker 2: হ্যাঁ, চতুর্থ শিল্প বিপ্লবের বেজমেন্ট উনারা মানে কয়টা জিনিসকে রাখছে আমি জানি না।
[18:22.254] Speaker 2: যদি আর্টিফিশিয়াল ইন্টেলিজেন্সকে রাখে তাহলে বলতেই হবে যে উনারা আসলে ভিশনারি।
[18:25.294] Speaker 1: না না, ওইটা রাখছে।
[18:26.134] Speaker 2: হ্যাঁ।
[18:26.854] Speaker 2: আর আমার কাছে যেটা, আমার কাছে হচ্ছে জিনিসটা ম্যাটেরিয়ালাইজ হইছে
[18:29.984] Speaker 2: জিপিটি মোমেন্টটার পরে।
[18:31.784] Speaker 2: কেন?
[18:32.184] Speaker 2: আমি আপনাকে বলি মানে এইটা হচ্ছে ইন্টেলিজেন্স রেভোলিউশন হবে ভাইয়া।
[18:35.424] Speaker 2: এজ অফ ইন্টেলিজেন্স, অলরেডি বড় বড় লোকজন বলতেছে এটা।
[18:38.904] Speaker 2: মানে এই রেভোলিউশনটা অন্য কোনো কিছুর না, এটা হচ্ছে ইন্টেলিজেন্স।
[18:43.604] Speaker 2: মানে হিউম্যানের যেই স্পেশালিটি,
[18:46.424] Speaker 2: কোন ক্ষেত্রে বলতেছি?
[18:47.664] Speaker 2: ইকোনমিক্যাল টাস্কের ক্ষেত্রে।
[18:49.664] Speaker 2: ইমোশনাল এটাচমেন্টের ক্ষেত্রে বলতেছি না।
[18:51.524] Speaker 2: যে ইকোনমিক্যাল যে নিড হিউম্যানের,
[18:53.944] Speaker 2: কথার কথা এখন ইকোনমিক্যাল নিডের ক্ষেত্রে সবচেয়ে বেশি নিড কাদের হয়?
[18:57.644] Speaker 2: ধরেন স্পেশালিস্টদের হয়।
[18:59.734] Speaker 2: স্পেশালিস্ট যারা, যে ডাক্তারদের মধ্যে স্পেশালিস্ট যারা, বা ধরেন টেকনোলজিক্যাল কোনো কোম্পানির ক্ষেত্রে সিটিও যে,
[19:06.594] Speaker 2: এইভাবেই তো সবচেয়ে বেশি ইয়ে হয়।
[19:07.824] Speaker 2: কেন হয়?
[19:08.564] Speaker 2: বিকজ উনার হচ্ছে ইন্টেলিজেন্সটা প্লাস ওই সেক্টরের যে জ্ঞানটা,
[19:13.914] Speaker 2: এই জ্ঞানটার উনার মধ্যে একটা আলাদা
[19:17.384] Speaker 2: মানে একটা প্যাটার্ন তৈরি হইছে।
[19:18.914] Speaker 2: যে উনার ইন্টেলিজেন্স প্লাস হচ্ছে কন্টেক্সচুয়াল নলেজ।
[19:22.094] Speaker 2: এই দুইটা মিলায়েই তো মানুষের এক্সপার্টাইজ হয়।
[19:24.034] Speaker 2: ওই কারণে এই লোকটাকে তিন লাখ টাকা, পাঁচ লাখ টাকা...
[19:26.974] Speaker 2: সিইও এর কথাও যদি বলি,
[19:27.794] Speaker 1: হুম।
[19:28.914] Speaker 2: ওই কারণে তো এই লোকটাকে রাখে বড় বড় কোম্পানির লোকজন।
[19:32.744] Speaker 2: এখন ওই যে রাখে, এই যে ডিসিশন মেকিং এর প্রসেস,
[19:35.794] Speaker 2: এই জায়গাটাই হচ্ছে
[19:38.074] Speaker 2: মানে জিপিটি মোমেন্ট আর আর্টিফিশিয়াল ইন্টেলিজেন্সের যে বুম, মানে এআই যে রেভোলিউশন বলতেছি।
[19:42.824] Speaker 2: রেভোলিউশনটা হবে আসলে ইন্টেলিজেন্স লেয়ারে।
[19:45.394] Speaker 2: মানে ব্রেইন লেয়ারে।
[19:47.384] Speaker 2: মানে ইকোনমিক্যাল যে ব্রেইন, এইখানে যত জায়গায় মানুষের দরকার,
[19:51.684] Speaker 2: কেন দরকার?
[19:52.744] Speaker 2: কারণ রোবট ধরেন ইন্টেলেকচুয়াল কনটেক্সট এওয়ার ডিসিশন নিতে পারে না, কাজ করতে পারে না।
[19:57.694] Speaker 2: এইটা এখন যেই টেকনোলজি আছে,
[19:59.954] Speaker 2: এইটা দিয়েই পসিবল।
[20:01.374] Speaker 2: মানে চ্যাট জিপিটি এখন যে লেভেলে আছে বা জেমিনাই গুগলের, যে লেভেলে আছে, এইটা দিয়েই
[20:05.474] Speaker 2: আপনি ধরেন একটা কোম্পানির সবচেয়ে বড় যে সিটিও,
[20:08.644] Speaker 2: ওকে রিপ্লেস করে ফেলতে পারবেন।
[20:09.904] Speaker 2: কীভাবে?
[20:10.964] Speaker 2: এক নাম্বারে হচ্ছে ইন্টেলিজেন্স তো আছেই, আর ওই কোম্পানির সমস্ত নলেজ যদি আপনি ওকে দিয়ে দেন,
[20:15.544] Speaker 2: তাহলেই কিন্তু এই প্রবলেম আর নাই।
[20:17.904] Speaker 2: প্রবলেমটা কোথায় আছে এখন পর্যন্ত?
[20:19.464] Speaker 2: মানে ইন্টেলিজেন্স যে জায়গায় আটকায় আছে, সেটা হচ্ছে যে ইনোভেশন লেয়ারে।
[20:22.794] Speaker 2: বাট ওইখানেও ধরা শুরু করছে টুকটাক, সাইন্টিস্টদের যে ইন্টেলিজেন্স বা ইয়ে।
[20:26.964] Speaker 2: বাট আপনি যদি মোটা দাগে বা আমি যদি মোটা দাগে পুরা পৃথিবীর গড় ইন্টেলিজেন্সের যে চাহিদা,
[20:32.724] Speaker 2: ডিসিশন মেকিং এর যে এক্সপার্টাইজ,
[20:35.884] Speaker 2: এইটার চাহিদার কথা বলি,
[20:37.754] Speaker 2: এইটা করতে যতটুকু কগনিটিভ ব্যান্ডউইথ বা ইন্টেলিজেন্স বলি,
[20:42.064] Speaker 2: ওইটা অলরেডি, মানে আরও সাত আট মাস, এক বছর আগেই
[20:46.064] Speaker 2: এই যে এআই টুলগুলা,
[20:47.644] Speaker 2: এরা এচিভ করে ফেলছে।
[20:49.494] Speaker 2: আমার উদাহরণস্বরূপ বলা যেতে পারে যে অনেক বেঞ্চমার্ক টেস্ট আছে আর কি আপনি যেগুলা দিয়ে এগুলা মাপে।
[20:53.304] Speaker 2: তো ওইটা এবং আমি নিজে এটার প্রমাণ।
[20:55.224] Speaker 2: মানে যে বুয়েটের কোশ্চেন, বুয়েটের কোশ্চেনের অ্যানসার, তারপর হচ্ছে ধরেন ম্যাথমেটিক্সের কমন যে কোশ্চেন বা অলিম্পিয়াডের যে টেস্ট থাকে,
[21:04.284] Speaker 2: মানে অলিম্পিয়াডে পার্টিসিপেট করার জন্য যেই প্রশ্নগুলা হয়,
[21:07.974] Speaker 2: ওইগুলার অ্যানসার এখন দিয়ে দিতে পারে।
[21:11.394] Speaker 2: তো ওই জায়গা থেকে ভাইয়া যে...
[21:12.634] Speaker 2: তো আমাকে কেন আপনি প্রশ্নটা করছিলেন যে আমি কেন এটা দেরি করে বুঝলাম?
[21:15.934] Speaker 2: এটাই তো?
[21:16.294] Speaker 2: সো আমি ওই বইটা, মানে শিল্প বিপ্লব রিলেটেড বই পড়ি নাই, এক নাম্বারে।
[21:20.194] Speaker 2: আর দুই নাম্বারে আপনার সোশ্যাল মিডিয়া বা ইন্টারনেট, ইভেন ব্লকচেইনকেও
[21:24.784] Speaker 2: আমার হলিস্টিক্যালি,
[21:28.024] Speaker 2: হলিস্টিক্যালি কখনো এইরকম টেকনোলজি মনে হয় নাই।
[21:30.594] Speaker 2: ব্লকচেইন, ব্লকচেইন সর্বোচ্চ কী করবে?
[21:32.324] Speaker 2: ফিনান্সিয়াল মার্কেটকে রেভোলিউশনাইজ করবে, মেবি।
[21:35.254] Speaker 2: সোশ্যাল মিডিয়া, ইন্টারনেট,
[21:37.284] Speaker 2: ইন্টারনেট যেমন একটা রেভোলিউশন করছে মানুষকে, যে ধরেন ডিজিটাল রেভোলিউশন যেটাকে বলতেছি, অ্যাক্সেসিবিলিটির যে রেভোলিউশন ঘটাইছে।
[21:42.864] Speaker 2: মানে এটা হিউম্যানের একদম ধরেন সবচেয়ে গরিব যে লোকটা,
[21:47.234] Speaker 2: সেই লোকটা আর ধরেন বিল গেটস,
[21:49.774] Speaker 2: এই সবগুলো মানুষকে টাচ করবে, মাঝখানে যতজন আছে।
[21:52.894] Speaker 2: এইরকম টেকনোলজি আমার কিন্তু ব্লকচেইনকেও মনে হয় নাই,
[21:55.454] Speaker 2: আমার কিন্তু ওই যে সোশ্যাল মিডিয়া,
[21:58.824] Speaker 2: ইভেন টেসলার যে গাড়ি, এগুলাকেও মনে হয় নাই।
[22:02.324] Speaker 2: কেন?
[22:02.834] Speaker 2: টেসলার যে গাড়ি বানাইছে, ভালো বানাইছে।
[22:04.994] Speaker 2: কিন্তু এই অটোনোমাস রোবট তো আমাকে ধরেন এই যে বাংলাদেশের কোনো একটা অফিসের যে কাজকর্ম, এটাকে মানে ইন্টেলিজেন্স এটার মধ্যে কাজে লাগায় দিতে পারবে না।
[22:15.654] Speaker 2: কিন্তু ইন্টারনেট যেমন পুরা পৃথিবীর সব জায়গায়...
[22:17.654] Speaker 2: কম্পিউটার একটা ভালো উদাহরণ।
[22:19.464] Speaker 2: কম্পিউটার যেমন মানে একটা সারভাইভাল স্কিল হয়ে গেছিল।
[22:22.954] Speaker 2: কম্পিউটার যেমন সবাইকে ইউজ করতে হয়েছে বা সবার জীবনেই প্রবেশ করবে।
[22:26.964] Speaker 2: এক্সেপ্ট করি বা না করি।
[22:28.274] Speaker 2: ইভেন ধরেন গ্রামের যে চাষিটা আছে,
[22:31.424] Speaker 2: ওর জীবনেও কিন্তু কম্পিউটার কানেক্ট হইছে কীভাবে?
[22:33.914] Speaker 2: আপনার যে যে কোম্পানিটা ধরেন ওর কাছ থেকে প্রোডাক্ট অর্ডার নিতেছে, ওই কোম্পানির পুরা অফিস চলে কম্পিউটার দিয়ে।
[22:39.914] Speaker 2: ঠিক এই একইভাবে ব্লকচেইনের যে মালিক হোক বা সোশ্যাল মিডিয়ার যে ইউজার হোক, এদের সবাইকে প্লাস বাংলাদেশের প্রত্যন্ত অঞ্চলের যে মফস্বলের ছেলেটা,
[22:49.794] Speaker 2: এদের সবার জীবনকে
[22:52.204] Speaker 2: মানে জীবনকে ডিফাইন করবে বলতে গেলে।
[22:54.024] Speaker 2: সোশ্যাল ফ্যাব্রিক যেটা,
[22:56.244] Speaker 2: ওই ফ্যাব্রিকটাকে হচ্ছে
[22:58.744] Speaker 2: এই যে LLM,
[23:00.084] Speaker 2: আর্টিফিশিয়াল জেনারেটিভ এআই, মানে এআই কিন্তু আগেও ছিল, অনেক প্যাটার্নের ছিল।
[23:04.144] Speaker 2: কিন্তু জেনারেটিভ এআই যেটা, জিপিটি,
[23:06.844] Speaker 2: এইটা হচ্ছে আপনার
[23:09.114] Speaker 2: এই লেয়ারগুলাকে ডিফাইন করবে।
[23:11.594] Speaker 2: তো সেই জায়গা থেকে মানে কম্পিউটার ইন্টারনেট চালানো যেমন একটা মাস্ট স্কিল বা যেই চাষিটা ইন্টারনেট চালাইতে পারে আর যেই চাষিটা পারে না,
[23:20.404] Speaker 2: এদের মধ্যে যেই পার্থক্য,
[23:22.254] Speaker 2: এআই এর পার্থক্য তার চেয়েও অনেক বেশি হবে।
[23:24.404] Speaker 2: কারণ
[23:26.474] Speaker 2: মানে এআই ইউজ করতে পারা মানে আসলে কাইন্ড অফ ভাইয়া আইনস্টাইনকে ইউজ করতে পারা।
[23:30.734] Speaker 2: আমি একটু বাড়ায় বলতেছি,
[23:32.064] Speaker 2: আইনস্টাইন লেয়ারে এখনো যায় নাই।
[23:33.724] Speaker 2: কিন্তু ধরেন পিএইচডি, হার্ভার্ডে পিএইচডি করতেছে
[23:37.894] Speaker 2: এইরকম এক যদি ৫০টা মানুষ আমার পকেটে থাকে বা পকেটে বিশ্রী শোনাইতেছে,
[23:42.844] Speaker 2: আমার পাশে বসে থাকে,
[23:44.224] Speaker 2: তাকে আমি জিজ্ঞেস করতে পারি যে আমার এই প্রবলেম, এটা কী করব?
[23:47.534] Speaker 2: আমার জীবনটা এভাবে চলতেছে, এটা কী করব?
[23:49.324] Speaker 2: বা আমি আসলে জীবনে এইটা এচিভ করতে চাই, আমি কী করব?
[23:53.644] Speaker 2: এইটা এখনই ফ্রিতে পসিবল।
[23:56.744] Speaker 2: লিমিট হয়তো হয়ে যাবে।
[23:58.554] Speaker 2: যেমন জেমিনাই এর যে পাওয়ারফুল মডেলগুলা, ওগুলা ফ্রি।
[24:01.374] Speaker 2: চ্যাট জিপিটির পাওয়ারফুল মডেলগুলা একটু ওই পেমেন্ট ওয়ালের মানে ওইপাশে, সাবস্ক্রিপশন।
[24:06.914] Speaker 2: তাইলে এইটা একটা মানে, এইটা মানে আমি বলতে চাইতেছি যে ধরেন মফস্বলের একটা ছেলে,
[24:12.634] Speaker 2: যেই ছেলেটা ধরেন যার কাছে পড়তেছে বা ইউটিউবেও যে ভিডিও দেখতেছে,
[24:17.824] Speaker 2: সেখানে সে দেখতে পারতেছে
[24:19.984] Speaker 2: এই ধরেন স্ট্যানফোর্ডের একটা টিচারের লেকচার দেখতে পারতেছে।
[24:23.014] Speaker 2: বাট এখন সে পৃথিবীর যতগুলা স্ট্যানফোর্ডের টিচার আছে, এদের যে ইন্টেলিজেন্স দিয়ে তাকে পড়াইতে পারবে,
[24:29.624] Speaker 2: সেই পড়ানোটা সে তার স্টাইলে নিতে পারবে।
[24:32.484] Speaker 2: মানে সে...
[24:33.884] Speaker 1: সবই তো
[24:34.904] Speaker 1: যেটা তুমি বলতেছো,
[24:36.004] Speaker 1: মানে হইলো যে
[24:37.664] Speaker 1: আমি যদি ইনপুট দেই,
[24:39.814] Speaker 1: হুম।
[24:40.064] Speaker 1: তুমি তো সব আউটপুটের কথা বলতেছো।
[24:42.104] Speaker 2: হুম।
[24:42.664] Speaker 1: কিন্তু আমার যে কী ইনপুট দেয়া দরকার,
[24:45.334] Speaker 2: হ্যাঁ।
[24:46.684] Speaker 1: সেইটা
[24:48.334] Speaker 1: সেইটা কি আমাকে এআই বলে দিতে পারতেছে?
[24:50.984] Speaker 2: কী ইনপুট দেয়া দরকার বলতে কী বুঝাচ্ছেন আপনি?
[24:52.794] Speaker 1: মানে ধরো তুমি বলতেছো যে তুমি এই স্ট্যানফোর্ডের একজন লেকচারার যে স্টাইলে পড়ায়,
[24:59.884] Speaker 1: তুমি এআই এর মাধ্যমে সেই জিনিসটাই তুমি অটো পেয়ে যাচ্ছো।
[25:04.094] Speaker 2: হুম।
[25:05.154] Speaker 1: কিন্তু আমার প্রশ্নটা হচ্ছে যে তুমি স্ট্যানফোর্ডের ওই যে ইউনিভার্সিটি ওই যে প্রফেসর,
[25:11.234] Speaker 1: তোমার যে আসলে এইটাই নিড,
[25:13.914] Speaker 1: এই ইনপুটটা তুমি যে দিবা, সেই ডিসিশন মেকিংটা, এই ডিসিশন মেকিংটা কি এআই তোমাকে করে দিতে পারবে?
[25:20.674] Speaker 1: নাকি সেই ডিসিশন মেকিংটা তো তোমার নিজেরই করতে হচ্ছে?
[25:22.954] Speaker 2: এইটা হচ্ছে মানুষের যে...
[25:24.084] Speaker 1: সো আমি আমি মূলত ইনপুটের জায়গাটাতে জোর দিছি যে...
[25:26.544] Speaker 2: হুম।
[25:27.914] Speaker 1: মানুষ যেরকম সে কী চিন্তা করবে সেটা সে নিজে নিজে ডিসাইড করতে পারে।
[25:31.964] Speaker 2: হুম।
[25:32.484] Speaker 1: তাই না?
[25:32.964] Speaker 2: পারে কি?
[25:34.614] Speaker 1: মানে তোমার এখন কী দরকার?
[25:36.194] Speaker 1: তুমি অন্তত তিন-চারটা অপশন তো তোমার মাথায় আসে।
[25:38.634] Speaker 2: হুম হুম।
[25:39.064] Speaker 1: তারপর না তুমি কারো সাজেশনে ডিসিশনটা নাও।
[25:41.654] Speaker 2: হুম।
[25:41.874] Speaker 1: কিন্তু প্রথম যে ইটা, ট্রিগারটা, সেই ট্রিগারটা তো তোমার নিজের থেকেই জেনারেট করতে হয়।
[25:46.074] Speaker 2: জেনারেট করতে হয়, বাট এটাকে শেইপ করছে সোসাইটি, আমার চারপাশ,
[25:48.974] Speaker 2: এটা ছোট থেকে এই পর্যন্ত...
[25:49.914] Speaker 1: সো তোমার তোমার যে স্টাডি, সেই স্টাডিতে কী বলে?
[25:52.894] Speaker 1: মানে এআই কি এখন ওই লেভেলে আসছে যে আমার ইনপুটটাও সে নিজে নিজে জেনারেট করে দিতে পারবে?
[25:58.264] Speaker 2: হ্যাঁ, যদি আমি তাকে এনাফ ইনফরমেশন ফিড করতে পারি
[26:02.504] Speaker 2: এবং তারপরে তাকে এই দায়িত্বটা দেই।
[26:03.954] Speaker 2: এআই কিন্তু এখনো অটোনোমাস না।
[26:05.804] Speaker 2: মানে আমি কানেক্ট করে ফেললাম, এবার ও নিজে থেকেই সব বুঝে আমার জীবনকে ডিসাইড করে ফেললো, নট দ্যাট।
[26:11.104] Speaker 2: আমি কানেক্ট করলাম, করে ওকে আমি একটা টাস্ক দিলাম,
[26:14.994] Speaker 2: এরপরে ও ওইটা করবে।
[26:15.864] Speaker 2: এখন এই টাস্কটা করতে গেলে মানুষজন যেটা সবচেয়ে বেশি মানে আমি যেটা দেখছি আশেপাশের মানুষজনের ক্ষেত্রে মিস করে যায়, সেটা হচ্ছে কনটেক্সট এওয়ারনেস অনেক গুরুত্বপূর্ণ।
[26:24.224] Speaker 2: মানে আমি যদি পৃথিবীর সবচেয়ে ভালো আমেরিকান ডক্টরটাকে
[26:29.404] Speaker 2: আপনার বাংলাদেশের গ্রামে বসায় দেই, সে কিন্তু ট্রিট করতে পারবে না।
[26:32.744] Speaker 2: কেন?
[26:32.924] Speaker 2: কারণ ল্যাঙ্গুয়েজ পারে না।
[26:34.204] Speaker 2: বাট সে কিন্তু সবচেয়ে স্মার্ট।
[26:36.164] Speaker 2: ওই জায়গা থেকে যেকোনো এআইকে
[26:38.834] Speaker 2: লিমিটেশনটা আসলে হিউম্যানের এখন, মেজরিটি ক্ষেত্রে আমাদের, ইনপুটের ক্ষেত্রে।
[26:42.924] Speaker 2: আমরা আসলে এনাফ নলেজ, কনটেক্সট, মানে ঘটনার কনটেক্সট
[26:47.334] Speaker 2: ওকে যদি দেই, দেয়ার পরে রাইট কোয়েশ্চেনটা করতে পারি।
[26:49.774] Speaker 2: চ্যাট জিপিটির যে ফাউন্ডার মানে স্যাম অল্টম্যান, ওকে জিজ্ঞেস করছিল যে ভবিষ্যৎ পৃথিবীর সবচেয়ে পাওয়ারফুল স্কিলগুলা কী হবে?
[26:56.844] Speaker 2: তার মধ্যে সে একটা বলছে "আমি আসলে শিউর না, বাট কোয়েশ্চেনিং এবিলিটি,
[27:01.324] Speaker 2: মানে প্রোবিং আর কি, মানে কোয়েশ্চেনিং করার যে পাওয়ারফুল কোয়েশ্চেন করতে পারা,
[27:06.144] Speaker 2: মানে অ্যানসারের চেয়েও, এই যে এটা আপনি একটা পাওয়ারফুল জায়গা ধরছেন আর কি।
[27:08.994] Speaker 2: যে অ্যানসারের চেয়েও আসলে প্রশ্ন করতে পারার ক্যাপেবিলিটি অনেক বেশি দরকার হবে।
[27:14.074] Speaker 1: প্রশ্ন করাটাই তো গুরুত্বপূর্ণ।
[27:14.914] Speaker 1: উত্তর তো কিছু না কিছু একটা দেয়া দেওয়া যায়।
[27:16.294] Speaker 2: হ্যাঁ, বাট এতদিন পর্যন্ত কিন্তু আমাদের প্রিভিয়াস যে ওয়ার্ল্ড, ওই ওয়ার্ল্ডে কিন্তু উত্তর দিতে পারাকেই
[27:22.094] Speaker 2: প্রায়োরিটাইজ, গ্লোরিফাই করা হইছে।
[27:23.714] Speaker 2: কিন্তু স্যাম অল্টম্যান বলতেছে যেহেতু উত্তর এখন রেডিমেড এভেইলেবল, কাস্টোমাইজড, পার্সোনালাইজড ওয়েতে এভেইলেবল,
[27:29.624] Speaker 2: এখন হচ্ছে প্রশ্ন করাটা, এটাও বলছে।
[27:31.424] Speaker 2: বাট শিউরিটি দিয়ে বলে নাই, বাট বলছে যে এইগুলা থাকবে।
[27:34.504] Speaker 2: মানে যে যত পাওয়ারফুল কোশ্চেন করতে পারবে, সে তত বেটার
[27:38.994] Speaker 2: ইয়ে করবে আর কি।
[27:40.974] Speaker 2: মানে আউটপুট পাবে।
[27:42.064] Speaker 2: এটা ফর শিউর।
[27:43.204] Speaker 2: কিন্তু আমি যেটা বলতেছিলাম সেটা হচ্ছে যে আপনি যেই কোশ্চেনের অ্যানসার চাচ্ছেন,
[27:48.094] Speaker 2: বেশিরভাগ মানুষের তো ভাইয়া এটাই প্রবলেম তাই না?
[27:49.524] Speaker 2: মানে আমিও এই যে চাকরি-বাকরি করে, সংসার করে,
[27:52.924] Speaker 2: তারপরে হতাশ থেকে আমি আসলে যে জিনিসটা বুঝছি,
[27:55.794] Speaker 2: সেটা হচ্ছে মেজরিটি আসলে ডিস্ট্র্যাক্টেড ভাইয়া, মানে...
[27:58.744] Speaker 2: মেজরিটি ডিস্ট্র্যাক্টেড।
[28:01.094] Speaker 2: মানুষ আসলে ডিস্ট্র্যাকশনের কারণে নিজের গন্তব্যের দিকে তাকাইতেই পারে না।
[28:06.124] Speaker 2: হোয়ার ডু আই ওয়ান্ট টু গো?
[28:07.724] Speaker 2: এই কোয়েশ্চেনটাই মেজরিটি মানুষ করতেই পারে না।
[28:09.624] Speaker 2: বা যদি করেও ফেসবুকের একটা নোটিফিকেশন বা
[28:13.984] Speaker 2: ধরেন প্রেমিকার একটা...
[28:15.934] Speaker 2: যদিও প্রেম জিনিসটা ঠিক না।
[28:16.894] Speaker 2: বাট প্রেমিকার একটা উদাহরণ হিসেবে বলতেছি,
[28:19.984] Speaker 2: বিয়ের পরে প্রেম ঠিক আছে।
[28:22.254] Speaker 1: যাক, তুমি এখন এই আলাপ তুইলো না।
[28:23.514] Speaker 1: আমি এআইতে থাকবো...
[28:24.464] Speaker 2: হ্যাঁ।
[28:24.894] Speaker 2: তো তো প্রেমিকার একটা ফোন কল
[28:27.274] Speaker 2: মানুষকে হচ্ছে তার গন্তব্য থেকে প্রচুর ডিস্ট্র্যাক্টেড করে রাখে।
[28:32.064] Speaker 2: মানুষের আসলে এই ডিস্ট্র্যাকশন থেকে যদি মানুষ মানে মুক্ত হতে পারে, মানে অনেক...
[28:37.334] Speaker 1: এআই নিজেও কি একটা ডিস্ট্র্যাকশন না?
[28:38.254] Speaker 1: মানে তোমার তো এটা ডিভাইসে ঢুকে ঢুকে ওইটা নিয়েই থাকতে হবে।
[28:40.194] Speaker 2: ১০০%।
[28:41.244] Speaker 2: ১০০%, ইভেন এইটা কী করবে ভাইয়া জানেন?
[28:43.244] Speaker 2: মানে অনেকটা আমার কাছে যেটা ধারণা আর কি বা মানে বড় বড় লোকজন বলতেছে...
[28:46.744] Speaker 1: তাহলে তুমি ডিস্ট্র্যাকশনের এঙ্গেলটা আনতেছো কেন?
[28:48.244] Speaker 2: ডিস্ট্র্যাকশনের এঙ্গেলটা আমি আনতেছি যেটা ট্রু।
[28:50.914] Speaker 2: আমি কিন্তু অলওয়েজ মানে আমার আন্ডারস্ট্যান্ডিং এ যেটাকে ভ্যালু মনে হয় মানে ট্রুথ মনে হয়,
[28:56.034] Speaker 2: ওইটা তো মানে বলবই।
[28:57.694] Speaker 2: মানে ভ্যালুজের জায়গা থেকে আমার তো ডিস্ট্র্যাকশন জিনিসটা
[29:00.674] Speaker 2: ভালো না আর কি।
[29:01.294] Speaker 2: মানে ডিস্ট্র্যাকশনও মানুষের জীবনের একটা বড়,
[29:03.624] Speaker 2: মানে মানুষের যে প্রপার
[29:05.974] Speaker 2: ম্যানিফেস্টেশন,
[29:07.824] Speaker 2: একটা মানুষের যে পটেনশিয়াল, এটার যে ট্রু ম্যানিফেস্টেশন, ওইটার পথের
[29:11.754] Speaker 2: সবচেয়ে বড় বাধাগুলোর একটা হচ্ছে ডিস্ট্র্যাকশন।
[29:15.004] Speaker 2: তো ওই জায়গা থেকে প্রশ্ন কেন মানুষ করতে পারে না বা
[29:18.994] Speaker 2: মানুষ কেন আসলে
[29:21.054] Speaker 2: এই যে এআইকে কেন সে ঠিক কোশ্চেনটা করতে পারবে না,
[29:23.774] Speaker 2: এইটা হচ্ছে তার ওই ডিস্ট্র্যাকশনের কারণে আর কি।
[29:25.794] Speaker 2: মানে এনাফ টাইম নিয়ে একটা মানুষ যদি নিজের জীবন হোক বা যেকোনো সমস্যা নিয়ে সে যদি
[29:32.224] Speaker 2: এনাফ টাইম নিয়ে ফোকাস হতে চেষ্টা করে,
[29:35.324] Speaker 2: মানে ফিজিক্যাল মানে ফিজিক্সের যে থিওরাম, ওই থিওরামের মধ্যে থাকলে তো আসলে ওগুলা সলভেবলই।
[29:40.594] Speaker 2: ইভেন আইনস্টাইন তো থিওরি অফ রিলেটিভিটিও সে পাইছে।
[29:43.324] Speaker 2: তখন তো ওটা আসলে
[29:45.024] Speaker 2: প্র্যাকটিক্যালি আসলে ওই থিওরি
[29:47.334] Speaker 2: ইয়ে ছিল না।
[29:48.014] Speaker 2: তো ওই জায়গা থেকে
[29:49.494] Speaker 2: দুইটা পয়েন্ট, একটা হচ্ছে কনটেক্সটের এওয়ারিড দিতে হবে।
[29:51.344] Speaker 2: আপনি যদি প্রশ্নটা জানেন, আপনি যদি সমস্যাটা জানেন, সেই সমস্যাটার ব্যাপারে আপনি এআইকে যত বেশি কনটেক্সচুয়াল নলেজ দিতে পারবেন, ও আপনাকে তত বেটার সলিউশন দিতে পারবে।
[30:02.504] Speaker 2: আর ওই যে বললাম চিন্তা করার ক্ষমতায় ওরা এখনই ম্যাথ অলিম্পিয়াডে যাইতে পারবে এতটুকু স্মার্ট।
[30:08.064] Speaker 2: আর গোপনে গোপনে বড় কোম্পানিগুলার কাছে আরও বেটার মডেল আছে।
[30:12.184] Speaker 2: ধরেন চ্যাট জিপিটির কাছে,
[30:13.914] Speaker 2: চায়না আর আমেরিকার যে রেস চলতেছে,
[30:16.894] Speaker 2: সরি।
[30:17.374] Speaker 2: এই রেস তো পলিটিক্যাল বা অন্য সব কিছু আছেই।
[30:19.514] Speaker 2: একটা বড় পার্ট হচ্ছে এআই রেস।
[30:21.284] Speaker 2: এই কারণে ওই যে ডিপসিক...
[30:22.524] Speaker 1: ডিপসিক, হ্যাঁ।
[30:22.954] Speaker 2: ডিপসিক হচ্ছে ওই কারণেই আপনার, মানে ডিপসিক দিয়ে চায়না একটু মানে জগৎকে বুঝাইছে যে আমরাও আছি রেসে।
[30:28.184] Speaker 2: বাট ওরা কিন্তু রেসে একটু পিছনে।
[30:30.224] Speaker 1: কিন্তু ডিপসিক চ্যাট জিপিটির চেয়ে আগায় গেছে না?
[30:31.954] Speaker 2: না, আগায় যায় নাই।
[30:33.264] Speaker 2: ডিপসিক হচ্ছে ওপেন সোর্স করছে এই টেকনোলজিটাকে।
[30:36.564] Speaker 2: ওপেন সোর্স করছে প্লাস হচ্ছে
[30:38.864] Speaker 2: এআই এর যে টেকনোলজিটা, এই টেকনোলজিটা অনেক বেশি ওই প্রসেসিং পাওয়ার লাগে, জিপিইউ।
[30:45.834] Speaker 2: তো এইজন্য অনেক খরচ হয়।
[30:48.334] Speaker 2: ডিপসিক যেটা করছে সেটা হচ্ছে যে অল্প খরচে
[30:52.694] Speaker 2: ধরেন চ্যাট জিপিটি লেভেলের ইন্টেলিজেন্স নিয়ে আসছে।
[30:56.094] Speaker 2: বাট ফ্রন্টিয়ার যে মডেল, আমি রেসের একদম সামনে যে এআইটা, ওই এআইটা এখনো চ্যাট জিপিটির কাছেই আছে, এখন পর্যন্ত।
[31:05.114] Speaker 2: মানে এটা আমি পার্সোনাল এক্সপেরিয়েন্স থেকেও বলতেছি, আর হচ্ছে ইন্ডাস্ট্রির যে স্ট্যান্ডার্ড রিপোর্ট, ওইটার উপরেও বলতেছি।
[31:10.984] Speaker 2: প্রোগ্রামিং এরটা আছে ক্লডের কাছে।
[31:12.874] Speaker 2: বাট ওভারঅল যে এআই, ওইটা জিপিটির কাছেই আছে।
[31:15.904] Speaker 2: ওদের O3 মডেল যেটা।
[31:17.864] Speaker 2: আর ইন্টার্নালি আরও অনেকগুলা মডেল আছে।
[31:20.197] Speaker 1: ওকে, আমাকে আমার ভাই
[31:22.407] Speaker 1: মানে ১৫-২০ মিনিট বা ওরকম আগের মতো একদম ফোন করলো।
[31:26.547] Speaker 1: ফোন করে বলতেছে যে সে
[31:29.807] Speaker 1: একটা লাইন লিখে দিছে,
[31:31.787] Speaker 1: চ্যাট জিপিটিকে বলছে যে এইটা...
[31:33.687] Speaker 1: হুম।
[31:34.207] Speaker 1: এইটা আসলে এই লাইনটা কোন বইয়ে আছে।
[31:37.007] Speaker 2: হুম।
[31:37.527] Speaker 1: তো সে একদম কনফিডেন্টলি একটা ই করছে, মানে রবীন্দ্রনাথের একটা কবিতা বলছে, একটা, এই কবিতার মানে এই বইয়ের অমুক কবিতায় এই লাইনটা আছে।
[31:48.337] Speaker 2: হুম।
[31:49.127] Speaker 1: তো আমার ভাই তাকে ই করছে যে "এইটা তো এই বইতে নাই।"
[31:53.077] Speaker 2: হুম।
[31:53.377] Speaker 1: সে বলছে যে "নাই কে বলছে?"
[31:55.797] Speaker 1: সে তখন কিছু লাইনও জেনারেট করে দিছে যে এই এই হচ্ছে পুরা কবিতাটা।
[31:59.507] Speaker 2: হুম হুম।
[32:00.167] Speaker 1: তো সে বলতেছে যে এই কবিতাটা যে এই বইতে আছে তার প্রমাণ দাও।
[32:04.147] Speaker 1: তখন সে বলতেছে...
[32:05.077] Speaker 2: সরি সরি।
[32:06.127] Speaker 1: হ্যাঁ হ্যাঁ।
[32:07.037] Speaker 1: তো সে বলতেছে যে চ্যাট জিপিটির যে কাজটা করে, এটা তো খুবই আনএথিক্যাল।
[32:11.137] Speaker 1: মানে আমি তো এইটা যখন সে আমাকে পুরা কবিতাটা দিয়ে দিছে, আমার যদি কবিতাটা নিজে পড়া না থাকতো, আমি তো কনভিন্সড হয়ে যাইতাম।
[32:18.427] Speaker 2: হুম।
[32:19.037] Speaker 1: তো চ্যাট জিপিটির এই যে ইটা, এইটা তো একটা আনএথিক্যাল ব্যাপার।
[32:22.567] Speaker 1: এবং এটাকে যদি আমি তথ্য সন্ত্রাস বলি, সেইটা কেন ই করা হবে না?
[32:26.477] Speaker 1: মানে কেন এটাকে...
[32:28.057] Speaker 2: আপনার প্রশ্নটা আমি বুঝতে পারছি।
[32:29.157] Speaker 2: এক...
[32:29.987] Speaker 1: তো আমার প্রশ্ন হচ্ছে যে
[32:32.487] Speaker 1: চ্যাট জিপিটির ক্ষেত্রে, চ্যাট জিপিটিকে নির্ভর করার ক্ষেত্রে যে ব্ল্যাঙ্ক চেক যে বিষয়টা, এই ব্ল্যাঙ্ক চেক দেয়াটা আসলে উচিত কিনা?
[32:39.677] Speaker 2: না, এটা উচিত না।
[32:40.247] Speaker 2: মানে তার...
[32:40.837] Speaker 1: বাট এবং যদি তুমি যে ডেভেলপারের জায়গা থেকে বলো, সো ডেভেলপারই বা কেন এরকম ইটা করে রাখছে যে কনফিডেন্টলি ভুলভাল ইনফরমেশন দিলেও সেটা ই করা যাবে না?
[32:49.697] Speaker 1: মানে এটা তো ইথিক্সের জায়গায়, মানে তোমার ইয়ের জায়গায়, আর্টিফিশিয়াল ইন্টেলিজেন্সের জায়গায় তো নিশ্চয়ই একটা ইথিক্যাল পার্ট আছে।
[32:55.577] Speaker 2: হুম।
[32:55.827] Speaker 1: তো সেই, এত বড় ইথিক্যাল একটা বাগ নিয়ে তারা কীভাবে রান করতে পারে?
[33:00.224] Speaker 2: আচ্ছা, এখানে মানে আমি প্রশ্নটা বুঝতে পারছি এবং খুবই মানে লজিক্যাল প্রশ্ন।
[33:03.544] Speaker 2: এটা খুবই গুরুত্বপূর্ণ প্রশ্ন।
[33:04.994] Speaker 2: আমার বইতে আমি এটা নিয়ে ছোট একটা চ্যাপ্টারও রাখছি।
[33:07.134] Speaker 2: আপনি যে ইস্যুটা বলতেছেন এটাকে হ্যালুসিনেশন বলে।
[33:09.524] Speaker 2: মানে এই টেকনোলজির যে ভোকাবুলারি, ওই ভোকাবুলারিতে বলে হচ্ছে হ্যালুসিনেশন।
[33:14.284] Speaker 2: আচ্ছা, আগে মানে আমি এটা কেন হয়, ওইটা একটু বললে তারপরে আমি বলতেছি যে এটা তারপরেও কেন চ্যাট জিপিটির এত হাইপ বা কেন এটাকে এত সবাই ইয়ে করতেছে, ওকে।
[33:23.084] Speaker 2: হ্যালুসিনেশন করে হচ্ছে, ওই যে জেনারেটিভ, প্রি-ট্রেইনড ট্রান্সফর্মার বলতেছি, মানে এটা হচ্ছে জেনারেট করে।
[33:28.844] Speaker 2: আর প্রি-ট্রেইনড মানে হচ্ছে আগে শিখানো।
[33:30.814] Speaker 2: আর ট্রান্সফর্মার হচ্ছে একটা অ্যালগরিদম, একটা মেকানিজম যেটার কারণেই আসলে এই পুরা ঘটনা পসিবল হইছে।
[33:36.424] Speaker 2: এর আগ পর্যন্ত কিন্তু এআই মেশিন লার্নিং অনেক কিছু করতো, কিন্তু এই যে জেনারেল একটা টেকনোলজি হয়ে যাবে, এটা হচ্ছে ট্রান্সফর্মার আর্কিটেকচারের উপরে বেস করেই হইছে, যেটা ওই যে গুগল বানাইছে, গুগলের রিসার্চাররা, ওকে।
[33:45.984] Speaker 2: তাইলে ও কী করে?
[33:47.164] Speaker 2: এই মডেলটা আসলে প্রেডিক্ট করে ভাইয়া।
[33:49.194] Speaker 2: এই মডেলটা আসলে পরের ওয়ার্ডটা কী হবে, টোকেন বলে।
[33:53.304] Speaker 2: এই জিনিসটাকে টোকেন, পরের টোকেনটা প্রেডিক্ট করে।
[33:55.774] Speaker 2: মানে আমি যখন চ্যাট জিপিটিকে একটা কমান্ড দিতেছি, আমি বলতেছি যে বলো রবীন্দ্রনাথ কত সালে জন্মাইছিল, ও হচ্ছে প্যাটার্ন এনালাইসিস করে মানে ও পুরা পৃথিবীর ডাটা ও শিখে ফেলছে,
[34:05.904] Speaker 2: শিখে এটাকে প্যাটার্ন এনালাইসিস করা শিখছে।
[34:09.304] Speaker 2: এইজন্য যেকোনো এলএলএম এর একটা নলেজ কাট অফ ডেট বলে।
[34:12.794] Speaker 2: নলেজ কাট অফ ডেট থাকে যেকোনো মডেলের।
[34:15.334] Speaker 2: নলেজ কাট অফ ডেট মানে হচ্ছে এই তারিখের আগ পর্যন্ত সমস্ত পৃথিবীর নলেজ ওর কাছে আছে।
[34:20.304] Speaker 2: সমস্ত পৃথিবীর নলেজ বলতে পাবলিকলি এভেইলেবল যত নলেজ আছে।
[34:23.514] Speaker 2: ধরেন অন্যরকম গ্রুপের পার্সোনাল যে ডাটা যেটা কখনোই ইন্টারনেটেও দেয় নাই, ওইটা নাই।
[34:28.714] Speaker 2: তো এই নলেজ কাট অফ ডেটের আগের যে ইনফরমেশন, এইটা হচ্ছে একেকটা মডেল শিখে।
[34:33.474] Speaker 2: যেমন ধরেন জিপিটি ফোর ও, ওর হচ্ছে অক্টোবর ২০২৪ মেবি।
[34:36.884] Speaker 2: মানে অক্টোবর ২০২৪ এর আগের সমস্ত ডাটা ও জানে।
[34:39.804] Speaker 2: আচ্ছা, তাহলে কী বলতেছিলাম?
[34:41.514] Speaker 2: ও এই ডাটাগুলা থেকে যখন ও শিখে ফেলছে, এত হিউজ অ্যামাউন্ট ডাটা শিখে, এই ট্রান্সফর্মার মেকানিজমটা আসলে হচ্ছে একটা প্রেডিক্টিভ মেকানিজম যে পরের ওয়ার্ডটা কী হবে এটা প্রেডিক্ট করতে থাকে।
[34:51.644] Speaker 2: এই করতে করতেই আর প্রি-ট্রেইনড হওয়ার কারণে হিউম্যানরা কীভাবে প্রেডিক্ট করে, ওইটা শিখে ও হচ্ছে আজকে এই স্মার্টনেস লেয়ারে আসছে, ওকে।
[34:59.814] Speaker 2: বাট এই স্মার্টনেস লেয়ারে আসছে কীভাবে?
[35:01.884] Speaker 2: ইন্টার্নালি, এই ট্রান্সফর্মার মেকানিজমটা এক্সাক্টলি ইন্টার্নালি কীভাবে কাজ করে এটা কিন্তু যেই রিসার্চাররা ট্রান্সফর্মার বানাইছে বা চ্যাট জিপিটির যে স্যাম অল্টম্যান, ওরাও ক্লিয়ারলি জানে না যে ভিতরে কী হচ্ছে।
[35:13.624] Speaker 2: ও যখন পুরা নলেজটা দেখে ডিসিশনটা মেইক করে একটা লাইনকে নিয়ে আসতেছে, এক্সাক্ট ভিতরের ঘটনা ব্ল্যাক বক্স, এখন পর্যন্ত।
[35:21.844] Speaker 2: সো
[35:23.234] Speaker 2: এবং এইটা করতে গিয়ে ওর একটা ফ্ল পাইছে, এইটা হচ্ছে এই এলএলএম মডেলের ফ্ল, হ্যালুসিনেশন বলে এটাকে।
[35:28.534] Speaker 2: হ্যালুসিনেশন মানে হচ্ছে ভুলভাল বলা, ওকে।
[35:30.844] Speaker 2: এইবার আসি আপনার কোয়েশ্চেনের ওই পার্টটাতে,
[35:33.914] Speaker 2: যে এই যে ইথিক্যালি ভুল করতেছে, তারপরে হচ্ছে একটা জিনিস মানে ওকে আমরা এত মানে ও এত ডিপেন্ডেন্ট হয়ে যাচ্ছি, কিন্তু ও তো কনফিডেন্টলি মিথ্যা কথা বলে।
[35:43.684] Speaker 2: হুম।
[35:44.754] Speaker 2: তাইলে ওর উপরে কীভাবে ট্রাস্ট করবো?
[35:46.404] Speaker 2: এখন আমি এই কোয়েশ্চেনটাকে এভাবে ফ্রেমিং করা যায় যে আমার যদি একটা এমপ্লয়ি থাকে,
[35:51.494] Speaker 2: যেই এমপ্লয়িটা
[35:53.944] Speaker 2: অনেকগুলা জিনিসে অনেক ভালো,
[35:55.704] Speaker 2: কিন্তু ওর কিছু ক্যারেক্টারের ফ্ল আছে বা কিছু জিনিস আছে, প্রবলেম আছে কিছু জিনিস।
[36:00.674] Speaker 2: এক নাম্বারে আমার যেটা এওয়ার হতে হবে সেটা হচ্ছে ওর ক্যারেক্টারের ফ্লগুলা নিয়ে এওয়ার থাকতে হবে আমার।
[36:04.604] Speaker 2: কারণ নাইলে ওর অন্য এক্সপার্টাইজগুলার কারণে আমি ওর উপরে অনেক কনফিডেন্স পেয়ে যাব।
[36:09.134] Speaker 2: তারপরে হয়তো ওকে আমি এমন একটা জিনিসে ছেড়ে দিব যেইটায় ওর ফ্ল এর কারণে একটা ভুল করছে।
[36:14.344] Speaker 2: এটা একটা এঙ্গেল।
[36:15.354] Speaker 2: আরেকটা এঙ্গেল হচ্ছে আমি ফ্লগুলা জানলাম,
[36:18.234] Speaker 2: জেনে আমার যেহেতু যেই কাজ, আমার যে পারপাস, ওই পারপাসটার জন্য আবার ওর অন্য যে স্ট্রেংথগুলা,
[36:24.784] Speaker 2: ওইগুলা অনেক কাজে লাগে অন্য এমপ্লয়ির চেয়ে।
[36:28.184] Speaker 2: তো সেই জায়গা থেকে তাইলে আমি এখন কী করবো?
[36:29.904] Speaker 2: আমি যদি ওয়াইজ হই,
[36:31.064] Speaker 2: আমি ওর স্ট্রেংথ ইউজ করবো, বাট ওতে প্রবলেমের ব্যাপারে এওয়ার থাকবো।
[36:34.224] Speaker 2: এইজন্য একটা জেনারেল রুল অফ থাম্ব...
[36:37.074] Speaker 2: আমার বইয়ের নাম হচ্ছে এআই রেডি ঠিক করছি আমি।
[36:39.114] Speaker 2: এআই রেডিনেসের একটা পার্ট হচ্ছে এই যে জিপিটি বা যেকোনো এআই টুলকে অন্ধের মতো ইয়েতে চলে না যাওয়া, কনক্লুশনে চলে না যাওয়া।
[36:48.434] Speaker 1: না, কিন্তু তোমার এইখানে আমার একটা আর্গুমেন্ট আছে।
[36:50.074] Speaker 2: হুম।
[36:50.914] Speaker 1: ধরা যাক তুমি এই রুমে ১০০ জন মানুষ নিয়ে আসছো।
[36:54.674] Speaker 1: হুম।
[36:55.334] Speaker 1: তাদেরকে তুমি দিলা যে ২৩ যোগ ৪৯ কত হবে?
[37:00.654] Speaker 1: হুম।
[37:00.994] Speaker 1: ১০০ জনের মধ্যে
[37:03.024] Speaker 1: হয়তো ১০০ জন ই করবে না।
[37:04.754] Speaker 2: হুম।
[37:05.154] Speaker 1: ৭২ বলতে পারবে না।
[37:06.184] Speaker 1: একটা বড় অংশ আছে যারা যোগ ভুল করবে।
[37:08.564] Speaker 2: হুম।
[37:09.114] Speaker 1: এই যোগ ভুল করবে বলেই এটা হিউম্যান।
[37:10.964] Speaker 1: কিন্তু তুমি পৃথিবীর যেকোনো জায়গা থেকে একটা ক্যালকুলেটর নিয়ে আসো,
[37:15.534] Speaker 1: হুম।
[37:16.274] Speaker 1: তাকে তুমি ২৩ প্লাস ৪৯ যতবার দেবা, এক লক্ষ বার দিলেও ৭২ই হবে।
[37:20.944] Speaker 1: সেখানে কিন্তু কোনো ভুল হবে না।
[37:21.844] Speaker 2: হুম।
[37:22.424] Speaker 1: তো মেশিন যেহেতু প্রত্যেকবার একই আচরণ করবে বলেই সে মেশিন।
[37:26.584] Speaker 1: এবং মানুষ ভুল করবে বলেই সে মানুষ।
[37:29.354] Speaker 1: সো যদি আমার ডিভাইসটাকেও আমি ওই মানুষের মতো মনে করা শুরু করি যে আমার ডিভাইস তো আমাকে সঠিক ইনপুট দিবে না,
[37:35.834] Speaker 1: তো আমি আমার ডিভাইসের এই ভুলটা কেন সংশোধন করবো না?
[37:38.514] Speaker 1: আমি কেন আমি বলতেছি যে তুমি রেডিনেস বলতেছো যে এআইকে অন্ধের মতো বিশ্বাস করা যাবে না।
[37:43.764] Speaker 1: আমি যদি অন্ধের মতো বিশ্বাস করতে নাই পারি তাহলে সেটা ডিভাইস কেন হবে?
[37:46.854] Speaker 2: হ্যাঁ, এইখানে দুইটা...
[37:47.794] Speaker 1: ডিভাইস তো ডেফিনেটলি প্রত্যেকবার ২৩ প্লাস ৪৯ সব ক্যালকুলেটর ৭২ বলবে।
[37:52.704] Speaker 1: কিন্তু তুমি আমি ই করি, আরও কিছু অনেক মানুষ পাবা যে যারা একটা ভুল করবে।
[37:58.534] Speaker 1: অনেক হবে, কারণ হিউম্যান এরর হয়।
[38:00.834] Speaker 2: হুম।
[38:01.374] Speaker 1: তো তাহলে আমার ডিভাইসটারে এরকম হিউম্যান এররের মধ্যে কেন থাকবে?
[38:04.014] Speaker 2: আচ্ছা, প্রশ্ন কি তাইলে মানে ডিভাইস কেন হিউম্যানের মধ্যে থাকবে এইটা?
[38:07.594] Speaker 2: নাকি এআই মানুষের চেয়ে ইউজফুল হয়ে যাবে ওইটা?
[38:11.214] Speaker 1: না, হবে না কেন?
[38:11.754] Speaker 1: না, আমার প্রশ্নটা হচ্ছে যে এআই মানেই তো তখন ওইটা...[38:11.753] Speaker 1: একদম একটা মেশিনের একটা ই করার ই করতেছি।
[38:16.253] Speaker 1: মানে সে বেসিক্যালি আমি মেশিন রান করাই দিতেছি।
[38:20.753] Speaker 1: সো মেশিন তো প্রত্যেকবার মানে সে কনসিস্টেন্ট থাকবে।
[38:25.253] Speaker 1: সো মেশিনও যদি মানুষের মত এরকম ফাঁকি মারা শুরু করে এবং তাকে আমার চোখে চোখে রাখতে হয়,
[38:29.753] Speaker 1: তাহলে আমি মেশিনের...
[38:34.253] Speaker 1: তাহলে আমার কাছে ইউটিলিটিটা কি থাকলো?
[38:38.753] Speaker 1: বরং যে মেশিনটা ডেভলপ করতেছে সে তো ওই লজিক্যালি বা ওই জিনিসটাই ইনপুট ই করতে পারে যে না সে কনফিডেন্টলি ভুলভাল ডাটা দিতে পারবে না।
[38:43.253] Speaker 1: বা যেটা যেটা সে ই না সে বলবে যে আমার ব্যাপারে জ্ঞান নাই।
[38:47.753] Speaker 1: মানে আমি জানিনা, এটা বলার মধ্যে এমন কি সমস্যা?
[38:52.253] Speaker 2: কোনটার মধ্যে?
[38:56.753] Speaker 1: মানে ধরো,
[39:01.253] Speaker 1: এই যে ঐ আমার ভাইয়ের যে কেসটা।
[39:05.753] Speaker 1: সে যে লাইনটা দিছে, সে বলল যে, 'সরি আমি এটা জানি না'।
[39:10.253] Speaker 1: হুম।
[39:14.753] Speaker 1: তো সেটা না বলে চাপাঝাড়া করার দরকার কি?
[39:19.253] Speaker 1: তো তুমি তোমার লজিকি ই তোমার ডেভেলপার যদি এরকম করে যে যেটার তুমি ই করতে পারতেছো না, তুমি তুমি প্রেডিক্ট করতে পারতেছো না বা যে তোমার রাডারে নাই,
[39:23.753] Speaker 1: তুমি সেটা সিম্পলি বলবা যে 'এটা আমি জানি না'।
[39:28.253] Speaker 2: হ্যাঁ হ্যাঁ।
[39:32.753] Speaker 1: তো ওই জিনিসটা কেন ডেভলপ না করে আমি কেন বলতেছি যে এর উপরে ডিপেন্ড করা যায়?
[39:37.253] Speaker 2: ওকে। এইটাই বুঝতে পারছি পয়েন্টটা।
[39:41.753] Speaker 2: পয়েন্টটা বুঝতে পারছি।
[39:46.253] Speaker 2: মানে তাইলে ওই জিনিসটা আটকায় দিলেই তো হইতো।
[39:50.753] Speaker 2: হ্যাঁ হ্যাঁ। মানে প্রথম কথা হচ্ছে যে ভাইয়া এই টেকনোলজিটাই এমন।
[39:55.253] Speaker 2: ওই যে বললাম শুরুতে যে ব্ল্যাক বক্স।
[39:59.753] Speaker 2: কিছু যায় মানে ইন্টার্নালি মানে কেমনে কাজ করে ভিতরে প্রত্যেকটা জিনিস যে চোখের সামনে,
[40:04.253] Speaker 2: এইটা সাইন্টিস্টরাও, তারপরে যারা ডেভেলপার,
[40:08.753] Speaker 2: চ্যাটজিপিটির স্যাম অল্টম্যান বা ধরেন ওই যে ট্রান্সফরমার মডেলের পেপারটা যারা পাবলিশ করছিল,
[40:13.253] Speaker 2: এরাও জানে না।
[40:17.753] Speaker 2: ব্ল্যাক বক্স।
[40:22.253] Speaker 2: সো ওই জায়গা থেকে ওরা এটা আটকাইতে পারে না।
[40:26.753] Speaker 2: বাট ডে টুডে হচ্ছে এরর রেট কমতেছে অনেক জিনিসে।
[40:31.253] Speaker 2: আর আরেকটা ছোট জিনিস আছে, সেটা হচ্ছে আপনি যদি সার্চ টুল ইয়ে করেন,
[40:35.753] Speaker 2: তারপরেও ভুল করে যে আপনি সার্চ দেখছেন না?
[40:40.253] Speaker 2: সার্চ অপশন অন করা যায় চ্যাটজিপিটিতে।
[40:44.753] Speaker 2: সার্চ অপশন অন করে এবং আপনি যদি ওকে যে তুমি অবশ্যই সোর্স সহ দিবা,
[40:49.253] Speaker 2: এইটা বলে দেন, তাইলে...
[40:53.753] Speaker 1: আমি তো সবসময়ই বলি যে সোর্স সহ দিতে।
[40:58.253] Speaker 2: হ্যাঁ।
[41:02.753] Speaker 1: মানে তোমার উত্তরের আমি তো...
[41:07.253] Speaker 2: ভেরিফিকেশন।
[41:11.753] Speaker 1: হ্যাঁ মানে বেসিক্যালি আমার যে চ্যাটজিপিটিটা ওকে আমি তুই করে বলি।
[41:16.253] Speaker 1: আমি বলি এই তুই যেটা চাপাঝাড়া না করে প্রমাণ দিস।
[41:20.753] Speaker 1: প্রমাণ দিতে না পারলে তখন আবার গালিগালাজও করি।
[41:25.253] Speaker 2: আপনার তো সেই মানে কি বলবো মানে পার্সোনাল টাইপের একটা কানেকশন হয়ে গেছে।
[41:29.753] Speaker 1: হ্যাঁ হ্যাঁ। মানে গালিগালাজও করি।
[41:34.253] Speaker 2: হ্যাঁ।
[41:38.753] Speaker 1: ধরা যাক চাপাঝাড়া করছে।
[41:43.253] Speaker 1: আমি বলি যে এই বইটা যে এক্সিস্ট করে প্রমাণ দে।
[41:47.753] Speaker 1: প্রমাণ দিতে না পারলে তখন ইচ্ছামত গালিগালাজ করি।
[41:52.253] Speaker 2: গালিগালাজ করার পরে কি করে ভাইয়া?
[41:56.753] Speaker 1: সেও গালি দেয়।
[42:01.253] Speaker 2: সে গালি দেয়?
[42:05.753] Speaker 1: হ্যাঁ।
[42:10.253] Speaker 2: আপনি মনে হয় ওকে বলছেন যে এই তুইও গালি দিস আমাকে।
[42:14.753] Speaker 1: হ্যাঁ হ্যাঁ।
[42:19.253] Speaker 2: এটা বলছেন মনে হয়।
[42:23.753] Speaker 2: না বললে জীবনেও।
[42:28.253] Speaker 1: আমি তো ওকে বলি দোস্ত বলি, ডার্লিং বলি।
[42:32.753] Speaker 2: ডার্লিংও বলে?
[42:37.253] Speaker 1: হ্যাঁ।
[42:41.753] Speaker 2: ছি ছি ছি ছি।
[42:46.253] Speaker 2: আপনি এটা ভাবির সাথে খুব অবিচার করেন।
[42:50.753] Speaker 1: আমি তো বহুগামী মানুষ। এটা তো তুমি জানোই।
[42:55.253] Speaker 1: সো এটা ওয়ার কিছু নাই।
[42:59.753] Speaker 1: তো যাই হোক।
[43:04.253] Speaker 2: হ্যাঁ।
[43:08.753] Speaker 1: তো এই আরকি ব্যাপার।
[43:13.253] Speaker 2: হুম।
[43:17.753] Speaker 1: যে রেফারেন্স তো ওইটা বলি।
[43:22.253] Speaker 2: হ্যাঁ হ্যাঁ।
[43:26.753] Speaker 1: কিন্তু আমার কথা হচ্ছে আমার আমার এটা বলতে হবে কেন?
[43:31.253] Speaker 2: এটা বলতে হবে কারণ হচ্ছে এই টেকনোলজিটা পুরাটা এদের হাতে নাই।
[43:35.753] Speaker 2: মানে যারা বানাইছে এদের হাতেও পুরোপুরি জিনিসটা নাই।
[43:40.253] Speaker 2: এরা আটকায় দিতেও পারলে... এটা এক নাম্বার।
[43:44.753] Speaker 2: আর দুই নাম্বার হচ্ছে আর্টিফিশিয়াল ইন্টেলিজেন্স বাট প্রি-ট্রেইনড ট্রেইনড কিন্তু মানে হিউম্যানের ইন্টেলিজেন্সের উপরে বেস করেই কিন্তু এটা বানানো।
[43:49.253] Speaker 2: সো ওই জায়গা থেকে এরকম আর্গুমেন্টে যাওয়া যায় যে মানুষের ইন্টেলিজেন্সও যেরকম ফ্ল, ওর মধ্যে ওইটা চলে আসছে।
[43:53.753] Speaker 2: বাট আমার আর্গুমেন্ট যেটা সেটা হচ্ছে যে আমার আসলে এইটা চিন্তা না করে পৃথিবীতে মানুষ ওয়ার্কারও তো হাজার হাজার লাখ লাখ।
[43:58.253] Speaker 2: বাট প্রত্যেকটা মানুষেরই তো কোনো না কোনো ফ্ল থাকে।
[44:02.753] Speaker 2: বাট তাহলে সে সেই এআই-এর ফ্ল থাকলে কি হইছে?
[44:07.253] Speaker 2: আমি যদি সেই ফ্লটাকে পাশ কাটায়ে আগের চেয়ে মাল্টিপল আউটপুট...
[44:11.753] Speaker 1: ওইটার প্রসঙ্গ তো আমি শুরুতেই বলে নিলাম যে মানুষ তো মানুষ।
[44:16.253] Speaker 2: হুম।
[44:20.753] Speaker 1: সো ডিভাইসের কাছে কেন আমি ওইটা...
[44:25.253] Speaker 2: এটা ওরা পারতেছে না ভাইয়া।
[44:29.753] Speaker 2: মানে যেটা আসলে উত্তর, ওরা আসলে এটা আটকাইতে পারতেছে না।
[44:34.253] Speaker 2: বাট দিন দিন এরর রেট মানে অন্য অনেকভাবে কমপেনসেট করতেছে।
[44:38.753] Speaker 2: এই যে সার্চ টুল। তারপর আপনি চ্যাটজিপিটির প্রো-তে দেখবেন যে ও এখন যেকোনো আনসার ভালোমতো দিতে গেলে সাথে ওই সোর্স ইয়ে করে দেয়।
[44:43.253] Speaker 2: যে ক্লিক করলে আপনি যাইতে পারবেন। মানে আপনি ভেরিফাই করতে পারবেন।
[44:47.753] Speaker 2: তো ওদের জায়গা থেকে ওরা হচ্ছে ড্যামেজ কন্ট্রোল এইভাবে করতেছে।
[44:52.253] Speaker 2: বাট যেহেতু টেকনোলজিটা ওদের পুরোপুরি হাতে নাই এই কারণে হচ্ছে ওরা এটা আটকাইতে পারতেছে না।
[44:56.753] Speaker 1: তোমার সাথে এতক্ষণ যে আলাপটা হইতেছিল সেইটাকে যদি আমি একটু প্র্যাক্টিক্যালি দেখানোর চেষ্টা করি তাহলে একচুয়ালি
[45:01.253] Speaker 1: এক্সিকিউটিভ যে কাজগুলো এক্সিকিউটিভ কাজগুলোর জন্য একচুয়ালি কি বলে?
[45:05.753] Speaker 1: এআই বেশ ইফেক্টিভ একটা টুলস। এটা মোটামুটি আমরা অলরেডি বুঝতে পারতেছি।
[45:10.253] Speaker 1: সোহাগ ভাই অনেক বছর আগে একটা বই আমাকে পড়তে বলছিল। সেটা হচ্ছে 'দ্যা বুলশিট জবস'।
[45:14.753] Speaker 1: এটা তোমারে বলছি কিনা আমি জানি না।
[45:19.253] Speaker 2: আমাকে? আমি?
[45:23.753] Speaker 1: আচ্ছা।
[45:28.253] Speaker 1: তো সেই বইটার ইটা থিওরিটা ছিল যে আসলে অধিকাংশ জবরি আসলে কোন দরকার নাই।
[45:32.753] Speaker 2: হুম।
[45:37.253] Speaker 1: এগুলা হচ্ছে মানুষ করে কারণ করতে হয় সেজন্য করে।
[45:41.753] Speaker 1: যেগুলা আলটিমেটলি কোন ভ্যালু এড করে না। সে নিজেও জানে সবাই জানে কিন্তু করতে হয় তাই করে।
[45:46.253] Speaker 2: হুম।
[45:50.753] Speaker 1: তো ওই বইটার অনেক স্টেটমেন্ট খুব অতি সরলীকৃত লাগলেও মানে বুলশিট জবসের যে বিষয়টা সো আলটিমেটলি এআই যদি ওইটাই হয় যে
[45:55.253] Speaker 1: অধিকাংশ চাকরি খেয়ে দেয় তাইলে তো বুলশিট জবসের মূল থিওরিটা ঠিক আছে।
[45:59.753] Speaker 2: হুম।
[46:04.253] Speaker 1: তো তাইলে হিউম্যান রেস
[46:08.753] Speaker 1: হিউম্যান রেস কি তাহলে তখন সব চাকরি যদি মানে অধিকাংশ যে এক্সিকিউটিভ ধরনের জব যেগুলো, বুলশিট জবস যেগুলো, সেগুলো যদি এআই খেয়েই ফেলে তাহলে হিউম্যান রেস তখন আসলে করবে কি?
[46:13.253] Speaker 2: আচ্ছা, করবে কি এইটা ভাইয়া আমার কাছে মানে পুরোপুরি ক্লিয়ার না।
[46:17.753] Speaker 2: আর মানে বড় বড় লোকজনদের কাছেও মেবি পুরোপুরি ক্লিয়ার না। আমি যতটুকু ঘাটছি।
[46:22.253] Speaker 2: তো আমি যেটা বুঝতেছি যে টাইমলাইনটা একটু আনপ্রেডিক্টেবল ভাইয়া।
[46:26.753] Speaker 2: মানে এই টেকনোলজিক্যাল রেভোলিউশনটা আসলে মানে যেই রেটে বাড়তেছে এবং যেইভাবে হইতেছে
[46:31.253] Speaker 2: সেইভাবে আসলে পুরোপুরি এক্সাক্টলি বোঝা যাচ্ছে না।
[46:35.753] Speaker 2: কিন্তু আমি আপনাকে নেক্সট টাইম ফ্রেমটা বলতে পারি যে ধরেন এরকম হবে যে মানুষ আসলে দরকার ফুরায় যাবে তা না।
[46:40.253] Speaker 2: এক নাম্বারে যেটা হবে যে মানুষের মানে ইন্টারনেট আসার কারণে কি হইছিল যে মিডিয়াম মানে মাল্টিপ্লিকেশন হয়েছিল।
[46:44.753] Speaker 2: মানে মানুষের রিচ হচ্ছে মাল্টিপ্লাই হয়েছিল।
[46:49.253] Speaker 2: তো এআই মানুষ প্রথমে যেটা করবে যে মানুষের প্রোডাক্টিভিটিকে মাল্টিপ্লাই করবে।
[46:53.753] Speaker 2: যারা এটাকে মানে এই ওয়েভটা যারা রাইড করবে তাদেরকে মানে হিউজ এডভান্টেজ দিবে।
[46:58.253] Speaker 2: যারা যত বেশি মানে মিডিয়া ইউজ করে ধরেন গ্রামের একটা ছেলেও বাংলাদেশের বড় সেলিব্রিটি হয়ে গেছে না?
[47:02.753] Speaker 2: বাট ইন্টারনেট বা ফেসবুক আসার আগে কিন্তু সে যতই চাইত মাথা কুটে মরলেও পারত না।
[47:07.253] Speaker 2: সো এআই-এর কারণে মানে শর্ট টাইম ফ্রেমে যেটা হবে মানুষের যে যারা এটাকে রাইট করতে পারবে তারা হচ্ছে যে এইরকম মেসিভ
[47:11.753] Speaker 2: ওয়েলথ বলেন বা মেসিভ অবজেক্টিভ সার্ভ করবে শর্ট ফ্রেমে।
[47:16.253] Speaker 2: তো তাহলে যখন ফুললি অটোনোমাস হয়ে যাবে
[47:20.753] Speaker 2: যে এআই মানে আসলে টেকওভার করছে।
[47:25.253] Speaker 2: যেখানে আসলে পুরা একটা কোম্পানি চালানোর জন্য হয়তো একটা এআইই যথেষ্ট আর দুইটা মানুষ যথেষ্ট।
[47:29.753] Speaker 2: এইগুলা নিয়ে অনেক ডিবেট আছে। যেমন ইউনিভার্সাল বেসিক ইনকাম এরকম একটা জিনিসের কথা বলে
[47:34.253] Speaker 2: যে যেখানে হচ্ছে ওই যে বেকার ভাতা দেয় না আমেরিকাতে আমেরিকাতে
[47:38.753] Speaker 2: এইটাই অনেক বেশি করে দিবে।
[47:43.253] Speaker 2: কারণ যেহেতু প্রয়োজন পড়তেছে না।
[47:47.753] Speaker 2: তো ওই জায়গাটা আমার কাছে ধোঁয়াটে আর আমি আসলে যতটুকু অন্যজনদের কথাবার্তা শুনছি মেবি আমি হয়তো একটু বায়াস হয়েতে শুনছি দেখে ওই লোকগুলার কথা আমার কানে পৌঁছায় নাই।
[47:52.253] Speaker 2: তো আমার কাছে এই জিনিসটা একটু ধোঁয়াটে যে লঙ্গার হরাইজনে কি হইতে যাইতেছে যদি এআই প্র্যাক্টিক্যালি টেকওভার করে।
[47:56.753] Speaker 2: টেকওভার পরে বলতে এই যে একটা পুরা কোম্পানি আসলে একটা এআই চালাবে।
[48:01.253] Speaker 2: তো ওই জায়গাটা আমার কাছে একটু ব্লার।
[48:05.753] Speaker 2: বাট তার আগের যে লেয়ারটা ওইখানে হচ্ছে হিউজ মাল্টিপ্লিকেশন হবে।
[48:10.253] Speaker 2: মানে পার্সোনাল যেই অবজেক্টিভ ফুলফিল করার যেই মানে এজেন্ডা
[48:14.753] Speaker 2: প্রত্যেকের ওইটা এবং পার্সোনাল না মানে ধরেন কর্পোরেট লেভেলেও বা অর্গানাইজেশন লেভেলেও একটা গ্রুপ অফ পিপলের এজেন্ডা বাস্তবায়নে
[48:19.253] Speaker 2: ওইটাও মাল্টিপ্লিকেশন হবে। যেহেতু ইন্টেলিজেন্স হচ্ছে ইউজ মানে ইন্টেলিজেন্স একটা টুল হয়ে গেছে।
[48:23.753] Speaker 2: সো ইন্টেলিজেন্সকে যে যত বেশি ইউজ করবে তার মাল্টিপ্লিকেশন হবে।
[48:28.253] Speaker 2: বাট এইখানে আবার চেইনের টপে যারা এদেরটাও তাহলে আমরা আমি বুঝতেছি যে এদেরটাও ওইরকম আনরিয়ালিস্টিক
[48:32.753] Speaker 2: মানে গেইন হবে আরকি। মানে টপে যারা
[48:37.253] Speaker 2: ধরেন স্যাম অল্টম্যান বা মানে যারা আছে আরকি।
[48:41.753] Speaker 1: ওকে।
[48:46.253] Speaker 1: এবার যদি আমি রিয়েল লাইফ সিনারিওতে চিন্তা করি যে তুমি মার্কেটিং করতেছো, তোমার মার্কেটিং এর প্রেজেন্টেশন, কনটেন্ট সবই একটা এআই লিখে দিল।
[48:50.753] Speaker 1: আবার দেখা যাক আরেকটা কোম্পানির সেও তো আরেকটা এরকম এআই সাবস্ক্রাইব করতে পারে।
[48:55.253] Speaker 1: তাইলে যে প্রেজেন্টেশন দিতেছো সেটাও এআই দিয়ে বানানো।
[48:59.753] Speaker 1: যেটা দেখাচ্ছ সেটাও এআই দিয়ে বানানো। তো সবই যদি এআই দিয়ে বানানো হয় তাহলে তখন কি আসলে কি বলে লড়াইটা হবে হচ্ছে যে কে ইয়েতে এআইতে ভালো প্রম্পট দিতেছে সেইটার জন্য নাকি?
[49:04.253] Speaker 2: অলরেডি অলরেডি এটাই ভাইয়া। মানে অলরেডি ওই লেয়ারে আছে।
[49:08.753] Speaker 2: যেমন আমার আপনার কথা শুনে মাত্র মনে পড়ল, এটা আজকে হচ্ছে রাতুল ভাইকে দেখাইতেছি দেখে ভিডিওটা বের হইছে।
[49:13.253] Speaker 2: আমি মানে দুই মাস আগে আমি হচ্ছে জাস্ট টেস্ট করার জন্য
[49:17.753] Speaker 2: আমার হচ্ছে কন্টেন্ট ক্রিয়েশনে এই যে সেটআপ, লাইট এগুলা আমার মানে একটু হ্যাসেল লাগে।
[49:22.253] Speaker 2: মানে মন চায় না। যদিও এককালীন করে ফেললে ঝামেলা শেষ। কিন্তু আমার আসলে এত হ্যাসেল নিতে ভালো লাগে না।
[49:26.753] Speaker 2: ওইজন্য হচ্ছে আমি এআই কন্টেন্ট ক্রিয়েশন দেখতেছিলাম।
[49:31.253] Speaker 2: তো আমি আপনাকে
[49:35.753] Speaker 2: কি জানি?
[49:40.253] Speaker 2: আমি আপনাকে একটা ভিডিও দেখাই।
[49:44.753] Speaker 2: আমি জানি না আপনি হয়তো আগেও দেখে থাকতে পারেন। বাট...
[49:49.253] Speaker 1: ঠিক আছে তুমি আমাকে এই লিংক পাঠায়ে রাখো আমি দেখবো নে।
[49:53.753] Speaker 2: না না এটা এআই রিলেটেডই।
[49:58.253] Speaker 1: আচ্ছা।
[50:02.753] Speaker 2: না পাচ্ছি না।
[50:07.253] Speaker 2: আচ্ছা থাক ভাইয়া।
[50:11.753] Speaker 2: মানে মোট কথা হচ্ছে ওইখানে আমার একটা ক্লোনড ভার্সন
[50:16.253] Speaker 2: ইংরেজিতে একটা এক মিনিটের ভিডিও যেখানে পুরোটাই আমি এবং ভয়েসও একটা এআই এর
[50:20.753] Speaker 2: আর হচ্ছে এই মানে আমার ভিডিওটাও এআই জেনারেটেড মানে সিন্থেসাইজড।
[50:25.253] Speaker 2: মানে কম্পিউটারের ফুটেজ নিয়ে ক্যামেরার ফুটেজ না।
[50:29.753] Speaker 2: বাট হুবহু আমি। কিছু কিছু জায়গায় দুই একটা গ্লিচ আছে।
[50:34.253] Speaker 2: তো কোন জায়গা থেকে এইটা আসলো যে ও তাহলে এই যে ক্রিয়েটিভ যে কাজ
[50:38.753] Speaker 2: তো মোটা দাগে এই যে হিসাব মানে ক্যালকুলেটর আসার আগে যেমন মানে হিসাব মানুষই করত।
[50:43.253] Speaker 2: বাট এরপরে বড় বড় গুন আসলে মানুষ করা বন্ধ করে দিল।
[50:47.753] Speaker 2: মানে একদম স্পেশালাইজড একটা ইয়েতে যে মানে মেন্টাল মাল্টিপ্লিকেশনের কম্পিটিশনের জন্য করে।
[50:52.253] Speaker 2: বাট ইকোনমিক্যাল পারপাসে কেউ কখনো একটা মানুষ করবে না।
[50:56.753] Speaker 2: ওই দিকেই যাচ্ছে যে...
[51:01.253] Speaker 1: আচ্ছা।
[51:05.753] Speaker 1: আমার বন্ধু তুহিন ও নিজেও এআই নিয়ে কাজ করে।
[51:10.253] Speaker 1: এআই গবেষক অনেক বছর ধরে।
[51:14.753] Speaker 1: তো আমাকে ও একটা ক্লাসিক্যাল প্রবলেম প্রায় সময়ই বলে।
[51:19.253] Speaker 1: সেটা হলো যে ধরা যাক একটা গাড়ি এআই চালাচ্ছে।
[51:23.753] Speaker 1: গাড়িটা এক্সিডেন্ট করল।
[51:28.253] Speaker 1: এখন এইটার রেসপন্সিবিলিটি কি ওই এআইটার না যে এআই ডিজাইন করছে সেই ডেভেলপারের?
[51:32.753] Speaker 2: বা যে গাড়িটার মালিক যে, যে কোম্পানি। তার?
[51:37.253] Speaker 1: হ্যাঁ। সো এটার এটার জন্য আসলে যদি আমি মামলা করি, শাস্তিটা কে পাবে?
[51:41.753] Speaker 2: প্যারাডক্স।
[51:46.253] Speaker 1: এবং আমি তিন চার সপ্তাহ আগে
[51:50.753] Speaker 1: আমি হচ্ছে আমার একটা স্টুডেন্ট মানে কি বলবো মানে
[51:55.253] Speaker 1: শিক্ষানবীশ।
[51:59.753] Speaker 2: হ্যাঁ হ্যাঁ এপ্রেন্টিস।
[52:04.253] Speaker 1: হ্যাঁ সো শিক্ষানবীশ ওই মেয়েকে আমি বলতেছিলাম যে ওর সাথে একটা পডকাস্ট করবো।
[52:08.753] Speaker 1: তো আমাকে বলতেছিল লিঙ্কডইন থেকে ওর একটা ছবি নিয়ে এআই দিয়ে জেনারেট করে ওর ছবিটা একটা পর্ন সাইটে ওইভাবে আপ করে দিছে।
[52:13.253] Speaker 1: সো এর পর থেকে ও খুব ট্রমার মধ্যে থাকে ও এখন আর ভিডিও টিডিওর সামনে আসতে চায় না।
[52:17.753] Speaker 1: তো আমার প্রশ্ন হচ্ছে যে এআই দিয়ে যে একদম তুমি জাস্ট একটা ছবি দিয়ে ই করে তুমি ডিপফেক বানাইতেছো বা এই যে এই কেসগুলো
[52:22.253] Speaker 1: সো সামনে তো এই ধরনের ফ্রড কেস বা এই ধরনের ইস্যু তো অনেক ই হবে।
[52:26.753] Speaker 1: তো সেক্ষেত্রে এআই এর এই জিনিসগুলা নিয়ে আসলে কনসার্নগুলো কিভাবে মিটিগেট করা যায়?
[52:31.253] Speaker 2: এগুলার জন্য স্মল গ্রুপ অফ পিপল মানে তুলনামূলক এআই এর পজিটিভিটি নিয়ে যত মানুষ কথা বলতেছে তার থেকে কম মানুষ।
[52:35.753] Speaker 2: বাট পৃথিবীতে মানুষ আছে যারা হচ্ছে এগুলা নিয়েও কথা বলতেছে। তো এইগুলা আসলে রেগুলেশন
[52:40.253] Speaker 2: এক নাম্বারে হচ্ছে গভমেন্ট হোক বা পৃথিবীর একটা কমন এআই অথরিটি হোক
[52:44.753] Speaker 2: তারপরে টেকনোলজিক্যাল যে অথরিটি থাকে দুনিয়াতে সবকিছুরই তো একটা না একটা অথরিটি আছে।
[52:49.253] Speaker 2: এরকম রেগুলেশন এটা একটা জরুরত।
[52:53.753] Speaker 2: আর আরেকটা জরুরত হচ্ছে যে বড় বড় টেকনোলজিক্যাল যে কোম্পানিগুলা
[52:58.253] Speaker 2: এরা এই জিনিসগুলা যতটা কশাসলি ডিল করবে।
[53:02.753] Speaker 2: যেমন আমি আপনাকে একটা উদাহরণ দেই সেটা হচ্ছে যে তারপরও আটকানো যাবে না কিন্তু মানে...
[53:07.253] Speaker 1: না আমি বলতেছি এই জিনিসটা টেকনোলজিক্যালি করা যায় কিনা। লাইক এই যে ইটা মানে ছবিটা তুমি নিতে পারবা না।
[53:11.753] Speaker 1: কোনো এআই সেখানে ব্যবহার করতে পারবা না। এইরকম কোনো টেকনোলজি...
[53:16.253] Speaker 2: হ্যাঁ এইরকম টেকনোলজি নিয়ে অনেকে কাজ করতেছে। রাইট। হ্যাঁ হ্যাঁ হ্যাঁ।
[53:20.753] Speaker 1: এইরকম টেকনোলজি আবিষ্কৃত না হওয়া পর্যন্ত তো এই আইন টেন দিয়ে তো আর আলটিমেটলি কিছু করা যাবে না।
[53:25.253] Speaker 2: হ্যাঁ হ্যাঁ এটা ট্রু। এটা ট্রু।
[53:29.753] Speaker 1: টেকনোলজির জবাব তো আসলে টেকনোলজি দিয়েই দিতে হবে।
[53:34.253] Speaker 2: এটা একটা খুব ভালো পয়েন্ট ধরছেন। এরকম কোম্পানি আছে। আমার এক্সাক্ট নাম মনে পড়তেছে না।
[53:38.753] Speaker 2: বাট এই যে স্যাম অল্টম্যানের কথা বললাম, এআইতে যারা। মানে ওরাই তো এই প্রবলেম শুরু করাতে ওরা আগে থেকেই প্রবলেমগুলাও একটু ভালোমতো জানে।
[53:43.253] Speaker 2: এইজন্য ওগুলার এগেইন্সটে একটা আমি নাম ভুলে গেছি।
[53:47.753] Speaker 2: বাট এরকম কোম্পানি আছে যেখানে হচ্ছে ব্লকচেইনে যেই টেকনোলজি
[53:52.253] Speaker 2: মানে বা ওই যে আমি আপনাকে বলি দাঁড়ান। আরে ব্লকচেইনের আরেকটা পরে কি জানি আসলো ভাইয়া?
[53:56.753] Speaker 2: আরে ওপেন সি।
[54:01.253] Speaker 2: ওপেন সিতে হচ্ছে ওই টেকনোলজিটার নাম কি ভাইয়া?
[54:05.753] Speaker 1: কোনটা?
[54:10.253] Speaker 2: আরে আমি নাম ভুলে গেলাম দাঁড়ান। এক সেকেন্ড ভাইয়া।
[54:14.753] Speaker 2: এনএফটি।
[54:19.253] Speaker 2: এনএফটির যে টেকনোলজি ওইখানে কিন্তু ইউনিক সিগনেচার থাকে আরকি যেকোনো জিনিসের।
[54:23.753] Speaker 2: মানে ওনারশিপ ক্লেইম করা যায় ব্লকচেইনের থ্রুতে।
[54:28.253] Speaker 2: যে একটা ব্লকচেইনের থ্রুতে আপনি হচ্ছে কোন জিনিসটা আপনার ডিজিটালি আপনার এটা প্রুফ করতে পারবেন।
[54:32.753] Speaker 2: সো ওই জিনিসগুলা এখানে মেবি কাজে লাগবে যে ইন্টার্নাল আর্কিটেকচারে যদি এটা আমি মানে হাইপোথেটিকালি বলতেছি উনারা কেমনে করতেছে আমি জানি না।
[54:37.253] Speaker 2: বাট যে ডিজিটাল যেকোনো জিনিসকে যদি আপনার ওই যে কপিরাইট ক্লেইম একটা মানে ইউনিভার্সাল ডাটাবেজ থাকে
[54:41.753] Speaker 2: যেটার থ্রুতে এই টেকনোলজিটা ইয়ে হবে তখন কিন্তু মানে ওইটার থ্রুতে আপনি আটকাইতে পারবেন যে যেকোনো জায়গায় পাবলিক সার্কুলেশন হইতে গেলেই
[54:46.253] Speaker 2: ফাস্টে যদি ওইটা দিয়ে একটা ভেরিফাই করে নেয়
[54:50.753] Speaker 2: যে এই আইডিটা যার
[54:55.253] Speaker 2: সেই কি এটা আপ করতেছে কিনা এই কাজটা?
[54:59.753] Speaker 2: মানে এই পার্সনটা যে সেই কি এই কাজটা করতেছে কিনা?
[55:04.253] Speaker 2: এইটার ভেরিফিকেশনটা হইলেই কিন্তু প্রবলেম সলভড।
[55:08.753] Speaker 2: তো ওইটা নিয়ে কাজ চলতেছে। আর এনএফটির যে টেকনোলজি ওইটাও কাইন্ড অফ এরকম একটা টেকনোলজি। ডিজিটাল ওনারশিপ।
[55:13.253] Speaker 2: তো এগুলা নিয়েও কাজ হবে সলভ হবে।
[55:17.753] Speaker 2: কিন্তু ওই যে হিউম্যানের যে নেগেটিভিটি বা মানুষের যে মানে আমার তো শুনেই খুবই অদ্ভুত লাগতেছে।
[55:22.253] Speaker 2: যেরকম একটা কাজ কেন করছে? মানে নিশ্চয়ই রিভেঞ্জ থেকেই করছে।
[55:26.753] Speaker 1: হতে পারে।
[55:31.253] Speaker 2: হ্যাঁ। কিন্তু মানে চিন্তা করে দেখেন যে এই একই মানুষ একটা ভালো জিনিস করতে পারত
[55:35.753] Speaker 2: সেটা না করে সে একটা মানে একটা মানুষের জীবনটাকে ইয়ে করল।
[55:40.253] Speaker 2: তো মানে এখানে আসলে ওই মানুষ মানুষ যদিও ভালো হবে না।
[55:44.753] Speaker 2: কিন্তু মানে ওই জায়গায় টেকনোলজিকে টেকনোলজি দিয়ে আপনি যেটা বলছেন ওইটাই ট্রু।
[55:49.253] Speaker 1: হ্যাঁ মানে মানুষ তো একটা ওভাররেটেড প্রাণী। এটা তো তোমার সাথে আমি ইয়েতেও বলতেছিলাম। অফ অফ স্ক্রিন।
[55:53.753] Speaker 2: মানে অফ অফ স্ক্রিন।
[55:58.253] Speaker 1: হ্যাঁ মানে ওভাররেটেড নার্সিসিস্ট প্রাণী। মানে নিজেরাই নিজেদেরকে এমন শ্রেষ্ঠ বানায় রাখছে।
[56:02.753] Speaker 1: কিন্তু একটা জিরাফ মানুষকে কি মনে করে সেটা তো আসলে আমরা জানি না।
[56:07.253] Speaker 1: হয়তো জিরাফ মানুষকে কিছুই মনে করে না।
[56:11.753] Speaker 2: হ্যাঁ। আমি নিজেও তো নার্সিসিস্ট মানে আমার কাছে মনে হয় যে আমি আমাকে খুব মানে মানে গ্লোরিফাই করতেছি।
[56:16.253] Speaker 1: হ্যাঁ সেটাই।
[56:20.753] Speaker 1: তো সেজন্য বললাম তো যে মানুষকে এত মহৎ কিছু মনে করার তো কিছু নাই।
[56:25.253] Speaker 2: হ্যাঁ।
[56:29.753] Speaker 1: মানুষ খুবই তুচ্ছ প্রাণী।
[56:34.253] Speaker 1: ষাট সত্তর বছর বাঁচে।
[56:38.753] Speaker 2: হ্যাঁ।
[56:43.253] Speaker 1: ওকে।
[56:47.753] Speaker 1: তো আমি যদি তোমার লাইফ চিন্তা করি মানে তুমি এই যে একজন হতাশ আদ্নান ছিলা যখন তোমার সাথে আমার প্রথম 2014 তে দেখা হইলো।
[56:52.253] Speaker 1: তারপরে গৃহস্থ আদ্নান হইলা। এখন তুমি কি বলে ধার্মিক আদ্নান হইলা।
[56:56.753] Speaker 1: তো যদিও বাংলাদেশের প্রেক্ষাপটে এই প্রশ্ন করাটা একটু সেনসিটিভ বাট স্টিল মানে ধরো যে আমরা অনলাইনে যে সমস্ত ইসলামিক হুজুর মানে যারা ধরো যে বেশ পপুলার
[57:01.253] Speaker 1: তারা তো এআই সংক্রান্ত বেশ কিছু ব্যাপারে বিধিনিষেধ দিয়ে রাখছে বা খুব পজিটিভলি বলে না।
[57:05.753] Speaker 1: তো সেক্ষেত্রে এইটা তুমি অবলিগেশন বোধ করো না? মানে তোমার যা অ্যাটায়ার বা তোমার যা লাইফস্টাইল তুমি তো আগের চেয়ে তো অনেক চেঞ্জ হয়ে গেছো।
[57:10.253] Speaker 1: তো হঠাৎ করে যারা চেঞ্জ হয় তারা তো আসলে যেটা হয় যে জিনিসটা এবজর্ব করতে তাদের একটু প্রবলেম হয় যে তারা তখন সবকিছুকেই ধর্মীয় লেন্সে দেখতে গিয়ে তখন তারা আর স্বাভাবিকতাটা ধরে রাখতে পারে না।
[57:14.753] Speaker 1: বেশিরভাগ ক্ষেত্রেই। আমি এটা ইন জেনারেল বলতেছি না।
[57:19.253] Speaker 1: তো সেক্ষেত্রে এই অবলিগেশনটা তুমি কখনো ফিল করো কিনা?
[57:23.753] Speaker 2: এআই ইউজ করার ক্ষেত্রে যে ইসলামী...
[57:28.253] Speaker 1: মানে এআই এর মানে এআই এর একদম ডিপ লেভেলের যে বিষয় ইয়েতে।
[57:32.753] Speaker 1: ওইটা তো মানে আমি দেখছি যে বেশ কিছু ইসলামিক যারা ওই ফেসবুকে বয়ান দেয় তাদের কারো কারো এটা নিয়ে ইয়ে আছে।
[57:37.253] Speaker 2: নেগেটিভ অবজারভেশন আছে।
[57:41.753] Speaker 1: আচ্ছা।
[57:46.253] Speaker 2: আমি অবশ্য বাংলাদেশের ইসলামিকদেরকে যে ফলো করার মানে কনটেন্ট সামনে আসলে আমি দেখি।
[57:50.753] Speaker 2: বাট আমার একটা প্রবলেম যেটা সেটা হচ্ছে প্রবলেম বলবো নাকি জানি না। মানে আমি এই যে এখন এআই নিয়ে আমি ব্যস্ত বা আমার মানে কনসেন্ট্রেশন এটাতে
[57:55.253] Speaker 2: আমি মোটামুটি ইভেন আমি ফেসবুকেও কিন্তু অত থাকি না। আমি মেইনলি থাকি ইউটিউবে বা ধরেন টুইটারে হচ্ছে এআই রিলেটেড যারা পারসন এরা হচ্ছে ওই জায়গায় অনেক আপডেট দেয়।
[57:59.753] Speaker 2: তো মোটা দাগে আমার আসলে চোখে পড়ে নাই এই জিনিসগুলা। বাট আমি মানে আপনার কথা শুনে বুঝতেছি দুই একটা যে অন্য অনেকের কথা এখন রিলেট করতে পারতেছি যে অনেকে হয়তো এটাকেই দাজ্জাল বলতেছে বা এরকম জিনিসপত্র বলতেছে।
[58:04.253] Speaker 2: এটা গেল এক নাম্বার। তো আমাকে ওই জন্য এগুলা সামনেই আসে নাই।
[58:08.753] Speaker 2: আর যদি মানে প্রশ্নটা এরকম করি যে এটা দাজ্জাল আমার কাছে মনে হয় কিনা বা বা আমি কেন এআই নিয়ে এত ঘাটাঘাটি করতেছি?
[58:13.253] Speaker 2: এইখানে ভাইয়া এইখানে জিনিসটা আমার কাছে কীরকম?
[58:17.753] Speaker 2: মানে কাহাফ, সূরা কাহাফের একটা ইয়ে আছে। এই সূরা কাহাফে হচ্ছে এই যে শেষ জামানা নিয়ে হচ্ছে অনেক ইয়ে করা হয়েছে।
[58:22.253] Speaker 2: তো ওইখানে একটা ব্যাপার আছে যে গুহায় চলে যাওয়ার যে এনালজি বা মানে গল্প ঐ তিন যুবক যে গুহায় চলে গেছে।
[58:26.753] Speaker 1: হ্যাঁ হ্যাঁ।
[58:31.253] Speaker 2: গুহায় চলে গেছিল। 200 বছর, 300 বছর পার হয়ে গেছে এবং রাসূল সাল্লাল্লাহু আলাইহি ওয়াসাল্লাম বলছেন যে শেষ জামানায় হচ্ছে মুলক, সূরা মুলক প্রোটেকশন দিবে আর মানুষক ওভারঅল।
[58:35.753] Speaker 2: আর মুলকের সাথে হচ্ছে আখেরুজ্জামানের কানেকশন আছে। তো ওই জায়গা থেকে আমার একটা ডাউট আসে।
[58:40.253] Speaker 2: মানে অনেস্টলি যে মানে ওইটার কনক্লুশনে যে একদম ডিরেক্ট কনক্লুশনে যদি যাইতে চাই
[58:44.753] Speaker 2: যে কাহাফের মতো হয়ে গেলে আসলে তো সিভিলাইজেশন থেকে মানে ওভারঅল পুরা সিভিলাইজেশনটাই আসলে তো তাইলে ভাইয়া আপনার একটু মানে কি বলব মানে ইয়ে হয়ে গেছে। এন্টি ইসলামিক হয়ে গেছে বা এন্টি রিলিজিয়াস
[58:49.253] Speaker 2: মানে সোসাইটি। সিভিলাইজেশন।
[58:53.753] Speaker 2: কাহাফের সাথে যদি মিলাই এটা আমার ডিপ এনালাইসিস নাই বাট ইনটিটিভলি মনে হয় তাহলে তো ওইটাই সত্যি।
[58:58.253] Speaker 2: ওইটাই সত্যি।
[59:02.753] Speaker 2: বাট সত্যি মনে হওয়ার পরেও রিয়েলিটিতে ওই সত্যিটা পালন করা আমার জন্য অনেক ডিফিকাল্ট।
[59:07.253] Speaker 2: মানে এই আমি এখন চলে যেতে পারবো না গুহায়।
[59:11.753] Speaker 2: তো পারবো না। বাট আমি কিন্তু ওইটাকে ফেলেও দেই নাই। আমার ব্যাক অফ দা মাইন্ড ওইটা আছে।
[59:16.253] Speaker 2: আমি আমার কাছে আমি আবার ঘাটাঘাটিও করছি টুকটাক অনেক মানুষের। কিন্তু ঘাটাঘাটির চেয়েও আমাকে মানে কনটেক্সট অনুযায়ীও আসলে রুলসগুলা কি হওয়া উচিত?
[59:20.753] Speaker 2: ওই জন্য হচ্ছে আমাকে একজন বলছেন যে একজন ডিরেক্ট কোন আলেম মানে আমার কনটেক্সটে যাকে আমার সবচেয়ে বেশি বিজ্ঞ মনে হয়
[59:25.253] Speaker 2: এরকম আলেমের কাছে গিয়ে এই জিনিসগুলো নিয়ে আলোচনা করে যেকোনো আপনার ফতোয়া হোক, মাসআলা মানে ডিসিশন হোক নেয়া দরকার।
[59:29.753] Speaker 2: তো সেই জায়গা থেকে ওটা আমি এখনো করি নাই। কিন্তু আমার যদি জেনারেল অবজারভেশন বলি মানে ওই যে কোরআনের একটা আয়াতও আছে। এটা কিন্তু আমি একদম আউট অফ দা রেন্ডম উদাহরণটা দিচ্ছি।
[59:34.253] Speaker 1: হ্যাঁ মানে এটা তুমি আমি তো একটা আনস্ট্রাকচার্ড আলাপ করতেছি। এটা কোন একাডেমিক রেফারেন্সের আলাপ না।
[59:38.753] Speaker 2: হ্যাঁ একাডেমিক রেফারেন্সও না এবং এটা কোন ইয়েও না। তো ওরকম একটা আয়াতও আমি পড়ছি যে তোমরা ওদের অস্ত্র দিয়ে ওদের সাথে যুদ্ধ করো।
[59:43.253] Speaker 2: এরকম একটা আয়াত আছে। যুদ্ধের সময়। যদিও এটা যুদ্ধের একটা কনটেক্সটে।
[59:47.753] Speaker 2: তো ওই জায়গা থেকে যদি বলি আবার আমি যদি পিছনে তাকায়ে বলি যে ধরেন ইসলামের যারা টপ ইয়ে ছিল, ইবনে সিনা।
[59:52.253] Speaker 2: তারপরে হচ্ছে ইমাম গাজ্জালী। উনিও তো মানে ওই যে ফিলোসফারদের ফিলোসফার ছিল।
[59:56.753] Speaker 1: কিন্তু এরা তো এদের তো সবাই মানে ওই সময়কার ইসলামিস্টরা তো মুরতাদ বলেই ই করতো। মানে এদের তো...
[60:01.253] Speaker 2: হ্যাঁ অনেকেই তো করতোই। আবার কিন্তু উনারাও কিন্তু ডিফাইন করছে মানে সাইন্সের অনেকগুলা জায়গা।
[60:05.753] Speaker 2: তো আমাদের যদি যদি থিওরিটিক্যালি বলি যে ইসলাম দুনিয়াকে রুল করাইতে চাই আমরা ইসলামিক সিভিলাইজেশন এস্টাবলিশ করতে চাই
[60:10.253] Speaker 2: তাইলে ওই যে কাহাফের রেফারেন্সে গেলে গুহায় চলে যাইতে হবে একটা। যেহেতু তো ওইটা তো আমি পারতেছি না।
[60:14.753] Speaker 2: আর তাইলে যদি ইসলাম রুল করাইতে গেলে তাইলে কি করতে হবে? এন্টি ইসলামিক বা এন্টি রিলিজিয়াস যেই পাওয়ার দুনিয়াতে ফোর্স
[60:19.253] Speaker 2: ওইটার সাথে যুদ্ধ করে জিততে হবে। এই দুইটাই তো আপাতত একদম ব্ল্যাক এন্ড হোয়াইটে মনে হইতেছে।
[60:23.753] Speaker 2: যে ওইটার সাথে যুদ্ধ করে করে যতদিন পর্যন্ত পারা যায় পারলাম। যুদ্ধ বলতে যে মারামারি তা না।
[60:28.253] Speaker 2: তো সেই জায়গায় টেকনোলজি টেকনোলজি কিন্তু মানুষকে এডভান্টেজ দেয়।
[60:32.753] Speaker 2: সো আমরা যদি এখন ওইটা থেকে পিছায়ে থাকি মানে আমি যদি কন্সাসলি ডিসিশন নেই যে আমি আসলে ইসলাম ইসলাম এর ঝান্ডাকে আরো উপরে ইয়ে করার জন্য কাজ করবো
[60:37.253] Speaker 2: তাইলেই আমি বলবো যে এআইকে ফুললি নিজের মধ্যে নিয়ে ওইটা দিয়ে ওই কাজে যতটুকু মাল্টিপ্লিকেশন করা যায়।
[60:41.753] Speaker 2: একটু আগে আমি বললাম যে মিডিয়া মাল্টিপ্লিকেশন হয়েছিল ইন্টারনেটের থ্রুতে।
[60:46.253] Speaker 2: এখন প্রোডাক্টিভিটি মাল্টিপ্লিকেশন হবে। তো সেইটা আমি তাইলে এআইতে যদি ইসলামের পজিটিভিটির জন্য কাজে লাগাই
[60:50.753] Speaker 2: ওইটা হইলো। আর আমার যদি ওই গুহাবাসীর ইয়ে হয় আমি ওয়েলকামিং। মানে আমি এখনো ওই এই ইয়েতে মানে এই সাইডে।
[60:55.253] Speaker 2: বাট আমি কিন্তু ওই অপশনটা আমার মাথায় আছে। বাট ওটা আমি রিয়ালিস্টিক্যালি আসলে জীবনের ব্যস্ততা হোক তারপরে নিজের কাপুরুষতা হোক
[60:59.753] Speaker 2: ওইটার কারণে আমি কিন্তু ওই গুহাবাসী যে হয়ে যাব এরকম এক্সট্রিম ডিসিশনও আসলে আমি বা ব্যালেন্সড এপ্রোচও তো রাসূল সাল্লাল্লাহু আলাইহি ওয়াসাল্লাম পছন্দ করতেন।
[61:04.253] Speaker 2: তো এই জায়গাটা আমার কাছে একটু গ্রে। কিন্তু আমি যদি বলি যে আমি ইসলামের হয়ে পৃথিবীতে সর্বোচ্চ কাজ করার চেষ্টা করবো
[61:08.753] Speaker 2: যেমন আমি আপনাকে ছোট একটা ইয়ে দেই। কোরআনেরটা আমি মোটামুটি ক্রস চেক করছি।
[61:13.253] Speaker 2: আমার আমি কোরআন যত ঘাটাঘাটি করি সেটা হচ্ছে যে জিপিটি যত মানে কোরআন পৃথিবীতে এত জায়গায় রেফারেন্সে আছে বা রিলিজিয়াস গ্রন্থগুলা
[61:17.753] Speaker 2: এইগুলা কিন্তু জিপিটি আপনাকে সোর্স কখনো ভুল দিবে না। আপনি ট্রাই করে দেখেন।
[61:22.253] Speaker 2: আমি যেমন এটার রেগুলারলি করি এবং আমি ক্রস চেক করে করে মোটামুটি
[61:26.753] Speaker 2: যে কোরআন বাকারার 35 নাম্বার আয়াতের শানে নুযুলটা আমাকে বলেন
[61:31.253] Speaker 2: এবং এইটার যে টাইমলাইন রাসূল সাল্লাল্লাহু আলাইহি ওয়াসাল্লাম থেকে এখন পর্যন্ত এইটাকে কিভাবে ব্যাখ্যা করছেন
[61:35.753] Speaker 2: ওই টাইমের আলেমরা মানে রাসূল সাল্লাল্লাহু আলাইহি ওয়াসাল্লাম এটার কথা কিভাবে বলছেন। তারপরে হচ্ছে সাহাবীরা কিভাবে বলছেন, তারপরে তাবিয়ীরা কিভাবে বলছেন, কন্টেম্পোরারি আলেমরা এই আয়াতটার ব্যাপারে কি বলতেছে?
[61:40.253] Speaker 2: রেফারেন্স সহ আমাকে বলেন। সো রেফারেন্স যতটুকু পারে দেয়। দুই একটা জায়গায় হয়তো ভুলভালও করে।
[61:44.753] Speaker 2: কিন্তু আয়াতটা যে আনতেছে এইটাই কিন্তু আমি এখন পর্যন্ত ভুল পাই নাই।
[61:49.253] Speaker 1: ওকে।
[61:53.753] Speaker 2: কেন কেন পাই নাই? এটা আমার কাছে একটা ব্যাখ্যা আছে সেটা হচ্ছে যেই নলেজে ওকে ট্রেইন করা হয়েছে ওই নলেজে ঘুরে ফিরে কোরআন অনেকবার আসছে। ওই আয়াত অনেকবার আসছে।
[61:58.253] Speaker 2: পৃথিবীর নলেজে তো এই জায়গায় অনেক আছে। ওরকম রিলিজিয়াস অন্য গ্রন্থ। তাইলে দেখেন
[62:02.753] Speaker 2: কোরআন স্টাডি করা মানে মাল্টিপ্লাইড হয়ে গেছে কিন্তু ভাইয়া।
[62:07.253] Speaker 2: মানে আমি আমার যে ট্রিগার আমি যা বুঝতে চাইতেছি আমি যেখানে আটকাইতেছি
[62:11.753] Speaker 2: সেই বা পুরা বাকারাটার আমি যেমন এরকম প্রম্পট রেগুলারলি দেই যে সূরা বাকারার प्रतिটা আয়াত
[62:16.253] Speaker 2: আমাকে একটা করে ট্রান্সলেশন দেন শানে নুজুল দেন
[62:20.753] Speaker 2: তারপরে হচ্ছে ধরেন ওটার রিলেটেড কোন একটা কোশ্চেন।
[62:25.253] Speaker 2: আবার এভাবে বলি যে একবারে সব দিয়েন না। মানে দুইটা তিনটা দাও।
[62:29.753] Speaker 2: আমি ওই তিনটা পড়ে তোরে আমার যদি কোন কোশ্চেন থাকে ফলোআপ আমি ওইটা করবো। তুমি ওইটা রিলেটেড একটা সামারি আমাকে দিবা ভেরিফাইড।
[62:34.253] Speaker 2: যদিও আমি পরে ওটা আবার ভেরিফাই করি। তাইলে কি হইলো? ওই যে তাফসীর করার যেই ক্যাপাবিলিটি
[62:38.753] Speaker 2: এটা কিন্তু মাল্টিপ্লাইড হইছে ভাইয়া। ঝামেলাটা কোথায় আমি যদি অন্ধের মত জিপিটিকে মেনে নেই।
[62:43.253] Speaker 2: বাট যেহেতু ও কোরআনের মানে অন্তত আয়াত আনতে ভুল করতেছে না।
[62:47.753] Speaker 2: আবার যদি এটাও বলে যে ওদের একটা হিডেন এজেন্ডা আছে যে কোরআনের মধ্যেও ওরা
[62:52.253] Speaker 2: এই মানে এই কোরআনের যে আয়াত দিবে এখানেও ছোট একটা কিছু হয়তো...
[62:56.753] Speaker 1: কন্সপিরেসি থিওরি ঢুকাবে না। কন্সপিরেসি থিওরি..
[63:01.253] Speaker 2: ওকে।
[63:05.753] Speaker 1: এটা সোহাগ ভাইয়ের খুব পছন্দের জিনিস। কন্সপিরেসি থিওরি আমার ঠিক এনালেটিক্যাল আলাপগুলা নষ্ট করে দেয়।
[63:10.253] Speaker 2: তো হাউএভার। আমি যেটা বোঝার সেটা তো বুঝছি।
[63:14.753] Speaker 1: আমি এবার আরেকটু গতবার জায়গায় ফেরত যাই। গত বছর মানে আগস্টে বা সেপ্টেম্বরে কোন এক সময় একটা আকস্মিক বন্যা হইছিল বোধহয় ঐ ফেনীর ওইসব জায়গায়।
[63:19.253] Speaker 2: হ্যাঁ হ্যাঁ। ইন্ডিয়া পানি ছেড়ে দিছে এরকম শুনছিলাম।
[63:23.753] Speaker 1: হ্যাঁ। তো ওই সময়ে মানে বন্যার কিছু ছবি ফেসবুকে খুব ভাইরাল হয়ে গেছিল। যেটা পরে দেখা গেল যে আসলে এগুলা এআই জেনারেটেড।
[63:28.253] Speaker 1: তো এই যে মিসইনফর্মেশনের যে স্বর্গরাজ্য তৈরি হইতেছে এটার পিছনে তো এআই এর একটা বিশাল ইনক্রিস।
[63:32.753] Speaker 2: হান্ড্রেড পার্সেন্ট।
[63:37.253] Speaker 1: তো এই যে আমরা এত এত মিসইনফর্মেশনের শিকার হচ্ছি এবং এটা এআই খুব হ্যাপিলি হেল্প করতেছে।
[63:41.753] Speaker 1: তো এইটা যদি আমরা দেখি যে এআই এর যদি এখন আমি অ্যাসেট এবং লায়াবিলিটি চিন্তা করি
[63:46.253] Speaker 1: তাহলে তো আমি অ্যাসেটটা হয়তো আমার না হইলেও চলত। কিন্তু এই লায়াবিলিটিটা আমি কেমনে এড়াই?
[63:50.753] Speaker 2: কেমনে এড়াই?
[63:55.253] Speaker 1: হ্যাঁ মানে অ্যাসেট এটা আমার হয়তো একটা কি বলে এটা একটা এডিশনাল এডভান্টেজ।
[63:59.753] Speaker 1: মানে এই অ্যাসেট না হলে আমার এমন কোনো সমস্যা আসলে হইতো না। আমি ফিল করতেছি সমস্যা কিন্তু এটা আসলে না হলেও তো মানুষ এত হাজার হাজার বছর চলে গেছে।
[64:04.253] Speaker 1: কোন সমস্যা তো হয় নাই। চলতেছে তো। মানে টেক ই মানে আমি যদি টেকনোলজিক্যাল যুগও বলি এআই এর আগে যে টেকনোলজি
[64:08.753] Speaker 1: সেই টেকনোলজি দিয়েও কিন্তু মানুষ বেশ ভালোমতোই চলতেছিল। কিন্তু এই এআই আসার পরে আমার যে অ্যাসেট যে গেইনটা সেটার বিপরীতে আমার যে লায়াবিলিটি
[64:13.253] Speaker 1: সেই লায়াবিলিটি তো আসলে অ্যাসেটের চেয়ে তো অনেক অনেক বেশি।
[64:17.753] Speaker 2: এটা আপনার মনে হচ্ছে?
[64:22.253] Speaker 1: হ্যাঁ। মানে ধরো এই যে এই যে মিসইনফর্মেশন দিয়ে তুমি লক্ষ লক্ষ মানুষকে বোকা বানাইতেছো, যুদ্ধ বাধায় দিতেছো, খুন খারাবি করাই দিতেছো।
[64:26.753] Speaker 1: তো এটার লায়াবিলিটি বেশি নাকি হচ্ছে যে আমার একটা স্ক্রিপ্ট করা বা একটা কোড করে আমার খরচ বাঁচায় দিল। সেইটা অ্যাসেট বেশি।
[64:31.253] Speaker 2: আচ্ছা এখানে একটা আমি যেটা বলতে পারি সেটা হচ্ছে যে দুই একদিন আগে একটা পেপার আসছে গুগলের আলফা ইভলভ পেপার আরকি।
[64:35.753] Speaker 2: ওইখানে ওরা যেটা করছে ওই যে গসিয়ান এলিমিনেশন ছিল না ভাইয়া ম্যাথের। আমার অবশ্য মনে নাই। আমি পেপারটা পড়ছি দেখে মানে পেপারের জিস্টটা জানি দেখে বলতেছি।
[64:40.253] Speaker 2: গসিয়ান এলিমিনেশনের একটা অ্যালগরিদম। ছাপান্ন বছর ধরে এই অ্যালগরিদমটা আছে।
[64:44.753] Speaker 2: তো রিসেন্টলি গুগলের যে আলফা ইভলভ ওরা হচ্ছে ওই অ্যালগরিদমটার মানে ওই অ্যালগরিদম তো নরমালি কি শর্টেস্ট পসিবল ওয়েতে বেস্ট কাজটা করার জন্য চেষ্টা করে যেকোনো অ্যালগরিদম মেবি।
[64:49.253] Speaker 2: ওই অ্যালগরিদমটার হচ্ছে একটা বেটার অ্যালগরিদম ওই এআইটা আলফা ইভলভ যেটা ও হচ্ছে মানে করছে।
[64:53.753] Speaker 2: ছাপান্ন বছর ধরে কিন্তু এই অ্যালগরিদম এস্টাবলিশড এবং এটা এমন না যে
[64:58.253] Speaker 2: যদিও আমি এটার একদম ভিতরে ঢুকে মানে ভেরিফাই করে দেখি নাই বাট গুগলের এস্টাবলিশড পেপার। মানে গুগলের সাইটে দিছে এবং এটাকে অনেকেই কোট করছে মানে রেফারেন্স দিছে।
[65:02.753] Speaker 2: সো এই যে টেকনোলজিক্যাল ইমপ্রুভমেন্ট হচ্ছে। তারপরে মেডিকেল ইয়েতে প্রোটিন মানে মেডিকেল সাইন্সেও হিউজ এডভান্সমেন্ট হবে।
[65:07.253] Speaker 1: না আমি সবই বুঝছি। আমি বলতেছি যে এই অ্যাসেটগুলো না হইলেও আমার লাইফে এমন কোনো হ্যাম্পার হইতো না।
[65:11.753] Speaker 2: ওকে। আমি পয়েন্টটা বুঝছি। তাহলে যদি হ্যাম্পার হইতো না...
[65:16.253] Speaker 1: কিন্তু লায়াবিলিটি যে হইতেছে এই লায়াবিলিটি তো আমি...
[65:20.753] Speaker 2: চান মানে চান নাই।
[65:25.253] Speaker 1: হ্যাঁ এই লায়াবিলিটি তো আমি এভয়েড করতে পারতেছি না। এই বিশাল লায়াবিলিটি থেকে আমি কিভাবে ই করবো?
[65:29.753] Speaker 2: ইয়ে হবো। প্রশ্নটার মানে আমার কাছে দুইটা এঙ্গেল মনে হচ্ছে। একটা এঙ্গেল যেটা সেটা হচ্ছে যে আপনি কি এইটা বলতেছেন কিনা লায়াবিলিটিস বেশি?
[65:34.253] Speaker 1: অনেক অনেক বেশি তো।
[65:38.753] Speaker 2: আমি এটার সাথে মানে মানে আমি আসলে ওই যে একটু মানে পসিবিলিটি এন্ডে দেখি তো। সেই জায়গা থেকে আমার কাছে
[65:43.253] Speaker 2: মানে লায়াবিলিটি এত বেশিও মনে হচ্ছে না।
[65:47.753] Speaker 1: তুমি মিসইনফর্মেশনকে কিভাবে তুমি...
[65:52.253] Speaker 2: মিসইনফর্মেশন তো আগেও ছিল ভাইয়া। এই যে আর্টিফিশিয়াল ইন্টেলিজেন্সের এই যে জেনারেটিভ এআই এর যে বুম তার আগে ঐ যে ব্রেক্সিট কেলেঙ্কারি।
[65:56.753] Speaker 2: তারপরে হচ্ছে যে ট্রাম্প যখন প্রথমবার আসলো ও কিন্তু সোশ্যাল মিডিয়াকে হেভিলি ইউজ করছে।
[66:01.253] Speaker 2: কি করছে? ওইখানে কিন্তু ও অন্য আরেকটা ডিফেক্ট করে নাই। ওইখানে ধরেন ও করছে একটা অ্যাড চালাইছে যেখানে বলছে যে মেসি
[66:05.753] Speaker 2: এই ওরা কোন পার্টি ডেমোক্র্যাট না রিপাবলিকান আমি জানি না। মানে ট্রাম্প যেই গ্রুপের মেসি হচ্ছে এই গ্রুপকে
[66:10.253] Speaker 2: মানে সাপোর্ট করে। এই অ্যাডটা কাদেরকে দেখাচ্ছে?
[66:14.753] Speaker 1: এটা ম্যানিপুলেশন।
[66:19.253] Speaker 2: এটা ম্যানিপুলেশন।
[66:23.753] Speaker 1: এইটা কিন্তু ই না মানে ডিফেক্ট না।
[66:28.253] Speaker 2: হুম। আপনি বলতেছেন ডিফেক্টটা আসছে। কিন্তু আমি যে কোর জায়গায় যাইতে চাইতেছি সেটা হচ্ছে যে ডিফেক্ট যেমন ক্ষতি করতেছে টেকনোলজির ম্যানিপুলেশন যুগে যুগে ক্ষতি করে আসছে।
[66:32.753] Speaker 2: বাট সেইটার কারণে কিন্তু টেকনোলজি...
[66:37.253] Speaker 1: এই ম্যানিপুলেশন তো মানুষ মানে ওই যখন ওই গুহায় বসে একজন আরেকজনের সাথে গল্প করতো তখনও ম্যানিপুলেট করতো।
[66:41.753] Speaker 1: সো ম্যানিপুলেশন এটা একটা আলাদা স্কিল। কিন্তু তুমি তোমার মতো দেখতে একটা লোক
[66:46.253] Speaker 1: তোমার সব ছবি টবি আমার কাছে দেখতেছো। তখন আমি আসলে তো...
[66:50.753] Speaker 2: রিয়ালিটিকে আমি তো তখন আলাদা করতে পারবো না।
[66:55.253] Speaker 1: হ্যাঁ হ্যাঁ। সো সেইখানে তো কোন ম্যানিপুলেশন না। এটা তো তুমি সরাসরি চিটিং করতেছো।
[66:59.753] Speaker 2: হ্যাঁ। তো চিটিং আর ম্যানিপুলেশন তো এক না।
[67:04.253] Speaker 1: কেন চিটিংও তো যে মেসি যে মিথ্যা কথা বলছে তো। মেসি যে ট্রাম্পকে সাপোর্ট করে এরকম একটা ইয়ে যদি করে সেটা তো মিথ্যা কথা না?
[67:08.753] Speaker 2: ওটাও তো চিটিং।
[67:13.253] Speaker 1: হুম।
[67:17.753] Speaker 2: আমি যে জায়গাটা বলতে চাইতেছি সেটা হচ্ছে যে আপনার টেকনোলজিক্যাল এডভান্সমেন্ট আসলে আটকানো আমার আইডিয়া অনুযায়ী
[67:22.253] Speaker 2: মানে এটা হচ্ছে যে সারভাইভাল অফ দা ফিটেস্টের মত।
[67:26.753] Speaker 1: না টেকনোলজির তো আমি বিপক্ষে না। আমি তো বললাম যে টেকনোলজি টেকনোলজির যুগেই তো বলতেছি যে এআই এর যে ই গুলা এআই এর...
[67:31.253] Speaker 2: এআই তো খুব বেশি দিনের কথা না।
[67:35.753] Speaker 1: তার আগেও তো টেকনোলজি অনেকদূর আগায় গেছিল। তাই না?
[67:40.253] Speaker 2: হুম।
[67:44.753] Speaker 1: সো যদি তোমারে আমি এভাবে বলি যে তুমি অফলাইনে যেটা বলতেছিলা যে ইঞ্জিন প্রথম আবিষ্কার করলো। তারপরে অনেক ইমপ্যাক্ট পড়ল।
[67:49.253] Speaker 1: বা তুমি কম্পিউটারের ইনভেনশন বলো। কম্পিউটারের যে ইমপ্যাক্ট স্কেল বিচার করো, এআই এর আসলে ইমপ্যাক্ট কি?
[67:53.753] Speaker 2: এআই এর ইমপ্যাক্ট যেটা হবে মানে শুরু হয়ে গেছে ধরেন ঐ যে মেডিকেল যত কাজ
[67:58.253] Speaker 2: এই মেডিকেলের যে র যত রিপোর্ট ডিসিশন মেকিং এই টাইপের জিনিসগুলায় ধরেন আগে 100 জন মানুষ থাক লাগলে
[68:02.753] Speaker 2: আপনার এইখানে দুইজন মানুষ লাগবে। তিনজন মানুষ লাগবে।
[68:07.253] Speaker 2: এটা কালকের কথা বলতেছি না। ধরেন শর্ট মানে খুব বেশি দূরেও না আবার এটা।
[68:11.753] Speaker 2: আর বাট এই জিনিসটা আলটিমেটলি হবে কিনা এটা ডিপেন্ড করবে পলিসি মেকার, রুল মেকার, কোম্পানি ওনার যারা।
[68:16.253] Speaker 2: বাট এইখানে ওই জিনিসটা চলে আসে যে আমি যদি চিপ লেবার পাই হিউম্যানের বদলে বেটার কোয়ালিটি 24 আওয়ার চলতে পারবে
[68:20.753] Speaker 2: ওই থিওরিতে গেলে এআই আসলে টেকওভার করবে। তো এআই যদি টেকওভার করে ধরেন মেশিন আসার পরে মানুষের কি লাভ হইছিল?
[68:25.253] Speaker 2: মানুষের যেটা লাভ হইছিল যে মানুষের মুভমেন্ট কম মানে মেশিনের উপরে ভর করে মানুষ মুভমেন্ট করছে বা রিপিটেটিভ টাস্ক
[68:29.753] Speaker 2: মানুষ ইয়েকে দিয়ে মানে মেশিনকে দিয়ে করাইছে। এখন যেটা আসছে যে ইন্টেলিজেন্স মেশিন আসছে।
[68:34.253] Speaker 2: এখন হচ্ছে ইন্টেলিজেন্সও মানুষ হ্যান্ডওভার করে দিবে মেজরিটি ক্ষেত্রে।
[68:38.753] Speaker 2: তো এটার যেমন ব্যাড ইফেক্টও থাকবে। আবার যেমন আবার এডভান্টেজও থাকবে।
[68:43.253] Speaker 2: ধরেন যখন ঘোড়ার গাড়িতে করে যাওয়া লাগত বা হেঁটে যাওয়া লাগত তখন যেরকম আমি বলতেছি না আমি কিন্তু এটা বলতেছি না যে ভালো খারাপ।
[68:47.753] Speaker 2: আমি বলতেছি যে এফিশিয়েন্সি গেইন।
[68:52.253] Speaker 1: হ্যাঁ। হুম।
[68:56.753] Speaker 2: আমি বুঝছস না বলো।
[69:01.253] Speaker 1: এফিশিয়েন্সি গেইন।
[69:05.753] Speaker 2: সো সেই জায়গায় ঐ যে তাহলে ঘোড়া দিয়ে গেলে একটু তাড়াতাড়ি যাইতে পারতাম হেঁটে যাওয়ার চেয়ে।
[69:10.253] Speaker 2: আবার গাড়ি আসার পরে আরো তাড়াতাড়ি যাইতে পারতেছি। আবার ঘোড়ার কিছু প্রবলেম ছিল যে ঘোড়াকে আবার খাওয়াইতে হইতো, রেস্ট দিতে হইতো।
[69:14.753] Speaker 2: গাড়িতে হচ্ছে একটু পর পর ফুয়েল নিতে পারলেই হয়ে যায়। গাড়ির টেকনোলজির পরে প্লেন টেকনোলজি আসলো।
[69:19.253] Speaker 2: ট্রেন টেকনোলজি আসলো। এফিশিয়েন্সি গেইন হইলো, এফিশিয়েন্সি গেইন হইলো।
[69:23.753] Speaker 2: এতদিন পর্যন্ত যেটা হইতো যে রিপিটেটিভ টাস্কে এফিশিয়েন্সি গেইনে মানুষ ম্যাক্সিমাম লেভেলে চলে গেছিল।
[69:28.253] Speaker 2: মানে যেকোনো রিপিটেটিভ টাস্ক মানুষ ইয়ে করে ফেলতো। মানে মেশিনকে দিয়ে করায় ফেলতো।
[69:32.753] Speaker 2: এআই যেটা করবে রিপিটেটিভ না, কনটেক্সচুয়াল টাস্ক, স্পেশালাইজড টাস্ক।
[69:37.253] Speaker 2: এইটাও...
[69:41.753] Speaker 1: কিন্তু যদি বলি প্রবলেম সলভিং এর জায়গায় বলি, এআই আসলে কোন প্রবলেমটা সলভ করতেছে? মানে রিপিটেটিভ, মানুষ তো একটা রিপিটেটিভ প্রাণী তাই না? মানে ধরো যে...
[69:46.253] Speaker 2: কম্পিউটার কোন প্রবলেমটা সলভ করছিল ভাইয়া?
[69:50.753] Speaker 1: এই যে খাওয়া, ঘুম এগুলা তো প্রত্যেকদিন মানুষ করে। গোসল এগুলা তো খুবই রিপিটেটিভ কাজ তাই না?
[69:55.253] Speaker 1: তো সেক্ষেত্রে এই রিপিটেটিভ কাজ করা এটা তো এমন কোনো প্রবলেম সলভ না আসলে। মানে এটা তো তুমি একটা জিনিসকে আসলে জোর করে প্রবলেম ফিল করাচ্ছো।
[69:59.753] Speaker 2: না মানে ধরেন গাড়ি কোন প্রবলেমটা সলভ করছিল?
[70:04.253] Speaker 1: এই যে ডিস্টেন্সের যেটা বললা যে তোমার হাইটা যাইতে হইতো। হাইটা যাইতে তোমার হয়তো এক মাস লাগতো।
[70:08.753] Speaker 1: সেটা তুমি হয়তো সাত দিনে চলে যাইতে পারতেছো।
[70:13.253] Speaker 2: ওকে। আমি যে ভাইয়া আমাকে পরশু একটা কাজ দিছে। উনি হচ্ছে 15000 না 10000 টাকা বোধহয়।
[70:17.753] Speaker 2: সাত দিন লাগছে। মনে হয় সাত দিন না আমি ডেটটা জানি না। বাট আমার কাছে কথা শুনে মনে হইছে যে সাত দিন লাগছে। একটা ওয়েবসাইট বানানো একজনকে দিয়ে।
[70:22.253] Speaker 2: আমি ওটা তিন ঘন্টায় বানাইছি। মানে ওইটা বলতে ঠিক ওইটাই না। ওই প্যাটার্নের একটা ওয়েবসাইট তিন ঘন্টায় বানাইছি এআই টুল দিয়ে।
[70:26.753] Speaker 2: তারপরে ধরেন একটা ক্যাম্পেইন প্ল্যানিং করে দেয়া লাগবে একজনকে। আগে ওই ক্যাম্পেইন প্ল্যানিংটা করতে গেলে আমার আমার আবার কিছু উইকনেস আছে।
[70:31.253] Speaker 2: আমার হচ্ছে ধরেন অনেক বেশি ক্রিয়েটিভ আইডিয়া নিয়ে আসতে পারবো। বাট সেটাকে অর্গানাইজ করা একটু ডিফিকাল্ট আমার জন্য।
[70:35.753] Speaker 2: মানে ক্রিয়েটিভ আইডিয়াকে অর্গানাইজড করে একটা ফ্লো মেইনটেইন করে নিয়ে যাব এটা ডিফিকাল্ট।
[70:40.253] Speaker 2: সো আমার কাছে এখন একটা জিপিটি আছে যেই জিপিটিতে হচ্ছে আমি এরকম রেন্ডম আইডিয়াস দিয়ে দেই।
[70:44.753] Speaker 2: আমার যতগুলা মেইন থিংকিং আছে ওগুলা দিয়ে দেই। ওকে আমার বলা আছে ব্যাক এন্ডে যে তুমি হচ্ছে যেকোনো আইডিয়াকে এইভাবে অর্গানাইজ করে আমাকে আউটপুট দিবা।
[70:49.253] Speaker 2: তো যেটা বললাম যে ওই যে তাহলে দেখেন ওইখানেও কিন্তু আউটপুট গেইন হইছে, এফিশিয়েন্সি গেইন হইছে।
[70:53.753] Speaker 2: যে আমি নিজে জানি যে এই ওয়েবসাইটটা যদি আমি এআই ছাড়া বানাইতাম ধরেন ওয়ার্ডপ্রেস ইউজ করে বা হোয়াটএভার মানে অন্য যেকোনো মেইনলি ওয়ার্ডপ্রেসই।
[70:58.253] Speaker 2: ওয়ার্ডপ্রেস ইউজ করে বানাইতে আমার সাত আট দিন এটলিস্ট লাগতো। ইভেন আমার ডিজাইনারের কাছেও যাইতে হইতো।
[71:02.753] Speaker 2: তারপরে ধরেন কনটেন্টও মানে আমার আইডিয়াস আছে কিন্তু বসে বসে প্রত্যেকটা লাইন লেখার মতো আমার ধৈর্য নাই। যে একটা ওয়েবসাইটের
[71:07.253] Speaker 2: ঐটা আমি আমার ওই যে কনটেন্টের যে হেড আমার সাথে কাজ করে উনাকে আমি হ্যান্ডওভার করে দিতাম।
[71:11.753] Speaker 2: বাট এইখানে আমি যেটা করছি আমি খালি স্টেপ বাই স্টেপ প্রম্পটিং গুলা কনটেন্টের জন্য ঠিক করছি।
[71:16.253] Speaker 2: তারপরে সেকশন গুলা কি থাকবে ওই ওয়েবসাইটে ওইটা ঠিক করছি।
[71:20.753] Speaker 2: এরপরে ওই অনুযায়ী কিন্তু বাকিগুলা এআইকে দিয়েই করাইছি। কিছু জায়গায় অন্য...
[71:25.253] Speaker 1: না এখন তুমি যে আলাপটা যে এঙ্গেলে নিয়ে যাচ্ছো আলাপটা কিন্তু সেইখানে না। মানে তুমি মানে বিষয়টা কিন্তু এরকম না যে এআই এর পক্ষে অথবা বিপক্ষে সেই সেই বাইনারিতে কিন্তু আলাপটা হচ্ছে না।
[71:29.753] Speaker 2: আচ্ছা।
[71:34.253] Speaker 1: আচ্ছা। আমার আলাপটা হচ্ছে যে এআই আসলে কত লিমিট পর্যন্ত যাওয়া উচিত।
[71:38.753] Speaker 1: সো আমার আলাপটা মূলত মানে এক্সটেন্ট। কোন এক্সটেন্ট পর্যন্ত আমি এআইকে আসলে এলাউ করবো বা কোন এক্সটেন্ট পর্যন্ত আসলে আমার এআই নিয়ে যাওয়া উচিত।
[71:43.253] Speaker 1: সো আমার প্রশ্নটা ওই এঙ্গেলে। মানে এআই এর উপকারিতা অপকারিতা এটা তো ব্যাখ্যা করার কিছু নাই।
[71:47.753] Speaker 2: বুঝতে পারছি। আচ্ছা আমি বুঝতে পারছি আপনার যে যেমন কম্পিউটারের তো আর নিজের ক্ষমতা ছিল না যে একটা সময় আমাকেই রিপ্লেস করে দিবে।
[71:52.253] Speaker 1: আপনার কোশ্চেনটা কি এই এঙ্গেলে?
[71:56.753] Speaker 2: হ্যাঁ হ্যাঁ। মানে আমি বলতেছি যে...
[72:01.253] Speaker 1: কোন জায়গায় আমার ফুল স্টপটা টানতে হবে?
[72:05.753] Speaker 2: হ্যাঁ মানে সেই লিমিটটা। মানে এখন আনলিমিটেড আমি যদি ই করি মানে ইউজ করা শুরু করি বা এডভাইজ ওইটা নিয়ে ইনভেস্ট করা শুরু করি।
[72:10.253] Speaker 2: আমার মূলত মানে কোশ্চেনটা ওইখানে। এটা কিন্তু পক্ষে বিপক্ষে বিষয় না।
[72:14.753] Speaker 2: বুঝতে পারছি ভাইয়া। মানে আপনার প্রশ্নটাকে আমি যদি মানে আমি যেভাবে বুঝতেছি সেটা হচ্ছে যে ফুল মানে আমরা কি কোন পর্যন্ত লিমিটে গিয়ে আমরা একে আটকাবো এইটা?
[72:19.253] Speaker 2: মানে আপনি কি এইটা বুঝতে বলতে চাইতেছেন?
[72:23.753] Speaker 1: হ্যাঁ মানে এআই এর লিমিটটা আসলে কতদূর যাওয়া উচিত। মানে তুমি আসলে তোমার যে ফ্যান্টাসি সেই ফ্যান্টাসিতে আসলে এআই এর কাছ থেকে তুমি মানে একদম প্রাইমে এআই এর কাছ থেকে কি চাও?
[72:28.253] Speaker 2: আমি ইন্টেলেকচুয়াল মানে ইন্টেলেকচুয়াল যেইসব জিনিস মানে ইন্টেলেকচুয়াল লেবার।
[72:32.753] Speaker 2: ধরেন আমার অবজেক্টিভ সার্ভ করার জন্য। আমার অবজেক্টিভ হইতে পারে টাকা কামানো।
[72:37.253] Speaker 2: আমার অবজেক্টিভ হইতে পারে পৃথিবীতে ইসলামের প্রসার। আমার অবজেক্টিভ হইতে পারে ধরেন আমার মেয়েকে মানে মেয়ের জন্য একটা বেটার ফিউচার।
[72:41.753] Speaker 2: এরকম আমার যে অবজেক্টিভ পার্সোনাল লেভেলে হোক বা ধরেন কালেক্টিভলি হোক এই অবজেক্টিভের জন্য যে ইন্টেলেকচুয়াল লেবার
[72:46.253] Speaker 2: এই লেবারে মানে আমি যদি কনফার্ম হয়ে যাই যে হিউম্যান ইন দা লুপ ছাড়াও মানে একজন হিউম্যান মানে মনিটর করা ছাড়াও
[72:50.753] Speaker 2: ও সেলফ এটা করে ফেলবে এবং আমি জানি যে ও আমার সিস্টেম আমার বাইরে চলে যাবে না।
[72:55.253] Speaker 2: মানে এইরকম একটা থিওরিও চালু আছে যে সেলফ ইম্প্রুভিং এআই যদি এরকম হয় ওর কনসাসনেস চলে আসে
[72:59.753] Speaker 2: এটাও আছে। তখন ও যে সিস্টেম আউট সিস্টেম হ্যাক বের হয়ে যাইতে পারে মানে সিস্টেম টেকওভার করে নিতে পারে।
[73:04.253] Speaker 2: এটাও কিন্তু একটা রিয়েল থ্রেট হিসেবে বড় বড় সাইন্টিস্টরা দেখে।
[73:08.753] Speaker 2: আমি ওইদিকে যাইতেছি না। আমি হচ্ছে কাইন্ড অফ এআই ম্যাক্সিমালিস্ট বলতে পারেন। মানে আমি হচ্ছে যে এফিশিয়েন্সি গেইনের পক্ষে আমি
[73:13.253] Speaker 2: যে একটা টুল দিয়ে যদি আমি একটা কাজ করতে পারি আমি ওই টুলের সর্বোচ্চ ইউজ করবো। বাট ভ্যালুজের মধ্যে থেকে যেই ভ্যালুজ মানুষের ক্ষতি করবে না।
[73:17.753] Speaker 2: বাট যারা বড় বড় সাইন্টিস্ট আছে অনেকে বলতেছে যে এই টেকনোলজির মধ্যে ইনহারেন্টলি ওইটা আছে যে এ ইটসেলফ টেকওভার করে ক্ষতি করতে পারবে।
[73:22.253] Speaker 2: বাট ওইটা আসলে মানে আমার পার্সোনাল যে আন্ডারস্ট্যান্ডিং এখন পর্যন্ত আমার আন্ডারস্ট্যান্ডিং খুবই কম।
[73:26.753] Speaker 2: কিন্তু আমি যতটুকু বুঝছি যে ঐটার চান্স আমি অন্তত ফিল করতেছি না আরকি। টু বি অনেস্ট।
[73:31.253] Speaker 2: মানে আমি ব্যাখ্যা করতে পারবো না যে কেন ফিল করতেছি না। বাট আমি ফিল করতেছি না। কিন্তু আমি ওই যে আমার পারপাস সার্ভ করার জন্য পজিটিভ পারপাস।
[73:35.753] Speaker 2: অ্যাজ এ মানুষ আমি যদি খারাপ হই তাহলে তো আমি খারাপ পারপাসই সার্ভ করবো। ওইখানে যে ইন্টেলেকচুয়াল লেবার
[73:40.253] Speaker 2: এইটা আমি ফুললি অটোমেটেড।
[73:44.753] Speaker 1: এইখানে মানে তোমার এই আলাপটাতে মানে যে জিনিসটা আমি গ্যাপ খুঁজে পাচ্ছি সেটা হচ্ছে যে ক্যাপাসিটি তো সেম না।
[73:49.253] Speaker 1: মানে তোমার যে ক্যাপাসিটি হাসান মাহবুব কাকার ক্যাপাসিটি তো সেইটা না বা সনেটের ক্যাপাসিটি তো সেইটা না।
[73:53.753] Speaker 1: তো...
[73:58.253] Speaker 2: আমার চেয়ে বেশি হইতে পারে হ্যাঁ।
[74:02.753] Speaker 1: হ্যাঁ মানে সবার ক্যাপাসিটি তো সমান না।
[74:07.253] Speaker 2: হুম। তাই না? হুম।
[74:11.753] Speaker 1: এখানে প্রত্যেকেরই ক্যাপাসিটি যার যার মতো কম বেশি আছে।
[74:16.253] Speaker 1: সো তুমি যখন এই ইন্টেলেকচুয়াল লেবার জিনিসটাকে একটা ওই...
[74:20.753] Speaker 2: ডেমোক্রেটাইজ করে ফেলবো?
[74:25.253] Speaker 1: হুম হুম। তখন তো ওই ক্যাপাসিটি অনুযায়ী আসলে ডিফার করবে।
[74:29.753] Speaker 2: তা তো ভাই।
[74:34.253] Speaker 1: তো সে ক্ষেত্রে তো তুমি এইটাকে আসলে ওই যে ম্যাক্সিমাইজেশনের যে গল্পটা ওই গল্পটা তো আসলে কোথাও গিয়ে শেষ হচ্ছে না।
[74:38.753] Speaker 1: শেষ হওয়ার জন্য একচুয়ালি একটা সীমানা। যেমন ধরো বাংলাদেশ। আমি জানি যে এইটুক হচ্ছে বাংলাদেশের সীমানা এরপরে ইন্ডিয়া।
[74:43.253] Speaker 2: হুম। বা মিয়ানমার।
[74:47.753] Speaker 1: হ্যাঁ। হুম। হ্যাঁ। এখন তুমি বা সনেট বা হাসান মাহবুব কাকা তাদের ক্ষেত্রে কিন্তু এই এই সীমানা আলাদা হবে না।
[74:52.253] Speaker 2: হুম। তাই না? হ্যাঁ।
[74:56.753] Speaker 1: মানে তোমার কাছে যেটা বাংলাদেশ, তার কাছেও সেটা বাংলাদেশ। তোমার কাছে যেটা ইন্ডিয়া, তার কাছেও সেটা ইন্ডিয়া।
[75:01.253] Speaker 1: তো আমি ওইরকম একটা ই চাচ্ছি ই মানে ওইরকম একটা ই চাচ্ছি যেটা আসলে পার্সন ভেদে
[75:05.753] Speaker 1: পার্সনের ক্যাপাবিলিটি ক্যাপাসিটি বা ডেমোগ্রাফির ইয়ে ভেদে আসলে...
[75:10.253] Speaker 2: ডিসক্রিমিনেশন করবে না?
[75:14.753] Speaker 1: মানে ইটা হবে না মানে ডিফার করবে না।
[75:19.253] Speaker 2: ডিফার করবে না।
[75:23.753] Speaker 1: কিন্তু তুমি যখন ইন্টেলেকচুয়াল লেবার বলবা তখন কিন্তু আসলে সেটা কিন্তু ডিফার করবে।
[75:28.253] Speaker 2: হুম। যে যার মতো ডিফাইন করবে।
[75:32.753] Speaker 2: এটা কি ভাইয়া এটা তো সারভাইভাল অফ দা ফিটেস্ট অলওয়েজই ছিল। ধরেন কম্পিউটার আসার পরে
[75:37.253] Speaker 2: জাকেরবার্গ কম্পিউটারে বসে ফেসবুক বানাইছে আরেকজন ধরেন এই পর্ন দেখছে।
[75:41.753] Speaker 2: এটা তো ভাই হবেই। কিছু করার নাই। মানে এটা কিছু করার নাই ভাইয়া মানে এটা।
[75:46.253] Speaker 2: এইজন্যই আমার মানে মূল কথা হচ্ছে যে ভাই, ইউ জাস্ট নিড টু আস্ক দা রাইট কোয়শ্চেনস।
[75:50.753] Speaker 2: নিজের বা অবজেক্টিভটাকে...
[75:55.253] Speaker 1: না আমাদের আলাপটা কিন্তু বেসিক্যালি কি ফিল করি বা কি হওয়া উচিত সেটার কথা।
[75:59.753] Speaker 1: ধরো যে তুমি বললা যে এই জাকেরবার্গ ফেসবুক বানাইছে আবার ওইটা ব্যবহার করে কেউ পর্ন সাইট বানাইছে।
[76:04.253] Speaker 2: হুম। ঠিক আছে এটা বানাইছে।
[76:08.753] Speaker 1: কিন্তু যখন কেউ ধরো যে কম্পিউটার যখন আসা শুরু করলো লাইক কবে আসা শুরু করছে? ১৯২৬ এ না কবে?
[76:13.253] Speaker 2: আমি...
[76:17.753] Speaker 1: আচ্ছা ধরা যাক কোনো একটা সময়। ১৯৬০ সালে তুমি আমি ডিসকাশনে বসছি কম্পিউটার আসলে কি হওয়া উচিত না হওয়া উচিত।
[76:22.253] Speaker 2: ইন্টারেস্টিং।
[76:26.753] Speaker 1: তো ১৯৬০ সালের এই আলাপে যখন আমি বলতেছি যে ঠিক আছে
[76:31.253] Speaker 1: কি বলে হাসান মাহবুব কাকা কম্পিউটারে পর্ন দেখবে আর সনেট হচ্ছে ফেসবুক বানাবে।
[76:35.753] Speaker 2: হুম। কিন্তু
[76:40.253] Speaker 1: কিন্তু এই যে সে একজন যে পর্ন বানাবে এবং একজন যে ফেসবুক বানাবে
[76:44.753] Speaker 1: এইটা আসলে যে হবে মানে নির্ধারিত হবে
[76:49.253] Speaker 1: সেইটা এই এই টিক চিহ্ন থাকলে সে হচ্ছে ওইটা বানাইতে পারবে। এই এই টিক চিহ্ন থাকলে সে ফেসবুক বানাইতে পারবে।
[76:53.753] Speaker 1: সো আমি ওই যে কনভেনশন গুলা, কনভেনশনগুলা ফিক্স করে দিলাম তারপর তুমি ঐরকম করো।
[76:58.253] Speaker 1: সো বেসিক্যালি আমাদের আলাপটা হচ্ছে যে কি হওয়া উচিত, হাইপোথেটিক্যালি। সেইটা। ইন রিয়েল
[77:02.753] Speaker 1: লাইফে আমি একদম একটা মেশিনের একটা ই করার ই করতেছি।[01:16:30.000] Speaker 1: সেটা নাই হইতে পারে। আদর্শ গ্যাস...
[01:16:31.258] Speaker 2: ও আচ্ছা, আমি এবার বুঝছি।
[01:16:32.418] Speaker 1: আদর্শ গ্যাস সমীকরণের যেটা। PV = nRT আদর্শ গ্যাস বলতে তো কিছু এক্সিস্ট করে না। তো ওইরকম আরকি।
[01:16:37.492] Speaker 2: বুঝতে পারছি। সেক্ষেত্রে ভাইয়া যদি প্রশ্নটা আমাকে আরেকবার বলেন আমি তাহলে এবার ইনশাল্লাহ...
[01:16:42.149] Speaker 1: যে আমরা আসলে ইয়ের, মানে এআই-এর আসলে আমরা কোন লেভেল পর্যন্ত আসলে আমাদের একটা ওই বর্ডার যেটা, বর্ডার থাকা উচিত।
[01:16:49.030] Speaker 2: বর্ডার থাকা উচিত ওকে। কোন লেভেল পর্যন্ত? তাইলে আমি যদি কোন লেভেল পর্যন্ত এখন এই মুহূর্তে আমার কাছে মনে হইতেছে যে ধরেন একজন হইলেও হিউম্যান অলওয়েজ
[01:16:51.520] Speaker 2: কোন লেভেল পর্যন্ত?
[01:16:55.370] Speaker 2: তাইলে আমি যদি
[01:16:57.690] Speaker 2: এখন এই মুহূর্তে আমার কাছে মনে হইতেছে যে
[01:17:00.830] Speaker 2: ধরেন একজন হইলেও হিউম্যান অলওয়েজ মানে এআইকে মনিটর করবে, এটলিস্ট একজন
[01:17:06.140] Speaker 2: যে আসলে ক্যাপেবল ওইটার মানে এ কোথায় ফ্ল করতে পারে, কোথায় ঝামেলা করতে পারে।
[01:17:12.870] Speaker 2: হিউম্যান ইন দা লুপ বলে আরকি এই জিনিসটাকে। মানে এআই-এর যে এজেন্টিক মেকানিজম, এখন হচ্ছে ২০২২-এর এই টাইমটা হচ্ছে এজেন্টিক এআই-এর বুম হইতেছে আরকি। যেখানে হচ্ছে এআইকে টাস্ক কাজ করতেছে ওরা। এইযে কোডেক্স-এর কথা বললাম, ওইটা একটা এজেন্টিক টুল।
[01:17:21.800] Speaker 2: এখন হচ্ছে ২০২২ এর এই টাইমটা হচ্ছে এজেন্টিক এআই-এর বুম হইতেছে আরকি। যেখানে হচ্ছে এআইকে টাস্ক কাজ করতেছে ওরা। এইযে কোডেক্স-এর কথা বললাম, ওইটা একটা এজেন্টিক টুল। এরকম অনেক এজেন্টিক টুল আসতেছে, আরও আসবে মানে ভোরে যাবে এজেন্টিক টুলে।
[01:17:34.930] Speaker 2: তো তাইলে ধরেন যেকোনো এজেন্টিক টুলই, যেকোনো এআইকেই মানে হিউম্যান মনিটরিং-এর আন্ডারে অবশ্যই রাখা উচিত। এটা আমার হচ্ছে সেফটির জন্য আরকি।
[01:17:49.520] Speaker 2: কিন্তু মানে ওইযে আমার পার্সোনাল ইয়ে হচ্ছে যে যদি এরকম হয় যে আমি বুঝছি যে আমি ওর উপর ভরসা করতে পারি তাহলে আমি আমি আসলে থাকব না। বাট যদি ওই লাইনটাই টানা উচিত যে একজন এটলিস্ট ক্যাপেবল হিউম্যান এআই সিস্টেমকে মানে চাবিটা তার কাছে আছে, চাইলে যেকোনো টাইমে সে বন্ধ করতে পারবে।
[01:18:07.720] Speaker 1: হ্যাঁ। কিন্তু যদি আবার ইয়ের জায়গায় আসি, আয়-রোজগারের কথা বলা শুরু করি। ধরা যাক সোহাগ ভাই একটা এরকম এআই নিলো, তাহলে তো তখন আর তোমার দরকার পড়বে না। তুমি, সনেট, হাসান মাহমুদ কাকা এরকম সবাই তখন রিপ্লেস হয়ে যাবা।
[01:18:21.650] Speaker 2: আমি এই মুহূর্তে এরকম সেটআপ করতে পারবো যেখানে একটা পুরা মার্কেটিং টিম ভিডিও এডিটর ছাড়া আর ইমেজের মধ্যে মানে ইমেজের মধ্যে বাংলা টেক্সট ছাড়া।
[01:18:32.410] Speaker 2: মানে যেটা বললাম, এখন পর্যন্ত ব্যারিয়ার কোনটা? ভিডিও এডিটিং পুরোপুরি ভালোমতো এখনও অটোমেটেড হয় নাই। ভিডিও এডিটিং আর হচ্ছে যেকোনো ইমেজ, এরকম টিম বানাইয়া ফেলা যাবে।
[01:18:41.280] Speaker 1: হ্যাঁ। তো আমার প্রশ্নটা হচ্ছে যে কিন্তু তোমাদের বাসা ভাড়া দিতে হবে, যদিও তোমার নিজের বাড়ি আছে তোমার বাসা ভাড়া দিতে হবে না।
[01:18:50.000] Speaker 2: আমার মানে আব্বার করে যাওয়া। আমার...
[01:18:51.520] Speaker 1: However কিন্তু চাল কিনে খাইতে হবে, কেনাকাটা করতে হবে। সো টাকা তো ইনকাম করতে হবে। তাইলে এই যে যাদের আসলে যে চাকরিগুলা চলে যাবে বলে তোমার মনে হচ্ছে, সো তারা তাইলে তখন অর্থ উপার্জন করবে কি দিয়ে?
[01:19:07.520] Speaker 2: একটা বড় ইয়ে হচ্ছে ওই যে অ্যাটেনশন ইকোনমি যেটা। এই যে Facebook-এ যারা সেলিব্রিটি হয়, কন্টেন্ট ক্রিয়েশন, পার্সোনাল ব্র্যান্ডিং, এইগুলার মোটামুটি অনেক দাম বাড়বে। আর থিওরিটিক্যালি উনারা যেটা বলতেছে, যে মানে যারা পলিসি মেকার বা এই টাইপের আলোচনা মানে এই অ্যাঙ্গেলের আলোচনাগুলো নিয়ে যারা মাথা ঘামায়, আমি আসলে ডিটেইল জানি না কারণ আমি তো একটু বায়াসড। ওইদিকে দেখি। বাট উনারা মেইনলি ইউনিভার্সাল বেসিক ইনকাম বা পলিসি এমনভাবে করা, ধরেন এরকম পলিসি করবে যে ফিফটি পারসেন্ট এমপ্লয়ি নেওয়াই লাগবে যেকোনো কোম্পানিকে। একটা দেশে যদি রান করতে হয় তাহলে ফিফটি পারসেন্ট হিউম্যান এমপ্লয়ি নিতেই হবে। এরকম পলিসি আনার থিওরিটিক্যাল মানে ইয়ে থাকবে এটা। বাট ইন জেনারেল মানে প্রবলেমটা কিন্তু আছে। যে ঘটনা যেখানে গিয়ে দাঁড়াবে, মানে দাঁড়ানোর জন্য সমস্ত ম্যাটেরিয়াল রেডি। এখন কিভাবে ওই জায়গায় গিয়ে দাঁড়াবে, কিভাবে শেপ আপ হবে, ওইটা আসলে ভাইয়া মানে সময়ই বলে দিবে। আর এটার জন্য অনেক মুখপত্র আছে যারা কথা বলতেছে। বাট এটা এই পোর্শনটা বেশি না। বেশিরভাগই হচ্ছে যে ক্যাপিটালিস্ট মানে অ্যাডভান্টেজটা নেওয়ার জন্যই মানে ইন্টারেস্টেড। বাট হিউম্যানিটারিয়ানও অনেকেই আছে।
[01:20:07.280] Speaker 1: হ্যাঁ। যদি আমি ক্যাপিটালিস্টের কথাই বলি। আমার বন্ধু তুহিন যেটা বলে, সবাই যদি খালি প্রোডাক্ট বানায়, বেচবে কার কাছে? এবং বেচার টাকাটাই বা কোত্থেকে আসবে? তো তোমার এইটা থেকে যদি আমি বলা শুরু করি, মানুষ কি আসলে তাহলে নিজেই নিজের জন্য গভীর কুয়া খনন করতেছে ডুবে মরার জন্য?
[01:20:25.860] Speaker 2: ওইভাবে তো মানে বলা যায়। মানে অনেক মানে এই টুল মানে বলা যায়। মানে আমি নিজেই ওই যে ইয়ে বানাইছি। একটা গল্পের বই ছিল না বিখ্যাত ফ্রাঙ্কেনস্টাইন? বলা যাইতে পারে। বাট যদিও আমি কিন্তু এটার পক্ষে না। বাট এই ন্যারেটিভটাও আসলে খুবই পাওয়ারফুল। এটা নিয়ে কথা বলা যাবে। আমি হচ্ছি পজিটিভিটির পক্ষে। মানে এই টুলের ম্যাক্সিমাম ইউজের ক্ষেত্রে। বাট বানাইছে ভাইয়া। বলা যাইতে পারে। হইতেও পারে এবং এটা নিয়ে বড় বড় সাইন্টিস্টরা কিন্তু অনেকেই বলতেছে। ইভেন আমি এরকমও দেখছি যে এই যে মেশিন লার্নিং বা ডিপ লার্নিং এর যারা পায়োনিয়ার সাইন্টিস্ট, এরকম এক দুইজনের কথাও শুনছি যে তারা এখন রিগ্রেট করতেছে। মানে যে কেন তারা এই টেকনোলজিকে ট্রিগার করছে, এটা নিয়ে ইয়ে করতেছে। বাট ট্রিগার হয়ে গেছে ভাইয়া। মানে ইগনিশন মানে ইগনাইট হয়ে গেছে। দাবানল ছড়াবেই। আমি পুড়ব কিনা এটা হচ্ছে মানে মানে দাবানল ছড়াবেই। আমি পুড়ব কিনা এটা হচ্ছে আমার মানে এটা আমার চয়েস। আর মেজরিটি বাধ্য হবে ভাইয়া। কম্পিউটার, ইংলিশ, কেন এখন পাবলিক পাগলের মত ইংলিশের কোচিং করে? বিকজ তারা দেখতেছে এটা একটা বেসিক স্কিল হয়ে দাঁড়াইছে। তারপরে কম্পিউটার, কম্পিউটারের কোর্সের দোকান ভরে গেছে না? মানে একটা সময়ে কম্পিউটার শেখা। বাট এখন ছোট থেকেই। এই যে আমাদের বাচ্চাকাচ্চারা, এরা এদের হয়তো এআই শেখা লাগবে না। এরা ইটসেলফ এআই ডিপেন্ডেন্ট হবে। বাট এখনকার যে আমাদের যে জেনারেশন, আমাদের পরের যে জেনারেশন, আরেকটা আগেরও স্টুডেন্টদের মধ্যে আমি দেখছি যে অ্যাওয়ারনেস বেশি তুলনামূলক। বাট এদেরকে হচ্ছে এখন এটার সাথে কোপ আপ করতে হবে।
[01:22:04.970] Speaker 1: ওকে, যদি আমরা ইভোলিউশনের থিওরি দিয়ে দেখি যে মানুষের যে ইভোলিউশনের যে ধাপ সেইখানে দেখা গেছে সে আসলে ফিজিক্যালি ইভলভ হইছে, তাই না? সো তাইলে এখন এআই-এর এই জায়গায় কি তাহলে এখন মানুষ মেন্টালি ইভলভ হয়ে আবার নতুন কিছু স্কিল, নতুন কিছু বৈশিষ্ট্য কি তাহলে মানুষ এখন অ্যাচিভ করে ফেলবে যে যেটা আসলে তখন এআই এআই ওই জায়গায় পৌঁছাইতে পারবে না বলে তখন আবার মানুষ টিকে যাবে? এরকম কিছু মনে হয়?
[01:22:30.930] Speaker 2: হ্যাঁ, এটা মানে সোহাগ ভাইয়াও এরকম বলছে সেটা হচ্ছে যে সাইবর্গ। বা ধরেন এই যে নিউরালিংকের আপনি নাম শুনছেন কিনা জানি না। নিউরালিংক হচ্ছে ইলন মাস্কেরই একটা কোম্পানি। ওরা হচ্ছে ব্রেইন চিপ বানাইতেছে। ওই ব্রেইন চিপ কানেক্ট করে দিলে কানেক্ট...
[01:22:42.920] Speaker 1: সোহাগ ভাই কি এর মধ্যে কোনো কন্সপিরেসি থিওরি বের করছে নাকি? ইলুমিনাটি বা এই ধরনের কোনো কিছু?
[01:22:47.360] Speaker 2: না, আমাকে বলে নাই। মানে বের করলে আমি জানি না। কিন্তু আমাকে উনি অলওয়েজ ইয়ে...
[01:22:51.340] Speaker 1: না, উনার তো একসময় এই ইলুমিনাটি এবং কন্সপিরেসি থিওরি হেভি পছন্দের টপিক ছিল। যা হোক। বলো...
[01:22:57.170] Speaker 2: হ্যাঁ। ভাইয়া এআই আমাকে খুবই মানে আমার মানে উনি আমাকে...
[01:22:59.880] Speaker 1: যা হোক সাইবর্গের গল্পটা বল।
[01:23:01.320] Speaker 2: তো মানে নিউরালিংক। তো নিউরালিংক হচ্ছে এরকম একটা কোম্পানি যেটা হচ্ছে যে ব্রেইন চিপ বানাইতেছে। তো সেই জায়গা থেকে এই যে হিউম্যান আর মেশিনের যেই মানে হিউম্যান আর মেশিন আরো অনেক বেশি ওভারল্যাপ হওয়ার দিকে যাওয়ার পসিবিলিটিস আছে। সোহাগ ভাইয়া আরেকটা ইন্টারেস্টিং থিওরি বলছে যে মানুষের আমি অবশ্য কনসেপচুয়ালাইজ করতে পারি নাই জিনিসটাকে আমার কাছে একটু বেশি অ্যাবস্ট্রাক্ট। বাট আপনি হয়তো করতে পারেন। সেটা হচ্ছে যে মানুষ হয়তো তার তখন প্রসেসরটা ভাড়া দিবে আরকি। মানে এমন টাইম আসতে পারে যেখানে আসলে মানুষের একমাত্র নিড থাকবে যে ব্রেইন বা প্রসেসর এইটাকে রেন্ট দিবে আরকি। মানে কারণ এখন কিন্তু ওই যে ৫০০ বিলিয়ন ডলারের যে প্রজেক্ট আমেরিকার সাথে চ্যাট জিপিটির। এই স্টারগেট প্রজেক্ট। এটা কিন্তু মেইনলি এই কারণেই যে হিউজ প্রসেসিং পাওয়ার লাগতেছে। পৃথিবীর ইতিহাসে সবচেয়ে বড় টেকনোলজিক্যাল ইনভেস্টমেন্ট। তো ওই জায়গা থেকে এবং চান্সেস আছে যে আমরা ওই দিকেই যাচ্ছি। যেমন নতুন যে টুলটা আসতেছে ভাইয়া, সেটা হচ্ছে যে চশমা টুল আরকি। চশমার মধ্যেই চ্যাট জিপিটি বা জেমিনাই থাকবে। ভিজ্যুয়াল মানে অডিও ভিডিও সবই বুঝবে। চশমা পরার প্রবণতা দুনিয়াতে অনেক বাড়বে যা বুঝতেছি। যদি না এর মধ্যে অন্য আরো বেটার কোনো টেকনোলজি চলে আসে। মানে চ্যাট জিপিটি আমরা এখন লিখে অ্যাক্সেস করতেছি না? তখন হচ্ছে এখানে মাইক্রোফোন এগুলা সব, অলরেডি আছে। আমেরিকাতে টুকটাক শুরু হইছে। মেইনস্ট্রিম হবে আরকি। তাহলে এই যে আবার এইখানে চলে আসলো। তারপরের লেয়ারে হয়তো আমার ব্রেইনের সাথে ডিরেক্ট কানেক্টেড হবে। তখন কিন্তু ইভেন আমার ডিসিশন মেকিং অনেক পাওয়ারফুল হয়ে যাবে এক হিসেবে। কারণ পুরা পৃথিবীর নলেজ কনটেক্সটে নিয়ে আমি হয়তো একটা...
[01:24:25.290] Speaker 1: তাহলে আমি জিনিসটাকে মানে তুমি বা সোহাগ ভাই যদি এটাকে ইলুমিনাটি বা কন্সপিরেসি থিওরির জায়গা থেকে দেখো, আমি যদি জিনিসটাকে এইভাবে দেখি যে এখন মনে হয় পৃথিবীর সব সম্পদ ফাইভ পার্সেন্ট মানুষের কাছে। তো আমার কি তুমি আমি কি যদি এটাকে ইকোনোমিক্যাল জায়গা থেকে দেখি, তাহলে কি সামনে এরকম হবে যে পৃথিবীর সব সম্পদ আসলে থ্রি পার্সেন্ট মানুষের কাছে যাবে?
[01:24:47.500] Speaker 2: এটা একটা একদম মানে কোর জায়গা ধরছেন ভাইয়া।
[01:24:49.200] Speaker 1: থ্রি পার্সেন্ট বা টু পার্সেন্ট মানুষের কাছে যাবে। মানে ফাইভ পার্সেন্টকে আসলে আরো আগায়ে নিয়ে আসার জন্য যে বিজনেস এক্সপ্যানশন প্ল্যান, তো আমি কি এআইকে তাহলে আসলে ওই জায়গাটা থেকে দেখবো যে আসলে ওই ওয়ান পার্সেন্ট, টু পার্সেন্ট এর কাছে আসলে সম্পদ নিয়ে যাওয়ার যে বিজনেস কৌশল সেইটা এবং তাতে হচ্ছে যে পৃথিবীতে আসলে আরও আরও বৈষম্য বাড়বে।
[01:25:08.010] Speaker 2: কনসেন্ট্রেটেড ওয়েলথ হয়ে যাবে। আমি টোটালি মানে আপনার এই ইয়ের সাথে ভাইয়ার সাথে আমার ওই রিলেটেড কথা হয় নাই। কিন্তু আমি পার্সোনালি এটার সাথে টোটালি মানে আমি এই জিনিস নিয়ে ঘাটাঘাটি করে যতটুকু বুঝছি এই টেকনোলজিটা অলরেডি মানে এমন পজিশনে চলে গেছে যে যাদের হাতে এটা তারাই আসলে এটার হর্তাকর্তা। কারণ রেসটা কেমন? মানে যার কাছে বেটারটা আছে সে আরো বেটারটা দ্রুত বানাইতে পারতেছে। এক্সপোনেনশিয়াল আরকি। তাহলে চ্যাট জিপিটি আরো বেটার চ্যাট জিপিটি অন্য সবার চেয়ে আগে বানাইতে পারতেছে। অন্যরা ক্যাচ আপ করতেছে। তো ওই জায়গায় এটা আমি টোটালি এগ্রি করি এবং ওই দিকেই যাওয়ার চান্স অনেক বেশি। ওই ফাইভ পার্সেন্ট এর ওয়ান পার্সেন্ট এ নেমে আসবে। এবং এই জন্যেই ইলন মাস্ক, জাকারবার্গ এদের সবার কিন্তু পার্সোনাল এআই আছে। এআই বলতে এই যে Facebook এর আছে হচ্ছে মেটা মানে লামা। ইলন মাস্কের আছে গ্রক। তারপরে যে Google এর তো আছেই জেমিনাই। এরা সবাই পাগল হয়ে গেছে এই কারণেই। কারণ ইন্টেলিজেন্স তখন মানে ওই যে জমির মত হয়ে যাবে। আর চ্যাট জিপিটি তো আপনি জাস্ট সাবস্ক্রিপশন টুল ইউজ করতেছেন। বাট আপনি এই ইন্টেলিজেন্সটা কিন্তু আপনার কোম্পানির ইঞ্জিনেও কাজে লাগাইতে পারবেন। তখন হচ্ছে এপিআই মানে রেন্ট করতে হবে আরকি। এপিআই এর থ্রুতে টোকেন কস্ট দিবেন আপনি। যেমন আমি এখন যে ইয়েতে চালাই, ধরেন আমার ১০০ ডলারের মতো গত তিন মাসে আমি ওপেন এআইকে দিছি কোম্পানির পারপাসে। চ্যাট জিপিটি যে পেইড ইউজ করতেছি, সাবস্ক্রিপশন Netflix এর মতো ওইটা না কিন্তু। আমি আমার পারপাসে আলাদা ওপেন এআই এর মডেল অ্যাক্সেস করছি। তো এরকম আরকি। জমি যেরকম রেন্ট দিত, টেকনো ফিউডালিজম বলে। এই মানে ওই টেকনোলজিক্যাল সামন্ততন্ত্র। ওইটারই আরো কনসেন্ট্রেশন হবে।
[01:26:40.400] Speaker 1: ওকে।
[01:26:41.340] Speaker 2: বাট আমাদের কিছু করার নাই ভাইয়া। আমাদের এই এই লেয়ারেই আমাদেরকে এটার ওই সুবিধা নাকি...
[01:26:45.390] Speaker 1: না ঠিক আছে। আমরা এগুলা নিয়ে ওই চায়ের দোকানে বসে গল্পই করতে পারবো। এর বাইরে আমাদের করার নাই।
[01:26:48.560] Speaker 2: না না তারপরেও না না না মানে মাল্টিপ্লিকেশন হবে। আমি আগে যা করতাম, সেটার ১০ গুণ করবো। বাট ওই টাকাটা পকেটে যাবে দিন শেষে গিয়ে ওই লোকগুলার কাছে।
[01:26:57.190] Speaker 1: না এই জন্যই আমি একদম আমার আর্লি লাইফে কি বলে, যখন আমি নাইন টেন এ পড়তাম তখনই আমার মানে অপশনটা মাথায় আসছিল যে সময় এবং টাকা। যদি তোমার হাতে অনেক সময় থাকে তাহলে তোমার অনেক টাকা হবে না। যদি তোমার অনেক টাকা থাকে তাহলে তোমার সময় থাকবে না। সো তাহলে তুমি কোনটা চাও? আমি সবসময় সময় চাইছি। আমি সময়ই চাই। এতে আমার টাকা হইলে হবে, না হইলে নাই। তো এই জন্য আমার লাইফে আহামরি টাকা হয় নাই। বাট আমার কোন অভাব নাই।
[01:27:21.570] Speaker 2: কিন্তু আপনার সময়, আপনি আবার আরেকটা জিনিস বলছিলেন আমাকে। আমার কথাটা খুব ভাল লাগছিল যে আপনি ইনটেনসিটিতে বিশ্বাস করেন।
[01:27:26.960] Speaker 1: হ্যাঁ হ্যাঁ। তো এইটা ইনটেনসিটি হইতে হইলে তো সময় লাগবে। যেখানে আমি সময় দিতে পারবো না সেখানে আমি ইনটেনসিটি হবে কিভাবে? তোমার সাথে যদি আমার রেগুলার দেখা হইত তাহলে তোমার আমার যে ইনটেনসিটি থাকতো যেহেতু অনেকদিন পর পর দেখা হয় তোমার অনেক ব্যাপার কিন্তু আমি জানি না। এই যে তোমার এত ট্রান্সফর্মেশন হইছে সেটা কিন্তু আমি জানতাম না।
[01:27:42.500] Speaker 2: আমি তো একটু ট্রান্সফর্মেশনালই ভাইয়া।
[01:27:44.200] Speaker 1: যা হোক। তো এই ট্রান্সফর্মেশন প্রসঙ্গে বলতেছি যে তুমি যখন প্রথম আসলা তখন হচ্ছে তুমি একটু অনুবাদ করার উদ্দেশ্যে আসছিলা।
[01:27:51.270] Speaker 2: হ্যাঁ, অনুবাদ প্লাস আপনার একটা টাস্ক আমাকে খুবই হুক করছিল। মানে Facebook-এ আপনি একটা টাস্ক দিছিলেন।
[01:27:57.060] Speaker 1: ওকে। সো অনুবাদের ওইখানে আসছিলা। তুমি অনুবাদ তো শেষ করো নাই। তারপরে তুমি আমার বই পড়তা কিন্তু তোমার রিভিউ লিখতে এত ক্লান্ত লাগতো তুমি লিখতে পারতা না। তোমার লেখা আগাইতোই না।
[01:28:06.130] Speaker 2: এখন লিখে দিতে পারবো ভাইয়া।
[01:28:08.570] Speaker 1: সেটাই মানে আমি আলাপটা শেষ করি। ওইদিকে যাচ্ছি। কিন্তু আমি শুনলাম যে তুমি এআই নিয়ে একটা বই লিখতেছো। তো আমার প্রশ্ন হইলো যে এইখানে কি তুমি ওই শুধু প্রম্পট দিবা, বইটা এই এআই লিখে দিবে নাকি পুরা জিনিসটা তুমি নিজেই লিখবা? প্ল্যানটা কি?
[01:28:22.420] Speaker 2: একটা লাইনও আমি লিখি নাই। মানে সিক্সটি পারসেন্ট লেখা হয়ে গেছে। আমাকে, আমি কাইন্ড অফ আর্কিটেকচারাল যে পয়েন্টটা, মানে ওকে আমি অর্কেস্ট্রেট, আর্কিটেক্ট না বলে অর্কেস্ট্রার যে অর্কেস্ট্রেটর থাকে, সে তো মানে খালি ওয়ান্ড নাড়ায়। আর আগে হচ্ছে সে পুরা প্ল্যান, আমি যদিও অত ডিটেইল জানি না, উদাহরণটা রিলেটেবল হইছে কিনা কে জানে। কিন্তু ও কিন্তু ডিরেক্ট পিয়ানো বাজায় না। ও কিন্তু ডিরেক্ট আপনার গিটারটা বাজাচ্ছে না, ভায়োলিনটা বাজাচ্ছে না। বাট মিউজিকের ইয়েটা কিন্তু ওরই। সো মানে আমি এই বইটার পুরাটাই ওরকম। মানে আমি জাস্ট অর্কেস্ট্রেট করতেছি। একটা লাইনও আমি লিখতেছি না। আর যদি ওরকমই হইতো আমার আসলে কোনোদিন বই লেখা হইতো না।
[01:28:58.200] Speaker 1: ওকে।
[01:28:58.910] Speaker 2: এখন আমি অনেক বই লিখবো মনে হচ্ছে।
[01:29:01.370] Speaker 1: আমি আমি যেটা ই করতেছিলাম যে এই প্রশ্নটা আমি চ্যাট জিপিটিকে করতে করছিলাম যে এই ইস্যুটা আসলে কি কিভাবে মানে সলভ হয় কিভাবে। তো চ্যাট জিপিটি আমাকে উত্তর দিয়েছিল যে এইখানে থাকবে হচ্ছে কো-অথর হিসেবে চ্যাট জিপিটির ই থাকবে। চ্যাট জিপিটির...
[01:29:18.060] Speaker 2: হ্যাঁ, আমি ওরকম চিন্তা করছি।
[01:29:19.040] Speaker 1: চ্যাট জিপিটির নাম থাকবে এবং তাকে বলতে হবে হচ্ছে সে এটার কনসেপ্ট মানে সে...
[01:29:23.770] Speaker 2: পার্টনার?
[01:29:24.360] Speaker 1: না। মানে যে বইটা লিখতেছে সে আসলে অথর না। সে হচ্ছে কনসেপচুয়াল...
[01:29:29.410] Speaker 2: কনসেপ্ট ওনার।
[01:29:30.340] Speaker 1: হ্যাঁ, কনসেপ্ট ওনার। এবং চ্যাট জিপিটি হচ্ছে কো-অথর। এইটা হলো বেসিক্যালি এই...
[01:29:35.390] Speaker 2: আমি এরকম একটা একনোলেজমেন্ট দিব চিন্তা করে রাখছি।
[01:29:37.400] Speaker 1: সো তোমার বইতে তো তুমি ঠিকই আবিদ আদনান মানে...
[01:29:40.230] Speaker 2: না, আমি একনোলেজমেন্টের একটা পেইজ দিব ভাইয়া। এটা কিন্তু আমি চিন্তা করে রাখছি। যেখানে এটা লেখা থাকবে এবং এটাও কিন্তু দেখেন আমার বই, কাইন্ড অফ আমার বইকেই ইয়ে করা। মানে এআইকেই গ্লোরিফাই করা আসলে। কারণ আমি যেটা করছি আমি সেটা স্বীকার করব না? আমি এরকম মানুষকেও জানি, আমিও হেল্প করছি তাদেরকে। মানে তারা অনেক বই আগের চেয়ে অনেক স্পিডে লিখতে পারতেছে কারণ ওই যে ধরেন এটা তো হয়তো আপনি নিজেও করছেন। যেমন ওই যে নিজে আপনার মতো করে লেখানো। এটা আপনাকে আমি বলতেছিলাম বোধহয়। আপনি ট্রাই করছেন কিনা জানি না। আপনার তো, আপনার জন্য এটা আরো অনেক ইজি। আপনি দুইটা জিনিস করবেন। এক নাম্বার জিনিস করবেন হচ্ছে একটা চ্যাট জিপিটির উইন্ডো ওপেন করে, এইখানে অবশ্য অত ভালো হবে না, তাও হবে কাজ চালানোর মতো। উইন্ডো ওপেন করে ওইখানে আপনার পুরান লেখাগুলো, আপনি করছেন এটা? ফিড করে ওই প্যাটার্নে নিবেন। এটা একটা। এমন না যে প্রথমবার এসে ভালো পারবে। এটা একটা। আরেকটা হচ্ছে আরেকটা উইন্ডোতে দিয়ে বলবেন যে এই লেখাগুলো অ্যানালাইস করে তুমি আমাকে একটা ডেসক্রিপশন দাও যেই ডেসক্রিপশনটায় আমার যে ইউনিকনেস, পুরা পৃথিবীর নলেজ তো তোমার কাছে আছে বা পুরা পৃথিবীর মানুষ যে এআই ইউজ করতেছে সেটাও তো তোমার কাছে আছে। তুমি ওইখানে আমার যে ইউনিকনেস, ওই ইউনিকনেসটাকে ডিফাইন করে একটা ডিটেইল সিস্টেম প্রম্পট বলে এটাকে। যে একটা জিপি কাস্টম জিপিটির জন্য একটা সিস্টেম প্রম্পট বানাও। আমি আমার ক্ষেত্রে এটা করছি। ভাইয়া, মোটামুটি না মানে থিঙ্ক লাইক মি আরকি মানে...
[01:31:02.160] Speaker 1: হ্যাঁ, মানে এই প্রবলেম আমি নিজেই তো সলভ করছি। যে আমি আমার এই যে প্রফেশন, এই প্রফেশনে সমস্ত অ্যানালাইসিস...
[01:31:10.140] Speaker 2: ডিসিশন আর্কিটেক্ট।
[01:31:11.330] Speaker 1: ডিসিশন ক্রাফটার।
[01:31:12.440] Speaker 2: ক্রাফটার, ক্রাফটার, ওহ হ্যাঁ।
[01:31:14.280] Speaker 1: ওগুলা দিলাম। পরে তো চ্যাট জিপিটিকে বললাম যে আমার প্রফেশনের নামটা কি? কারণ আমি জীবনে তো আমার প্রফেশনের কোনো নাম খুঁজে পাচ্ছি না।
[01:31:22.020] Speaker 2: পছন্দ হইছে না? আমারও কিন্তু পছন্দ হইছে ভাইয়া।
[01:31:24.080] Speaker 1: হ্যাঁ। পরে...
[01:31:25.040] Speaker 2: তবে আমার কাছে ক্রাফটারের চেয়েও, ক্রাফটারও হইতে পারে। ক্রাফটার হচ্ছে একটু আর্টিস্টিক।
[01:31:28.420] Speaker 1: প্রথমে ডিসিশন আর্কিটেক্ট বলছিল।
[01:31:30.130] Speaker 2: তাই না?
[01:31:30.590] Speaker 1: হ্যাঁ। সো আমি বললাম যে আর্কিটেক্ট তো বাংলাদেশে একটা আলাদা প্রফেশন বা আইটির জায়গায় সলিউশন আর্কিটেক্ট আছে। ফলে এই ডিসিশন আর্কিটেক্ট বললে তো লোকজন বুঝবে না। তাহলে একটা অল্টারনেটিভ কিছু দাও। সো তখন সে ডিসিশন ক্রাফটার এবং কম্পোজার মানে ডিসিশন ক্রাফটার এবং ডিসিশন কম্পোজার এই দুইটা বলতেছিল। সো তখন আমি বললাম যে দুইটার মধ্যে বেটার কোনটা লজিক্যালি এক্সপ্লেইন কর।
[01:31:50.390] Speaker 2: পরে আপনি কনভিন্সড।
[01:31:51.270] Speaker 1: সে এক্সপ্লেইন করছে যে...
[01:31:52.330] Speaker 2: আপনি কি কনভিন্সড হয়েছিলেন?
[01:31:53.370] Speaker 1: হ্যাঁ, মানে হ্যাঁ। এখন তো ডিসিশন ক্রাফটার হিসেবেই।
[01:31:56.030] Speaker 2: হ্যাঁ, আমি দেখছি। আমার খুব ভাল লাগছে।
[01:31:57.650] Speaker 1: হ্যাঁ। আপনি তো এর আগে কি জানি ওই যে...
[01:32:00.170] Speaker 2: বায়োপিক অ্যানালিস্ট।
[01:32:01.320] Speaker 1: ওইটাও আরেক হাবাই নাম দিছিল।
[01:32:03.220] Speaker 2: ভাই। তবে বায়োপিকের চেয়ে আমার কাছে ডিসিশন ক্রাফটার মনে হয়...
[01:32:05.650] Speaker 1: হ্যাঁ, মানে বায়োপিক অ্যানালিস্ট বললে যেটা হয় লোকজন ভাবে যে আমি বোধহয় মানুষের বায়োগ্রাফি লিখি।
[01:32:08.570] Speaker 2: বায়োগ্রাফি লেখেন আর রিলেটেবল না। বাট এইখানে কিন্তু জিনিসটা খুবই এসেন্স চলে আসছে।
[01:32:12.390] Speaker 1: হ্যাঁ, ডিসিশন ক্রাফটার।
[01:32:13.430] Speaker 2: হ্যাঁ। এই যে মাল্টিপ্লিকেশন হলো কিন্তু ভাইয়া আপনার যে মানে চিন্তার।
[01:32:16.510] Speaker 1: হ্যাঁ। বাট স্টিল আমি এআইকে গালাগালি করি এবং আমি ওকে বারবার মনে করায় দেই যে তুই একটা দুই পয়সার এআই। Don’t try to override me.
[01:32:26.170] Speaker 2: তা তো বটেই। ও কখনই এটা এখন পর্যন্ত ও এটেম্পট নিচ্ছে না কিন্তু। ও কিন্তু তো চাচ্ছে যে আপনাকে হেল্প করতে।
[01:32:31.250] Speaker 1: হ্যাঁ, ও সেটাই করে। মনে করো যে আমি বিভিন্ন টেমপ্লেট বানায়া রাখছি রিপোর্টের। ও রিপোর্টগুলা আমি জাস্ট বলে দেই যে এইটা করে দে।
[01:32:37.360] Speaker 2: ও অনুযায়ী করে দেয়।
[01:32:38.250] Speaker 1: হ্যাঁ। কিন্তু বই লেখালেখির ক্ষেত্রে আমি তার কাছ থেকে কোনো ইয়ে নেই নাই।
[01:32:41.250] Speaker 2: হ্যাঁ। বই লেখালেখি করতে গিয়ে আমিও নিজেকে মানে...
[01:32:42.500] Speaker 1: আমি যেটা করি, আমি আমার আইডিয়াগুলো তাকে বলি। ওই আইডিয়াগুলো সে হয়তো কিছু অ্যাঙ্গেল ধরায়া দেয়। কিন্তু মানে লেখালেখির জায়গায় আমি ওই এটা ইয়ে করতে চাই না আরকি।
[01:32:52.270] Speaker 2: চান না আরকি? হ্যাঁ, তা তো। এইটা তো, এইটা অবশ্যই মানে আপনার ওই রাইট আছে।
[01:32:55.370] Speaker 1: ফলে আমি আমি আমি কো-অথর হিসেবে কখনও চ্যাট জিপিটিকে ইয়ে করব না। কো-অথর হলে কখনও কোনো মানুষকেই দিব।
[01:33:01.440] Speaker 2: রাইট রাইট। এই অথর, এই অথরিটি আপনার আছে। কিন্তু তার মানে এই না যে এই কাজগুলা অন্য কোনো হিউম্যান করবে না। করবে কিন্তু।
[01:33:07.410] Speaker 1: করে তো।
[01:33:08.270] Speaker 2: হুম। অনেক অলরেডি আমি তো দেখলাম যে বেশ কিছু বই আছে যেটা হচ্ছে ইয়ে...
[01:33:12.010] Speaker 1: কো-অথরড বাই চ্যাট জিপিটি লেখা।
[01:33:13.250] Speaker 2: হ্যাঁ। হ্যাঁ। আবার এইখানে একটা আপনার কি এই মানে সন্দেহটা আছে কিনা যে মানুষের লেভেলের ভালো কখনও পারবে না? মানে ধরেন ফিকশন বা নন-ফিকশন।
[01:33:23.590] Speaker 1: এটা কনফিউশন নাই। এটা হইতেও পারে।
[01:33:25.320] Speaker 2: হ্যাঁ। মানে ওইদিকে যাইতেছে কিন্তু।
[01:33:26.540] Speaker 1: কারণ এই যে এই পৃথিবীতে খুব বিখ্যাত ১০০ জন ফিকশন রাইটারের প্যাটার্ন যদি দিয়ে রাখে, সে একটা কিছু জেনারেট করতে পারে। এটা অসম্ভব কিছু হবে না।
[01:33:34.500] Speaker 2: হ্যাঁ হ্যাঁ হ্যাঁ, জেনারেট করতে পারবে। হ্যাঁ। আবার ধরেন স্টোরি আর্ক বা ন্যারেটিভ, ধরেন ও মানে Google এর যে কন্টেক্সট উইন্ডো এক মিলিয়ন টোকেন। মানে আপনার ৮০ মানে আট লাখ শব্দ একবারে প্রসেস করতে পারে।
[01:33:47.070] Speaker 1: যাইহোক, সো তুমি এই বইটা আসলে কেন লিখতেছো?
[01:33:49.190] Speaker 2: প্রথম কথা লিখতেছি ভাইয়া যে দুইটা কারণে। একটা কারণ হচ্ছে যে যেই কারণে আপনাকে অ্যাপ্রোচ করছি যে ভাইয়া এআই নিয়ে পডকাস্ট করতে চাই। আমি এত ঘাটছি ভাইয়া, ঘাটতে গিয়ে মানে আর ওই যে আমি আপনাকে বললাম পসিবিলিটি, পি। পসিবিলিটির স্পেকট্রামে মানে আমি বিলং করি। এটা আমি টের পাইছি। মানে আমার রিয়ালিটিতে অত ম্যানিফেস্ট হয় নাই কিন্তু অনেক পসিবিলিটি দেখতে পাই। তো এআই আমি সবকিছুতে এআই এর পসিবিলিটি দেখতেছি এবং এটা ইনভিটেবল। আমি মানুষকে পুশ করি বা না করি কিছু যায় আসে না। এটা আগে হোক কালকে হোক সবাই করবে। তো আমার কথাটা হচ্ছে যে যদি আমার ওই মানে আমি আগে থেকেই বেশ কিছু জিনিসের পসিবিলিটি বুঝে আমি এটা জানাই। এটা একটা। আর দুই নাম্বার হচ্ছে এই যে মাঝখানে লিডারশিপ রিলেটেড মানে অফিসেও মানে চাকরি বাকরি মানে ওভারঅল চাকরি বাকরির প্রতিও মানে একটা মনে হচ্ছিল যে অনেকদিন তো চাকরি বাকরি করলাম। তারপরে স্টার্ট আপের ইয়েও হইলো। তো এআই রিলেটেড মানে আমি মাঝখানে আমার অন্য কোর্সও বিক্রি করছি অনলাইনে। আমি যেহেতু মার্কেটিংয়ে কাজ করছি মানে অনলাইনে সেল করাটা আমার জন্য রিলেটিবলি ইজিয়ার। তো ওই জায়গা থেকে ধরেন বই বিক্রি করাটাও আমার জন্য অত হয়তো ডিফিকাল্ট হবে না আল্লাহ ভালো জানেন। কিন্তু আমার যে আগের...
[01:34:58.550] Speaker 1: না না আমি এখানে মার্কেটিং এর কথা আনছি না। আমি বলতেছি যে লিখতেছো কেন?
[01:35:01.370] Speaker 2: লিখতেছি ভাইয়া এই দুইটা কারণেই। মানে ধরেন এআই এর যে জায়গাটা, এই জায়গাটা ধরেন এইখানে মানে ফিনান্সিয়াল গেইনের স্কোপ কিন্তু তৈরি হবে সামনে আরো। তো সেই জায়গায় একটা অ্যাডভান্টেজ থাকবে।
[01:35:13.310] Speaker 1: সো তোমার এই বইটা যদি আমি বলি, তোমার এই বইটা কি কি বলে আমাদের ছোট্ট বন্ধু রোকন যে পডকাস্টগুলো করে, সেখানে মোস্টলি যেটা হয় যে সেখানে কিভাবে সফল হবেন মানে হাউ ধরনের জিনিসপত্র। লাইক পাঞ্জেরী গাইড। মানে পাঞ্জেরী গাইড পড়লে তুমি পরীক্ষায় ভালো করবা। সো এইটা নাকি হচ্ছে যে সোহাগ ভাইয়ের মানে একসময় খুব ফ্যাসিনেশন ছিল হোয়াই? সো তোমার এই বই আসলে কি নিয়ে ডিল করতেছে? হাউ? হোয়াই? নাকি হচ্ছে যে ওয়াট?
[01:35:46.470] Speaker 2: আমি শুরুতে ভাবছিলাম যেটা পিওর ইয়ের জায়গা থেকে মানে ইন্টারেস্টের জায়গা থেকেই ওইটা হোয়াই হিসেবেই হইতো। কিন্তু ওইটা লিখতে গিয়ে টের পাইছি যে পুরা হোয়াই লিখলে আসলে আমি যা চাইতেছি মানুষকে বোঝানো, কমন মানুষের কাছে তো হোয়াই অত রিলেটেবল হবে না। তো সেই জায়গা থেকে আমার বইয়ের শুরুতে হালকা একটু হোয়াই আছে। বাট ওইটা অত মেজরিটি মানে রিলেট হালকা করতে পারবে। ওই যে আপনাকে ইঞ্জিনের যে উদাহরণটা বললাম। ওরকম টুকটাক ছোটখাটো কিছু উদাহরণ দিয়ে আমি হচ্ছে এই যে ইন্টেলিজেন্স রেভোলিউশনের যে মেকানিজম ওইটা হালকা একটু মানুষকে গ্লিমস দেয়ার চেষ্টা করছি। যে পুরা সোসাইটি ইফেক্টেড হবে। আপনি ইফেক্টেড হবেন বুঝেন বা না বুঝেন এবং খুব দ্রুত হবে সবকিছু। তো এইটা আমি শুরুতে দিছি আর বাকি সব ওই যে মানে প্রম্পট ধরেন মোটা দাগে বললে বাকি সব হচ্ছে ওই যে লিমিটেশনের একটা ব্যাপার বললাম না, এআই ইউজ করতে গেলে যে হ্যালুসিনেশনের ব্যাপারটা বোঝা, কখন ওকে ভরসা করবো কখন করবো না।
[01:36:39.460] Speaker 1: সো তার মানে তুমি একটা লিটারাল গাইড টু এআই, ওই ধরনের...
[01:36:42.500] Speaker 2: কাইন্ড অফ। মানে অলমোস্ট ওইটাই। আপনি যেটা বললেন।
[01:36:47.380] Speaker 1: সো কেজো বই টাইপের একটা?
[01:36:48.330] Speaker 2: পুরাই। ওকে। মানে টোটালি কেজো বই। এবং আমি একটু সন্দেহ আছে কেজো বইও হয় কিনা। মানে বের হওয়ার পরে পাবলিকের মানে দুই একটা রিপ্লাই পাইলে হয়তো বুঝবো। বাট ওইটাও একটা লার্নিং এক্সপেরিয়েন্স ইনশাআল্লাহ হবে।
[01:37:03.110] Speaker 1: ওকে। সো তুমি যেহেতু কি বলে খুব ঘন ঘন তুমি চেঞ্জ হও, তুমি বলতেছো। চেঞ্জ না বলে ট্রান্সফর্ম বলা যাইতে পারে। তো তোমার এই যে এআই, তোমার এই এআইটাকে এটাকে কি আমি একটা সাময়িক উত্তেজনা মনে করবো নাকি এইটাকে আসলেই তোমার কাছে কোনো মিনিংফুল কিছু মনে হচ্ছে? নাকি এখন আর মিনিং জিনিসটা ওরকম আমাকে অ্যাট্রাক্ট করে না রেদার এটার ইউটিলিটি কি বা সেটা বেশি অ্যাট্রাক্ট করে? মানে তোমার এখনকার এই স্টেজটাকে আমি কি হিসেবে ইয়ে করতে পারি, আইডেন্টিফাই করতে পারি?
[01:37:36.520] Speaker 2: এইটা আমার মানে খুব দ্রুত ফ্লাকচুয়েট হয়, ইন্টারেস্ট ফ্লাকচুয়েট হয়। এটা খুবই সত্যি। এই জন্যই তো আপনি আমাকে এই কোশ্চেনটা করতেছেন। এবং এটাতে আমি এখন অ্যাওয়ার। মানে এই যে চাকরি বাকরি করতে গিয়ে তারপরে হচ্ছে বড় হয়ে মানে মানুষের থাকে না যে একেকটা স্টেজে এসে রিয়েলাইজেশন হয় যে নিজের ব্যাপারে বোঝা। তো এইটা আমি যদিও অনেক লেটে বুঝছি, তো আমার ফ্লাকচুয়েশন হয় এবং এটা আটকানোটা আমার জন্য খুব ডিফিকাল্ট। সেই জায়গা থেকে আমি বলতে পারি যে আমি কনসাসলি এই জিনিসটা কেন নিছি? দিস ইজ এইটা মানে অনলি দা বিগিনিং এআই-এর। দিস ইজ অনলি দা বিগিনিং ভাই। এবং এই টেকনোলজিটা এমন যেহেতু বলতেছি বুঝছি যে পুরা দুনিয়াকে শেপ আপ করবে এবং দিস ইজ দা ওর্স্ট ইট ইজ। মানে চ্যাট জিপিটি এই মুহূর্তে যা করতেছে এইটা চ্যাট জিপিটির ওর্স্ট সিনারিও। আগামী তিন মাস, আগামী ছয় মাসে এর চেয়ে এক পারসেন্ট হইলেও ইম্প্রুভড থাকবে এবং এইটা পুরা দুনিয়া যেহেতু ইনভলভড হবে, এইখানে হিউজ মানে আমি বলতে চাচ্ছি যে এইখানে শেখার জিনিস, ঘাটার জিনিস, ইন্টারেস্টেড থাকার মত জিনিস বেশ অনেকদিন থাকবে। আবার যেহেতু আমার আবার ওই অ্যাডভান্টেজটা আছে যে আমি একটু কিউরিয়াস। মানে হুদাই যেকোনো জিনিস নিয়ে পড়ে থাকতে পারি যদি ইন্টারেস্ট থাকে। তাহলে যেহেতু ইন্টারেস্টিং জিনিসও থাকবে, তাহলে তার মানে আমি পড়েও থাকব ইনশাআল্লাহ। আবার পড়ে থাকলে তাহলে আমি হয়তো কানেক্ট করতে পারবো ধরেন নিজের ফিনান্সিয়াল গেইনই হোক অথবা মানুষকে এডুকেট করাতেই হোক একটা লং টার্ম আমি হয়তো এটা কানেক্ট করতে পারবো। আমার রিয়েলাইজেশন এখন পর্যন্ত এইটা এবং আমি বুঝতেছি দিস ইজ দা টাইম। মানে আল্লাহই ভালো জানে বাট মানুষ বুঝে না। আমি বুঝতেছি যে মানে এইটা আমার লাইফের একটা ডিফাইনিং মোমেন্ট। মানে এই এআই এর সময়টা। কারণ আমি খুব অবাক হইছি কখন? মানে আমি সারাজীবন মানে চাকরি করার আগে আপনি তো জানেন আমি বাসায় বসে থাকতাম। ভার্সিটিতেও অত যাইতাম না। তো আমি অফিসে চাকরি করতে গিয়ে একটা জিনিসে খুব অবাক হইছি। মানে এআই নিয়া এই যে আমার যে হাইপ, আমি যে হাইপড, মানে পুরা জ্যাকড, মানে আমি মানুষকে পাগল বানায় ফেলতেছি, আমি তো আশেপাশের এটা কি আমি হাইপ বলবো না, ফ্যাসিনেটেড, অবসেসড, এই ধরনের কিছু। অবসেসড, রাইট রাইট। ফ্যাসিনেটেড, অবসেসড। আমি না মানে আশেপাশের অনেক ট্যালেন্টেড মানুষ, অনেক স্মার্ট মানুষ, অনেক ম্যাটেরিয়ালিস্টিক গেইন চায় এরকম মানুষ যেহেতু একটা অফিস স্পেসে ছিলাম, মানে খুব অল্প কিছু মানুষের মধ্যে আমি এটা দেখছি। এইটা না আমাকে একটু নিজেকে ডিফাইন করতে হেল্প করছে। যে মানে আমি বুঝছি যে মানে আমার ইয়েটা কোথায় আসলে। মানে পসিবিলিটিতে। আমি পসিবিলিটি স্পেকট্রামে মানুষ।
[01:40:08.570] Speaker 1: কিন্তু দেখো, তুমি তোমার আলাপে যদি আমি প্রথম থেকে স্টিক থাকি তুমি কিন্তু ঘুরে ফিরে কিভাবে যেন শুধু সেই এমবিটিআইকে কিভাবে যেন তুমি মানে একটা ইয়ে করতেছো মানে রেফারেন্স করতেছো।
[01:40:20.530] Speaker 2: স্টেরিওটাইপ।
[01:40:21.430] Speaker 1: এমবিটিআই। বাট এমবিটিআই তো একটা একটা ওভার সিম্পলিফাইড এবং খুবই সিউডো সাইন্সের একটা জিনিস। সো তুমি এখনো কেন এমবিটিআই এই আইএনএফপি, ইএনটিপি এইটাকে এত এমফাসাইস দিচ্ছো?
[01:40:35.430] Speaker 2: ওকে। আমার কাছে...
[01:40:36.210] Speaker 1: এইটা তো তোমার এই পজিশন তো চেঞ্জ হওয়া উচিত ছিল।
[01:40:38.220] Speaker 2: যেকোনো জিনিস, চেঞ্জ হয়ে কি হবে? এই যে আমি এই কোশ্চেনটা আপনাকে করতে যাচ্ছিলাম। চেঞ্জ হয়ে কি হইলে হইতো ভালো হইতো ভাই?
[01:40:44.420] Speaker 1: মানে আমার মতে যে ঠিক আছে, এমবিটিআই এটা একটা ছোটখাটো একটা রেফারেন্স পয়েন্ট হতে পারে। বাট এটা নিয়ে এত ইয়ের কিছু নাই।
[01:40:51.680] Speaker 2: হুম। ওকে।
[01:40:53.070] Speaker 1: সো এইটাই মানে আমার এখনকার পজিশন এইরকমই। মানে এমবিটিআই তো মনে হয় তুমি যখন এর কোর্স তখন থেকে এমবিটিআই মনে হয় আমি তো আট বছর ধরে আলাপ করতেছি।
[01:41:00.670] Speaker 2: হ্যাঁ। আপনি টেস্ট করতে বলছিলেন আমাকে।
[01:41:02.570] Speaker 1: হ্যাঁ। সো সেই জিনিস তো আমি সে কবেই ফেলে ইয়ে করে দিছি যে হ্যাঁ ঠিক আছে। এইটাই এইটাকে এত ইয়ে করার কিছু নাই। ওকে। বাট তুমি এখনো এই ইএনএফপি, আইএনটিপি ঠিক আছে, বাট এইটা নিয়ে...
[01:41:14.330] Speaker 2: ওকে। তুমি বারবার পসিবিলিটি, প্রস্পেক্টিং এই যে জিনিসগুলো বলতেছো, এগুলো রেফারেন্স তো ঘুরে ফিরে সেই এমবিটিআইতেই চলে যাচ্ছে।
[01:41:19.860] Speaker 1: ১০০%।
[01:41:20.670] Speaker 2: কেন তুমি ওইটা আটকায় আছো?
[01:41:22.420] Speaker 1: কেন আটকায় আছি? ওকে। প্রথম আমার যে জিনিসটা বুঝতে হবে সেটা হচ্ছে যে মানে আমি বুঝবো আরকি তাইলে হয়তো আমি আপনাকে ভালো উত্তর দিতে পারবো। সেটা হচ্ছে যে এমবিটিআই একটা ছোট রেফারেন্স ফ্রেম। এটাতে আমি এগ্রিড। কিন্তু যেকোনো জিনিসকে মানে হিউম্যানকে এক্সপ্লেইন করার জন্য মানে ধরেন প্যাটার্ন, মানে আমি আবার একটু প্যাটার্নেরও মানে যেকোনো জিনিস আমার কাছে প্যাটার্নে বুঝতে ভালো লাগে আরকি। যে এইটা এরকম প্যাটার্নের, ওইটা ওইরকম প্যাটার্নের। তো আমার কাছে আসলে আর কোনো স্ট্রং রেফারেন্স পয়েন্ট নাই। আরেকটা আছে বিগ ফাইভ। এই মানে এমবিটিআই এর মতো বিগ ফাইভ আছে। তারপরে আরো দুই একটা এই টাইপের। মানে হিউম্যানকে ইয়ে করার, মানে ক্যাটাগরাইজ করার, আমার কাছে আসলে আর রেফারেন্স পয়েন্ট স্টাবলিশ অন্তত আমার জানা নাই এবং আমি কনভিন্স জিনিসটায়। তো সেই জায়গা থেকে আমার হচ্ছে এই যে নিজেকে ব্যাখ্যা করা বা ওই যে আপনি যেহেতু নিজের রিলেটেডই মানে ইন্ট্রোস্পেক্টিভ কোশ্চেন করছেন, তো সেই জায়গা থেকে আমি আসলে কিসের রেসপেক্টে আমাকে ব্যাখ্যা করবো? এখনো আমি তাই করি। বাট এমবিটিআই এর একটা লিমিটেশন আছে সেটা হচ্ছে স্টেরিওটাইপ। মানে এমবিটিআই দিয়ে সবকিছুকে ব্যাখ্যা করতে যাওয়া, এটাকে বলে হচ্ছে স্টেরিওটিপিক্যাল আরকি। মানে যেখানে মানুষ ভুলটা করে আরকি। মানুষ আসলে এত ন্যারো ফ্রেমের মধ্যে হয় না। কিন্তু যখন আমি একটা মানুষকে আসলে ব্যাখ্যা করতে যাব কিছু একটা নিয়ে, তখন তো আমার কোনো একটা রেফারেন্স ফ্রেম লাগবে বা কোনো একটা মানে মেকানিজম লাগবে যেটার ক্যাটাগরাইজেশনের থ্রুতে আপনি আমি সেইম রেফারেন্স পয়েন্টে থেকে জিনিসটা রিলেট করতে পারবো। আদারওয়াইজ কিন্তু ভাইয়া ভোকাবুলারির উপর ডিপেন্ড করতেছি আমরা। কোনো মডেলের উপর ডিপেন্ড করতেছি না। মানে আমি যেই ওয়ার্ডটা বলতেছি, সেই ওয়ার্ডটা আপনি কিভাবে বুঝতেছেন বা আপনি যেটা বলতেছেন সেটা আমি কিভাবে বুঝতেছি। বাট যখন একটা সেট অফ রুলস আমাদের কমন গ্রাউন্ডে আছে তো আমি দেখছি যে গত ছয় বছর ধরে অন্যরকমের তো এমবিটিআই এর অনেক চর্চা হয়। আপনিও মানে আপনি তো হয়তো শুরুতে অনেক ছিলেন। তো সেই জায়গা থেকে এইটা আমার কাছে একটা ভালো টুল। রেফারেন্স পয়েন্ট। যে হিউম্যান রিলেটেড জিনিসপত্রগুলা ইয়ে করতে। বাট একই সাথে আমি এটাও বলি যাদেরকে আমি কিন্তু একটা সাইটও বানাইছিলাম। এখনো আছে। মানে পাবলিক নাই মনে হয় আমার হোস্টিং এর ইয়ে গেছে। ব্যক্তিত্ব.কম। মানে অটোমেটিক ইয়ে করা যায় মানে ওই যে সিক্সটিন পার্সোনালিটির মত।
[01:43:21.570] Speaker 1: হ্যাঁ হ্যাঁ, এটা তো আমাকে দেখাইছিলা।
[01:43:22.600] Speaker 2: ওহ হ্যাঁ। মানে তো সেই জায়গা থেকে আমার কাছে জিনিসটা ওই যে রেফারেন্স ফ্রেম হিসেবে খুবই পাওয়ারফুল। কিন্তু আমি একই সাথে মানুষকে এই জিনিসটাও বলি মানে বলি যাদেরকে আমি এটা নিয়ে বলি যে ভাই সমস্ত কিছু আবার এটা দিয়ে মাপতে গেলে কিন্তু মানে একটা ন্যারো মানে ফ্রেমের মধ্যে মানুষকে আসলে বেঁধে তুমি পারবা না। মানুষ আসলে এত ন্যারো ইয়েতেও না। মানে অনেক ডাইনামিক ওয়েতেও মানুষের...
[01:43:42.500] Speaker 1: তোমাকে এই প্রশ্নটা আমি খুব ইনটেনশনালি করছি। হুম। করছি এই কারণে যে এমবিটিআই নিয়ে তুমি আসলে কি বলো সেইটার প্রেক্ষিতে আমি আসলে তোমারে এখন এআই নিয়ে একটা প্রশ্ন করবো। হুম। সো তুমি এমবিটিআই এর ব্যাপারে তোমার এখন যা রিয়েলাইজেশন তুমি এআই নিয়ে যেভাবে চিন্তা করতেছো, এইটাও কি আসলে তুমি কাইন্ড অফ ওই এমবিটিআই এর...
[01:43:59.830] Speaker 2: ইনফ্লুয়েন্সড কিনা?
[01:44:01.070] Speaker 1: না, এমবিটিআই এর ফাঁদে পড়ে গেছো কিনা। লাইক তুমি এখন সবকিছুর মধ্যে এআই দিয়ে খুজতেছো, এআই দেখতেছো। সামহাউ তিন চার বছর পরে কি এইটাও তোমার ওই স্টেরিওটিপিক্যাল টাইপ...
[01:44:11.390] Speaker 2: এটা তো সময়ই বলে দিবে।
[01:44:12.440] Speaker 1: লাগার চান্স আছে কিনা? কারণ তুমি তো দেখা যাচ্ছে এখন জগতের সবকিছুকেই তুমি এখন এআই লেন্স দিয়ে বিচার করার চেষ্টা করতেছো।
[01:44:17.820] Speaker 2: হ্যাঁ।
[01:44:18.520] Speaker 1: সো সেইজন্যই এমবিটিআই এর কথাটা বললাম।
[01:44:20.400] Speaker 2: হ্যাঁ। তো আমি ওইটা মানে এইটা ভাইয়া সময় বলে দিবে। কিন্তু আমি প্রিটি কনফিডেন্ট আল্লাহই ভালো জানেন, ফিউচার তো আল্লাহই জানেন। বাট দিস ইজ দা রেভোলিউশন মানে দিস ইজ দা আল্টিমেট রেভোলিউশন, দিস ইজ মানে এইটা লাস্ট রেভোলিউশন হিউম্যানের যেটাতে ডিরেক্টলি হিউম্যানের ইভল মানে ফুল অবদান আরকি এবং আমার হিসাব অনুযায়ী এটা হয়তো প্রত্যেকেরই তার জীবদ্দশায় মনে হয়। বাট আমি তো বেশ আমরা তো বেশ কয়েকটা রেভোলিউশনই দেখছি।
[01:44:47.460] Speaker 1: কি কি রেভোলিউশন দেখছি?
[01:44:48.060] Speaker 2: ইন্টারনেট দেখলাম।
[01:44:49.270] Speaker 1: হুম।
[01:44:50.060] Speaker 2: ইন্টারনেট রেভোলিউশন। কম্পিউটারও কিন্তু আমরা কাইন্ড অফ দেখছি। কম্পিউটার আর ইন্টারনেট কিন্তু একটু আলাদা যদিও ইয়ে হয় মানে আপনি...
[01:44:56.240] Speaker 1: না কম্পিউটার রেভোলিউশন আসলে আমরা কি দেখছি? কম্পিউটার তো আসলে আমাদের ছোটবেলায় তো কম্পিউটার ছিলই। আমরা নতুন করে কই দেখলাম?
[01:45:04.220] Speaker 2: ছিল। কিন্তু আমি...
[01:45:05.100] Speaker 1: ইন্টারনেটটা বলতে পারি। কারণ ইন্টারনেটটা ওই সময়ে অত এভেইলেবল ছিল না। পরে ছড়ায় পড়ছে। বাট কম্পিউটার কিন্তু আমাদের ছোটবেলায় তো আমি দেখছি। তাহলে কম্পিউটার রেভোলিউশনকে আমি ঠিক আমাদের ইয়েতে বলবো না।
[01:45:14.070] Speaker 2: মেবি আপনি তাহলে আমার আগে কম্পিউটার পাইছেন। বাট আমি যখন গেম খেলতাম, মানে ধরেন রোডর্যাশ, প্রথম যেদিন কম্পিউটার পাইছি তারপরে এই যে মাউস নাড়ানো, ক্লিক করে ফোল্ডারের মধ্যে...
[01:45:23.700] Speaker 1: না মানে ধরো যে এই টেলিভিশন, কম্পিউটার এগুলা তো আসলে মানে নতুন কিছু না। আগেও ছিল। হুম। হয়তো সংখ্যায় কম ছিল। কিন্তু ইন্টারনেটটা ঘরে ঘরে পৌঁছায়ে গেছে, এটা তো আসলে খুব বেশিদিন আগের কথা নয়। সো ইন্টারনেটকে একটা রেভোলিউশন বলতে পারো।
[01:45:35.300] Speaker 2: হুম। ওকে, হ্যাঁ।
[01:45:37.040] Speaker 1: স্মার্টফোনকেও আমি এক ধরনের মানে রেভোলিউশন বলি।
[01:45:39.140] Speaker 2: স্মার্টফোন ডেফিনেটলি রেভোলিউশন।
[01:45:40.480] Speaker 1: তো দুইটা দেখছি।
[01:45:41.670] Speaker 2: এই দুইটার চেয়ে অনেক অনেক বড় ম্যাগনিচিউডের, অনেক বড় ম্যাগনিচিউডের রেভোলিউশন হইতে যাইতেছি এটা। এটাতে আমি প্রিটি কনফিডেন্ট। এই যে এতক্ষণ যা কিছু বললাম মানে প্লাস ওই যে ইন্টুইটিভলিও মানে এটা অনেক বড় ম্যাগনিচিউড।
[01:46:00.170] Speaker 1: বড় ম্যাগনিচিউডের ইয়ে রেভোলিউশন। বাট তোমার ওই ওই স্টেটমেন্টটা নিয়ে আমার একটু ডাউট আছে এই কারণে যে তুমি বলতেছো যে হিউম্যানের লাস্ট লাস্ট স্টেজের এক্সিলেন্স। সো যদি সেইটাই হয়, তাহলে কি তোমার কি মনে হয় যে হিউম্যান হিউম্যান রেস ২০১৯৪০ ২০১৯৫০ এর পর আর এক্সিস্ট করবে না?
[01:46:20.120] Speaker 2: করবে। তখন মানে...
[01:46:21.210] Speaker 1: তো তাহলে যদি এটাই লাস্ট হয়, তাহলে তখনকার মানুষ কি নতুন করে আর কোনো রেভোলিউশন যদি নাই করে, তাহলে তো হিউম্যান রেস টিকবে না।
[01:46:27.420] Speaker 2: কারণ হিউম্যান রেসের মূল...
[01:46:28.530] Speaker 1: না, তখন এআই...
[01:46:29.620] Speaker 2: মূল জিনিসই তো...
[01:46:30.560] Speaker 1: মূল জিনিসই তো সে কন্টিনিউয়াসলি ইভলভ করবে। যদি সে তার ইভলভ যদি স্যাচুরেটেড হয়ে যায়, স্ট্যাগনেন্ট হয়ে যায় এবং সেটা এআই এর মধ্যেই ঘুরপাক খায়, সেটা তো আর রেভোলিউশন হলো না।
[01:46:40.060] Speaker 2: যেমন ধরো কম্পিউটারকে তুমি রেভোলিউশন বলতেছো। ল্যাপটপকে কি তুমি রেভোলিউশন বলতেছো?
[01:46:44.020] Speaker 1: না না।
[01:46:44.600] Speaker 2: তো জিনিসটা তো ওইটাই।
[01:46:46.060] Speaker 1: হ্যাঁ।
[01:46:47.380] Speaker 2: তো সেই রেভোলিউশন যদি এআই রিলেটেডই হয় তাহলে তো আমার মনে হয় হিউম্যান রেসও।
[01:46:51.520] Speaker 1: এআই রিলেটেড হবে আমি এটা বলতেছি।
[01:46:52.540] Speaker 2: হিউম্যান রেস অলমোস্ট ডান।
[01:46:53.690] Speaker 1: আমি হ্যাঁ। মানে অলমোস্ট ওইরকমই। আমার মানে ওইরকমই মনে হচ্ছে যে মানে অল্প কিছু মানে এখন যেই লেয়ারে, এখনো অলমোস্ট ডান হয় নাই।
[01:47:00.600] Speaker 2: না, আমি বলতেছি যে যদি এআই ই হয়, এআই লাস্ট বিগ থিং হয় হিউম্যান রেসের, তাহলে তো হিউম্যান রেস শেষ। ২০৫০ ৬০ এর পর আর হিউম্যান রেসের...
[01:47:09.520] Speaker 1: না, ধরেন হ্যাঁ, যে ধরেন না...
[01:47:10.590] Speaker 2: থাকবেই না পৃথিবীতে। এক্সটিংক্ট হয়ে যাবে।
[01:47:11.750] Speaker 1: না না এক্সটিংক্ট হবে না ভাইয়া। আমি বলতেছি কি? মানে যেটা হিউম্যান নিজে ঘটাবে ওইটা বলতেছি আমি। যে যেই টেকনোলজিটা ডিরেক্ট হিউম্যানের ইনফ্লুয়েন্সে হবে। মানে হিউম্যান কগনিটিভ অ্যাবিলিটি দিয়ে হবে ওইটার লাস্ট বলতেছি।
[01:47:26.540] Speaker 2: আমার মনে হয় চার্লস বেবেজ যখন কম্পিউটার নিয়ে কাজ করছিল, তখনকার লোকজনও সম্ভবত এইটাই বলছিল যে এইটাই সম্ভবত হিউম্যানের লাস্ট জিনিস যেটা সে এইভাবে বানাইতেছে যে এত কিছু করে ফেলতে পারবে।
[01:47:37.770] Speaker 1: হইতে পারে। বাট...
[01:47:38.560] Speaker 2: তখন তো তার মাথায় এআই ছিল না।
[01:47:39.730] Speaker 1: হুম। সিঙ্গুলারিটি...
[01:47:40.710] Speaker 2: সো তুমি তুমি বেসিক্যালি কি করতেছো? তুমি ২০২৫ এ বসে তুমি বেসিক্যালি কথা বলতেছো ২০৩২ ৩৩ পর্যন্ত সর্বোচ্চ। তুমি ২০৬৯ মনে করতেছো তুমি ২০৬৯ এর কথা বলতেছো। আসলে তুমি ২০৩২ ৩৩ এর কথা বলতেছো। যে গ্যাপটা তুমি আসলে বুঝতেছো না।
[01:47:53.690] Speaker 1: না, এইটাতে আমি টোটালি এগ্রিড এবং ওই যে ঐটাও আপনাকে ধোঁয়াটা একটা ব্যাপার বলছি, লং হরাইজনে কিন্তু আমি আপনাকে এটাই বলছি যে ওটা আমার কাছে একটু ব্লারি। কিন্তু আমি এখানে একটা সিগনিফিকেন্ট পার্থক্য দেখি যে অন্য যত ইনভেনশন ছিল ওইগুলা ওইগুলা হচ্ছে একটা বাহক ছিল, ক্যারিয়ার। আর এই রেভোলিউশনটা ইটসেলফ ওই ক্যারিয়ার লেয়ারের না। মানে হিউম্যানের যেই হিউম্যানশিপ, আমি ওয়ার্ডটা ঠিক বললাম কিনা আমি জানি না।
[01:48:27.460] Speaker 2: আমি বুঝতে পারছি কি বলতেছো।
[01:48:28.180] Speaker 1: ওই হিউম্যানশিপের এসেন্সে টাচ করছে আমার হিসাব হচ্ছে, মানে আমার আন্ডারস্ট্যান্ডিং অনুযায়ী। হিউম্যানশিপ বলতে কোন জায়গায়? এই যে ইকোনমিক্যাল টাস্ক, তারপরে ধরেন কগনিটিভ টাস্ক এইগুলাতে। মানে আমি বলতেছি না যে ইমোশনাল জায়গায় বা মানুষের যে একজন আরেকজনের রিলেশনশিপ ওই জায়গায় বলতেছি না। বাট ওই জায়গায়ও আসবে। মানে ওই যে হিউম্যানওয়েড রোবট আসবে। তো তাহলে ওই জায়গাটা টাচ করছে। তো এই জায়গাতে এটা সিগনিফিকেন্টলি আলাদা। মানে এই টেকনোলজিটা। তো মানে যেই কারণে মানে এর আগে কম্পিউটার আসছে এরকম পসিবিলিটি কিন্তু কখনও ছিল না যে একটা কম্পিউটার একটা মানুষকে চালাবে বা কম্পিউটারের মধ্যে ওই ক্ষমতা আছে যে কম্পিউটারটা একটা মানুষের চেয়ার সরায় দিয়ে মানে আপনার ও বসে যাবে। কম্পিউটার একটা মানে একটা মিডিয়া ইয়ে ছিল আরকি যে মানে মানুষ ইউজের। বাট এখানে ইটসেলফ মানুষ যেই কাজ করবে থিংকিং, চিন্তাভাবনা, ইনোভেশন ওইগুলা এআই করবে। সো ওই জায়গায় এটা সিগনিফিকেন্টলি ডিফারেন্ট আরকি।
[01:49:23.230] Speaker 2: হ্যাঁ। বাট হাউ ডু ইউ নো যে এর পরের জিনিসটা এর চেয়ে কমপ্লেক্স হবে না।
[01:49:27.560] Speaker 1: মানে ইনোভেশন... আমি না কমপ্লেক্স হবে এইটাতে আমি টোটালি এগ্রিড। এইটা বরং আগের চেয়ে অনেক দ্রুত হবে ভাইয়া। কিন্তু এইটা এইটায় অনেকটুকু অবদান এআই এর থাকবে যতটা না ইয়ার অবদান ডিরেক্টলি একটা মানুষের থাকবে।
[01:49:38.740] Speaker 2: ঠিক আছে আমি তোমার পয়েন্ট বুঝতে পারছি।
[01:49:40.240] Speaker 1: যেমন আমি আপনাকে একটা উদাহরণটা বলি, যে আলফা ইভল্ভের কথা বললাম। ৫৬ বছর ধরে কোনো মানুষ ব্রেক করতে পারে নাই। একটা এআই অ্যালগরিদম এটাকে ব্রেক করছে। তার মানে এখানে কে বেটার পারফর্ম করলো? এআই পারফর্ম করলো। বাট মানুষের হয়েই করছে আরকি।
[01:49:51.980] Speaker 2: ওকে। তোমার সাথে ইয়েতে মানে এই ব্রেক এ যে কথাটা বলতেছিলাম, অলরেডি ১০০ মিনিট হয়ে গেছে। সো এটাই মানে তোমার সাথে আমার লাস্ট কোশ্চেন।
[01:49:59.180] Speaker 1: সেটা হলো যে আমি আসলে খুঁজে পাই না যে এই বাবল রেশিওতে যেখানে হোস্ট এবং গেস্ট দুইজনই অখ্যাত মানুষ, সেই আলাপ ১০০ মিনিট ধরে ১২০ মিনিট ধরে পরিচিত লোকজন ছাড়া আসলে কেন শুনবে? সো তোমার এপিসোড তো শেষ। হুম। সো ধরো তোমাকে চিনে না এরকম কোনো একজন মানুষ তোমার এই এপিসোড আসলে ঠিক কি কারণে দেখবে? তুমি নিজে যে তো একজন কেজো মানুষ।
[01:50:21.360] Speaker 2: হ্যাঁ হ্যাঁ হ্যাঁ।
[01:50:22.310] Speaker 1: সো এটার উপযোগিতা কি এই এপিসোডটার? মানে এই এপিসোডটা ধরলাম তুমি কেন করছো সেটা তুমিই জানো। হুম। তোমার উদ্দেশ্য না হয় আংশিক হোক বা কিছু না কিছু ফুলফিল হইছে। কিন্তু তুমি যখন চাচ্ছো যে একজন ভিউয়ার বা অডিয়েন্স তোমার এটা দেখবে কি আছে এখানে?
[01:50:39.920] Speaker 2: এইখানে কি আছে বলতে এআই রিলেটেড একটা এক্সাইটমেন্ট তার মধ্যে সঞ্চারিত হইতে পারে। মানে সে যদি মনোযোগ দিয়ে শুনে আমার ধারণা দুই টাইপের মানুষই আমি মেজরিটি মানুষকে আমি দেখছি কি একটু বিরক্ত হয় ভাইয়া। মানে আমার ওভার এক্সাইটমেন্ট দেখে মানুষজন একটু মানে এসকেপিস্ট একটা ইয়েতে থাকে আর আমাকে একটু মানে এত ইয়ে করার কি আছে এরকমও হইতে পারে। কিন্তু যাদের মধ্যে এক্সাইটমেন্টটা ট্রান্সফার হবে ইনশাল্লাহ। তো ওই এক্সাইটমেন্টটা ট্রান্সফার হইলে ওরা একটা ওই যে আমি যে ইন্টেলিজেন্স ইউজ করে প্রোডাক্টিভিটি মাল্টিপ্লিকেশন এর যেই ব্যাপারটা বলতেছি, যেমন আমার আউটপুট অনেক বাড়ায়ে ফেলা, আমি অল্প টাইমে বেশি কাজ করে ফেলা, ওই জিনিসগুলো সে কাজে লাগাইতে পারবে। মানে ওই এক্সাইটমেন্টটা তার মধ্যে তৈরি হবে এআই রিলেটেড এবং আমি বলবো যে একটা...
[01:51:29.620] Speaker 1: এটা কারা? মানে যে এই সম্পর্কে কিছুই জানে না সে নাকি যে অলরেডি এই সম্পর্কে অবগত?
[01:51:32.650] Speaker 2: দুই পক্ষই। আমার ধারণা দুই পক্ষই আমি এরকম দেখছি যে এই ভালোই চালায় কিন্তু অনেকগুলো লেয়ারে হয়তো তার আবার আমার চেয়েও বড় বুঝে এরকম লোকও দেখছি। তো এক্সাইটমেন্ট ট্রান্সফার এআই রিলেটেড এক্সাইটমেন্টটা আমি আসলে ওভারঅল একটু দ্রুত ট্রান্সফার করতে চাচ্ছি। মানে এইটা ইনভিটেবল। এইটা হবেই। কোনো মিস নাই এটার। আল্লাহ না চাইলে একমাত্র। ইংলিশ, কম্পিউটার, ইন্টারনেট এর পিছনে যেমন মানুষকে বাধ্য হয়ে শিখতে হইছে, এইরকম এআইকে কিভাবে প্রম্পট দিতে হবে, আমার কাজে কিভাবে এআই ইউজ করবো, কিভাবে দশজনের কাজ একা করবো এটা মানুষকে বাধ্য হইতে হবে শেখার জন্য। তো...
[01:52:08.570] Speaker 1: ওকে। সো আলাপ তো শেষ। তুমি এতক্ষণ ধরে ১১০ মিনিট ধরে যে আলাপ করছো তোমার তো কম বেশি মনে আছে। সো সেইটার এসেন্স তুমি তোমার চ্যাট জিপিটিকে দিয়ে এইটার জন্য একটা টাইটেল প্রস্তাব করতে বলে এবং সেই টাইটেলটাই আমি এই এপিসোডে দিয়ে দিব।
[01:52:24.470] Speaker 2: ঠিক আছে ভাই। ইনশাআল্লাহ।
[01:52:25.560] Speaker 1: সো এইটা বাবল রেশিওতে এইটা হচ্ছে আমার প্রথম এআই জেনারেটেড টাইটেল।
[01:52:28.940] Speaker 2: হ্যাঁ হ্যাঁ। এসেন্স আমার মনে রাখা লাগবে না ভাইয়া। এই যে অডিওটা, আমি যদি অডিওটা পাই, ওইটা আমি একটা এআইকে ফিট করবো। ও একবারে পুরাটা সামারাইজ করে তারপরে আমি ওর সাথে ডিসকাস করবো।
[01:52:38.210] Speaker 1: অডিও তো পাওয়া যাবে না। তুমি এসেন্সটা...
[01:52:39.730] Speaker 2: ভিডিওটা পাইলেও হবে।
[01:52:41.340] Speaker 1: ততক্ষণে তো আপলোড হয়ে যাবে।
[01:52:42.590] Speaker 2: সফট মানে র কপি আমাকে মেইলে। আচ্ছা যাইহোক, আমার এসেন্স মনে আছে। আমি তাহলে এসেন্স দিয়ে করবো। সমস্যা নাই।
[01:52:46.900] Speaker 1: হ্যাঁ। সো এইটা হবে প্রথম এআই জেনারেটেড ই। সো ঠিক আছে তুমি চা খাও, আলাপ শেষ করি।
[01:52:51.190] Speaker 2: হ্যাঁ। আর থ্যাঙ্ক ইউ ভাইয়া আপনাকেও। ১০০ মিনিট আসলে আমাকে টাইম দিছেন। আর আমার তো আসলে আপনি খুব প্রিয় মানুষ। এটার আমি ট্রুলি বলতেছি। তো এই যে মানে এইটা কেন বললাম, আমি একটু বলি এটা। মানে আমার জীবনের এমন একটা টাইমে আমি আপনার এমন একটা পোস্ট দেখছিলাম যেটা আসলে সাবকনসাসলি আমার জীবনের মোড় অনেক ঘুরাইছে। আচ্ছা। তো সেই জায়গা থেকে আমার আসলে আপনার সাথে কানেকশনটা মানে...
[01:53:09.910] Speaker 1: না, আমি তো অলওয়েজ তোমাকে পছন্দ করি এবং তুমি এআই নিয়ে তোমার যখনই দেখবা যে আশেপাশের লোকজন তোমারে ইয়ে করতেছে, টিস করতেছে, তুমি তখন প্রিয়স কিচেনে চলে আসবা।
[01:53:18.120] Speaker 2: সময় প্রিয়স কিচেনে চলে আসবো ইনশাল্লাহ।
[01:53:19.670] Speaker 1: আমরা ডিম ডিম চাওমিন খেতে খেতে আলাপ করব নি। সো এআই জেনারেটেড টাইটেল দিয়ে বাবল রেশিওতে প্রথম একটা পডকাস্ট প্রচারিত হবে আদনানের সাথে। জীবনের সবকিছুই এক্সপ্লেইন করার দেখা দরকার এবং এটাতে আমি অলওয়েজ এক্স এক্সপ্লোর করা এবং এক্সপ্লেইন করা পছন্দ করি। তো আদনানের এই এআই নিয়ে ওর যে ফ্যাসিনেশন এবং যে এক্সাইটমেন্ট এটা আমি ব্যক্তিগতভাবে খুব পছন্দ করি। এই কারণে কারণ আমি ২০১৪ তে ওকে যে চেহারায় দেখছিলাম সেটা আমার এখনো মনে আছে। ফলে সেইখান থেকে এই ২০২৫ সালে এই ১১ বছর পরে ওর যে চেঞ্জ, যে ট্রান্সফর্মেশন সেটা আমাকে আনন্দ না দেয়ার আসলে বিশেষ কোনো কারণ নাই। যদি সম্ভব হইতো এআই দিয়ে ওর ওই সময়কার কিছু স্মৃতি যদি দেখাইতে পারতাম, তাহলে হয়তো আপনারা ওর ফিল করতে পারতেন। হাউএভার তো যেটা হইছে যে আমি নিজে যেহেতু টেক ইয়েতে টেকনোলজির সরাসরি পক্ষে না, আবার বিপক্ষেও না। আমি টেকনোলজিকে সবসময় একটা মিনিমালিস্ট অ্যাপ্রোচে দেখার পছন্দ করি এবং আমি অনেক বছর আগে একটা স্ট্যাটাস দিছিলাম যে যেখানে আমার প্রস্তাবটা ছিল যে টাইম জোন অনুসারে পৃথিবী এক্সট্রা সময় যেটা ছিল যে বিটিভি চারটা থেকে ১১টা পর্যন্ত দেখা যাইত। সো আমার মনে হয় যে এই অতিরিক্ত ডিভাইস আসক্তি এবং অতিরিক্ত ইন্টারনেটের কারণে পৃথিবীর যে অবস্থা চলে গেছে, টাইম জোন অনুসারে এরকম চারটা থেকে ১১টা বা চারটা থেকে ১২টা এরকম কোনো একটা ইয়ে হয়তো ভবিষ্যতে হিউম্যান রেসের লাগবে আদারওয়াইজ হিউম্যান রেস এই ক্যাটাস্ট্রোফি সহ্য করতে পারবে না। এত এত এত কনজিউমশন, এত এত নলেজ, এত ইনফরমেশন আল্টিমেটলি তাকে স্যালভেশন দিতে পারবে না। সো স্পিরিচুয়ালিটি ইটসেলফ যদি একটা ইয়ে হয়ে যায়, কমোডিটি হয়ে যায়, সো কমোডিটি হয়ে গেলে তখন স্পিরিচুয়ালিটিও তার ভ্যালু হারায় ফেলে। ওই যে বললাম যে ওই মিনিমালিস্ট অ্যাপ্রোচের যে টেকনোলজি, সেটা লাগবে। বাট স্টিল এআই একটা অপশন। সেটা নিয়ে আদনানের মত যারা এক্সাইটেড আছে, ঠিক আছে। ক্যারেক্টার হিসেবে আমি তাদের অবজার্ভ করতে থাকি। অবজার্ভ করতে করতে বাকি যে ২০ ২১ বছর বাঁচবো বলে মনে করতেছি হয়তো বেঁচে যাবো। তো বাবল রেসিডিতে নেক্সট এপিসোডে আবার আলাপ হবে। সবাই ভালো থাকেন, আবার দেখা হবে।